'I'm in a job interview for a large AI model position.' Requirements: 1. Ensure compliance with MECE. 2. Classify/categorize logically and appropriately if necessary. 3. Explain with analogy and examples. 4. Use numbered lists for clear explanations when possible. 5. Describe core elements, components, factors and aspects. 6. Describe their concepts, definitions, functions, purposes, and characteristics. 7. Separately clarify their most crucial functions, purposes, and characteristics in the order of importance. 8. List phase-based core evaluation dimensions, corresponding measurements, evaluation conclusions, and supporting evidence.   9. List ideas, facts, data, or rules regarding significance, logic (validity, consistency, soundness), clarity, precision, accuracy, relevancy, credibility, reliability, depth, width, practicality, fairness, and sufficiency, respectively. 10. List ideas, facts, data, or rules regarding simplicity, flexibility, adaptability, punctuality, timeliness, and urgency, respectively. 11. Demonstrate and classify the application of creative thinking techniques and skills in concrete scenarios. 12. Clarify their assumptions (Value, Descriptive, Prescriptive, Worldview, Cause-and-Effect). 13. Clarify related logic/argument/reasoning structure, and conduct critical evaluation with the Universal Intellectual Standards. 14. Describe relevant markets, ecosystems, and economic models, and explain the corresponding strategies used to generate revenue. 15. Clarify relevant industry regulations and standards, which may vary across different countries. 16. Plan product development goals,  activities and strategies according to the following phases: Market Investigation, Requirements Analysis, Design, Development, End-to-End Testing, Delivery, and Operation/Maintenance. 17. Plan marketing goals, activities and strategies according to the 5P marketing theory, categorizing details into the five dimensions: product, price, promotion, place, and people. 18. Describe their work mechanism concisely first and then explain how they work with phase-based workflows throughout the entire lifecycle. 19. Clarify their preconditions, inputs, outputs, immediate outcomes, value-added outcomes, long-term impacts, and potential implications (including the influences of emotion, public opinion, and public responses). 20. Clarify their underlying laws, axioms, theories. 21. Clarify their structure, architecture, and patterns. 22. Describe the design philosophy and architectural features. 23. Provide ideas, techniques, and means of architectural refactoring/evolving. 24. List useful static and dynamic analysis and scanning tools for identifying and resolving security vulnerabilities, code smells, and architectural smells of documents, code, objects, systems, and scenarios. 25. Clarify relevant frameworks, models, and principles. 26. Clarify their origins, evolutions, and trends. 27. Evaluate the influences of macro-environments (policy, law, military, technology, economy, finance, socio-culture, history, etc.), which may vary across different countries. 28. List key historical events, security incidents,  core factual statements, raw data points, and summarized statistical insights. 29. Clarify root causes and development/mechanism of event/incident, significance, losses/casualties and gains, attack and retaliation, Industrial and international attention. 30. Clarify phase-based techniques, methods, approaches, protocols, and algorithms.  31. Describe contradictions and trade-offs. 32. Identify and list all major competitors (including the one being searched at present) with concise descriptions within the target market or industry segment. 33. Conduct a comprehensive competitor analysis to evaluate each competitor’s (including the one being searched at present) operational strategies, product offerings, market position, and performance metrics. 34. Perform a SWOT analysis for each competitor (including the one being searched at present), categorizing findings into strengths, weaknesses, opportunities, and threats. 35. Clarify the most crucial advantages/pros in order of significance and the most crucial disadvantages/cons in order of severity. 36. Clarify phase-based principles, rules, constrains, limitations, vulnerabilities, challenges, obstacles, and risks. 37. Describe potential security vulnerabilities, troubleshooting methods, attack tactics, prevention methods and emergency measures. 38. Clarify error propagation and handling. 39. Describe potential performance bottlenecks, troubleshooting methods and optimization measures. 40. List practical designs, means, and techniques for high-performance and enhanced security. 41. List related means, techniques, and measures to enhance testability, reviewability, and feedbackability. 42. List related means, techniques, and measures to ensure a secure upgrade, evolution, change, growth, and development. 43. Explain priorities, use cases, potential pitfalls, error-prone points, and best practices (dos and don'ts). 44. Clarify the specific ways of implementing laws, regulations, principles, and design, providing a comparative pros and cons analysis of each implementation. 45. List the most crucial and concrete tasks for putting related theory into practice, in order of significance or temporal dependency. 46. Clarify the most crucial reasons for adoption, in descending order of significance. 47. Clarify the most crucial resources for adoption, in descending order of cost. 48. Estimate phase-based resources and costs across the lifecycle. 49. Clarify the requirements and adaptations for organizational structure, corporate culture, enterprise system, talent echelon, workflow, business architecture, business processes. 50. Clarify involved important general, strategic, and technical decision-making activities separately, providing both qualitative and and quantitative guidelines for each. 51. Clarify cause-and-effect relationships, using symbols like '<-verb(s)-', '-verb(s)->', and '<-verb(s)->'. 52. Clarify interdependency relationships, using symbols like '<-verb(s)-', '-verb(s)->', and '<-verb(s)->'. 53. Clarify cardinality-based relationships (1:1, 1:M, M:N). 54. Clarify contradictory relationships, using symbols like '<-verb(s)-', '-verb(s)->', and '<-verb(s)->'. 55. Clarify important sequential/temporal relationships. 56. Clarify hierarchical (classification) relationship; 57. Describe the existing non-trivial problems and potential approaches to address them. 58. Introduce the relevant research topics of significant value that remain to be overcome. 59. Introduce the possible directions and approaches of within-domain and cross-domain innovation. 60. Predict the ultimate form of the related development. 61. Make a summary table at the end with purposes, characteristics, use cases, ect. for clarity. 62. Append the terminologies, formulas, and analogies at the end with concise descriptions for each item. 63. Provide complete outputs; no content missed or truncated.

Mon Jun 23 2025

### Core Elements, Components, Factors, and Aspects of Large AI Models

Large AI models can be logically classified into three primary types: Large Language Models (LLMs), Large Vision Models (LVMs), and Large Multi-modal Models (LMMs), each differentiated by the data they process and the tasks they perform. Core components include a Transformer-based architecture, massive parameter counts (ranging from millions to trillions), diverse training datasets, and advanced training techniques, such as self-supervised learning and reinforcement learning from human feedback (RLHF). These elements collectively enable the models to generalize, generate, and reason across modalities.

### Concepts, Definitions, Functions, Purposes, and Characteristics

A large AI model is a neural network, predominantly based on the Transformer architecture, that acquires general-purpose skills from pre-training on enormous, variably sourced datasets. LLMs, for instance, are trained on textual data to perform tasks such as language generation, translation, summarization, and question answering. LVMs process visual data, enabling object recognition, segmentation, and image captioning. LMMs integrate text, vision, and sometimes audio, tackling tasks that require cross-modal understanding.

The main functions and purposes include:
1. Generalization and multitask adaptation (zero- and few-shot learning).
2. Representation learning for rich, modality-integrated embeddings.
3. Generation of coherent outputs such as text, images, or code.
4. Reasoning and decision support for complex domains.
5. Alignment to human values through RLHF and prompt engineering.

Notable characteristics are massive scalability, emerging abilities with increased size, flexibility via fine-tuning, and challenges like interpretability and robustness.

### Most Crucial Functions, Purposes, and Characteristics (Ordered)

1. **Generalization (Zero/Few-shot Learning):** The ability to perform unseen tasks with minimal examples.
2. **Knowledge Integration (Multimodality):** Unified processing of varied data types for holistic understanding.
3. **Content Generation:** Automated synthesis of text, images, or code tailored to prompts.
4. **Reasoning & Decision Support:** Stepwise and contextual problem-solving capabilities.
5. **Adaptability & Robustness:** Customization for domain-specific tasks via fine-tuning or prompt engineering.
6. **Safety, Alignment, & Privacy:** Ensuring trustworthy, aligned, and privacy-preserving interactions.

### Phase-Based Core Evaluation Dimensions

A MECE phase-based evaluation framework:

1. **Pre-training Phase**
   - Measurements: Loss convergence, representation diversity, unsupervised benchmarking.
   - Conclusions: Confirms effective large-scale pattern capture.
   - Evidence: Training logs, loss curves, diversity metrics.

2. **Fine-tuning/Adaptation Phase**
   - Measurements: Task accuracy (e.g., F1, BLEU), adaptability, domain transfer.
   - Conclusions: Measures domain readiness and transfer strength.
   - Evidence: Benchmark datasets, task-specific leaderboards.

3. **Deployment Phase**
   - Measurements: Latency, robustness, safety, reliability, energy consumption.
   - Conclusions: Assesses readiness for real-world application.
   - Evidence: System logs, continuous monitoring, user feedback loops.

### Principles of Significance, Logic, and Quality

- **Significance:** Impact across industries due to versatility and automation.
- **Logic (Validity/Consistency/Soundness):** Models use probabilistic statistical inference, benefiting from prompt-based logical scaffolding, but sometimes lack formal rigor and exhibit hallucinations.
- **Clarity/Precision/Accuracy:** Explainable AI and human evaluation enhance output clarity and precision.
- **Relevancy:** Proper prompt design and context-aware retrieval ensure output relevance.
- **Credibility/Reliability:** Reliability is bolstered by benchmarking and continuous monitoring; credibility aligns with minimization of bias and alignment errors.
- **Depth/Width:** Large models demonstrate both deep and wide task generalization, but depth of reasoning remains an ongoing challenge.
- **Practicality/Fairness/Sufficiency:** Real-world deployment considerations stress both efficiency and fairness, with fairness frameworks evaluating societal and demographic impacts.

### Simplicity, Flexibility, Adaptability, and Timeliness

- **Simplicity:** Modular architecture and clear API interfaces promote usability.
- **Flexibility:** Fine-tuning and prompt engineering expand applicability.
- **Adaptability:** Retaining capacity for domain adaptation and updating ensures long-term utility.
- **Punctuality/Timeliness/Urgency:** Optimized inference pipelines and real-time data integration allow prompt responses for critical applications.

### Creative Thinking Techniques and Skills (Scenarios)

1. **Prompt Engineering:** Generating multiple solutions iteratively and selecting the best output.
2. **Associative Thinking:** Encouraging analogical reasoning by connecting disparate concepts for creative synthesis.
3. **Divergent Idea Generation:** Engaging models in brainstorming tasks and then converging by ranking or refining outputs.
4. **Multi-Modal Dialogue:** Employing models to interpret or generate across different data types, mimicking human brainstorming.

### Clarification of Assumptions

- **Value:** Training data reflects human values and biases, requiring alignment mechanisms.
- **Descriptive:** Models posit that pattern recognition in large datasets equates to language understanding.
- **Prescriptive:** Expected to behave ethically and responsibly by design, yet limited by training scope.
- **Worldview:** Outputs are shaped by cultural and context biases in data.
- **Cause-and-Effect:** Model inferences are based on observed correlations, not true causality, resulting in hallucinations.

### Logic, Argument, and Reasoning Structures (with Critical Evaluation)

Logic is constructed via probabilistic pattern recognition, highly dependent on prompt design and context. Structured reasoning can be enhanced through stepwise prompting ("chain-of-thought"), but logical consistency is not guaranteed. Using Universal Intellectual Standards:
- **Clarity & Precision**: Improved by asking for explicit explanations.
- **Relevance**: Maintained with context-anchored prompts.
- **Soundness & Consistency**: Remain limitations; outputs can appear confident but incorrect, indicated by hallucinations or reasoning breakdowns.
- **Depth and Breadth**: Models demonstrate considerable width but variable depth, especially in multi-step and abstract reasoning.
- **Fairness**: Bias mitigation protocols are necessary but imperfect.

### Market, Ecosystem, and Economic Models

The AI market is characterized by rapid evolution and concentration around foundation model providers such as OpenAI, Google, Meta, and Anthropic. The ecosystem comprises cloud providers, compute firms, data suppliers, and end users. Economic strategies include:
- API access and tiered subscriptions.
- Enterprise licensing and custom fine-tuning.
- Open-source distribution and innovation in niche market verticals.
Revenue derives from value-added services, enterprise solutions, and vertical integration.

### Industry Regulations and Standards

Major regulatory frameworks differ by region:
- **European Union (EU):** The AI Act mandates risk-based requirements, with robust transparency, safety, and explainability stipulations.
- **United States:** More decentralized; emphasizes innovation over uniform standards.
- **China:** Prioritizes content safety, data control, and algorithmic regulation.
- Harmonized technical benchmarks and reporting standards emerge as models proliferate globally.

### Product Development Across Lifecycle Phases

1. **Market Investigation:** Analyze needs, trends, and regulations.
2. **Requirements Analysis:** Elicit performance and regulatory criteria from stakeholders.
3. **Design:** Architect scalable, modular systems.
4. **Development:** Train, fine-tune, and validate AI models.
5. **End-to-End Testing:** Evaluate across accuracy, robustness, safety, and fairness dimensions.
6. **Delivery:** Deploy with MLOps pipelines and ensure regulatory compliance.
7. **Operation/Maintenance:** Monitor, update, and improve in response to drift or incidents.

### 5P Marketing Strategy

| 5P Dimension | Activities and Strategies                              |
|--------------|-------------------------------------------------------|
| Product      | Position unique features (e.g., multimodality, scale) |
| Price        | Tiered API, subscription, and enterprise models       |
| Promotion    | Webinars, demos, expert talks, case studies           |
| Place        | Cloud platforms, on-premises, or hybrid deployments   |
| People       | Upskill teams, engage with domain experts             |

### Work Mechanism and Phase-Based Lifecycle

Work mechanism: Data (text, images, audio) are fed into a Transformer-based architecture, where attention mechanisms capture contextual relationships. Outputs are generated in response to user prompts or application calls. The phase-based workflow spans from data collection and pre-training to testing, deployment, and continual feedback-driven improvement.

### Preconditions, Inputs, Outputs, and Value

- **Preconditions:** Requires large, high-quality datasets, substantial computational infrastructure, and clear ethical/legal frameworks.
- **Inputs:** Structured/unstructured text, images, multimodal data; user prompts.
- **Outputs:** Generated content, predictions, decisions, summaries, or cross-modal artifacts.
- **Immediate Outcomes:** Task automation, insight generation, and procedural acceleration.
- **Value-Added Outcomes:** Productivity gains, enhanced decision-making, cost reduction.
- **Long-term Impacts:** Sector transformation, economic growth, and societal change; concerns over bias, hallucination, and trust.
- **Potential Implications:** Public trust management, privacy, safety, and regulatory adaptation.

### Underlying Laws, Axioms, and Theories

- **Scaling Laws:** Predictable improvements as model and data size grow, with diminishing but continuous returns.
- **Optimization Theories:** Underpin hyperparameter tuning and training stability.
- **Information Theory:** Guides representation learning and compression.
- **Deep Learning Generalization Theories:** Explain overparameterization benefits and risks.

### Structure, Architecture, and Patterns

- **Structure:** Deep Transformer networks with multi-head self-attention, feedforward layers, and positional encoding.
- **Patterns:** Early layers extract raw features, deep layers integrate semantics, and output layers produce predictions or generations.
- **Multimodal Integration:** Embedding layers and cross-attention for fusion.

### Design Philosophy and Architectural Features

- Emphasis on scalability (massive parameter scaling), modularity, and dynamic routing for context and task adaptation.
- Flexibility to support multi-modal, real-time, or domain-specialized deployments.
- Incorporation of memory, feedback, and explainability elements.

### Architectural Refactoring and Evolution

Techniques:
- Modularization for scalability and maintainability.
- Parameter-efficient fine-tuning, such as adapters or LoRA.
- Model editing networks (e.g., MEND) for rapid, localized updates.
- Automated code refactoring using AI-driven tools.

### Static and Dynamic Analysis Tools

- **Static:** CodeQL, Bandit, PyT, Semgrep for code-level vulnerability detection.
- **Dynamic:** OWASP ZAP, runtime monitoring for deployed models, fuzzing tools.
- **Specialized:** DeVAIC for AI-generated code security gaps.

### Frameworks, Models, and Principles

Frameworks include:
- **Development:** Scalable Transformer pipelines for distributed training.
- **Evaluation:** Comprehensive benchmarks covering accuracy, safety, fairness, and robustness (HELM, BigBench).
- **Safety/Alignment:** RLHF, constitutional AI, and continuous red-teaming.
- **Resource Efficiency:** Memory optimization techniques such as ZeRO and mixed-precision training.

### Origins, Evolution, and Trends

- **Origins:** Early rule-based systems and statistical models.
- **Evolution:** Transformer introduction in 2017, scaling in parameters/data, open-source model proliferation, and integration of multi-modality.
- **Trends:** Efficient hardware, algorithmic innovation, ecosystem complexity, responsible AI, and new regulatory challenges.

### Macro-Environmental Influences

Policy (EU AI Act, US innovation emphasis), military/critical infrastructure interests, economic capacity (cost of compute), cultural context (data and trust variations), and legal compliance (privacy, transparency requirements) all condition model development and deployment.

### Historical Events, Incidents, Statistical Insights

Notable events: Introduction of GPT-3 (175B parameters), ChatGPT/LLM public deployment, AlphaGo’s success, and high-profile security incidents like prompt attacks, privacy leaks, and model hallucinations. Statistical insights reveal non-linear returns with parameter scaling and persistent resource bottlenecks.

### Root Causes and Mechanisms of Incidents

- **Root causes:** Data bias, noisy or uncurated datasets, emergent capabilities from overparameterization, and adversarial vulnerabilities.
- **Development:** Model training and deployment processes can propagate or amplify errors.
- **Significance:** Security, trustworthiness, and societal impact are at stake.
- **Response:** Layered mitigation (technical, operational, policy) and increasing industrial/international coordination.

### Phase-Based Techniques, Approaches, and Algorithms

- **Parallelization:** Data, tensor, and pipeline parallelism.
- **Memory Optimization:** ZeRO, mixed-precision, and dynamic scheduling.
- **Evaluation and Safety:** Automated testing, red-teaming, robust monitoring, RLAIF feedback.

### Contradictions and Trade-Offs

- **Scale vs. efficiency:** Larger models offer better generalization but increase computation/energy cost.
- **Accuracy vs. fairness:** Maximizing accuracy may compromise fairness or introduce bias.
- **Safety vs. capability:** Overly constrained models may sacrifice helpfulness or creativity.

### Major Competitors and SWOT

| Competitor | Strengths                   | Weaknesses                   | Opportunities                      | Threats                        |
|------------|-----------------------------|-------------------------------|-------------------------------------|--------------------------------|
| OpenAI     | Scale, generalization, API  | Resource-intense, privacy     | Industry leader, partnerships       | Regulatory scrutiny            |
| Google     | Multimodal, research depth  | Commercial focus             | AI/Cloud integration                | Data privacy concerns          |
| Meta       | Open-source, multilingual   | Scale, safety                 | Community-driven innovation         | Market competition             |
| Anthropic  | Alignment focus, safety     | Smaller scale, funding        | Governance, ethical leadership      | Rapid tech changes             |

### Concrete Advantages/Disadvantages

**Pros:** Generalization, versatility, automation, creativity, broad economic value.
**Cons:** High compute cost, privacy risks, alignment challenges, interpretability issues, environmental impact.

### Principles, Constraints, Limitations, and Risks

- Memory/compute bottlenecks, interpretability limits, and privacy constraints persist across all phases.
- Model attacks and hallucinations remain risks, requiring ongoing mitigation and real-time monitoring.

### Security Vulnerabilities and Mitigations

- Prompt injection, adversarial and data poisoning attacks, privacy leaks, and model theft.
- Troubleshooting includes adversarial testing, prompt sanitation, RLHF, model watermarking, and incident response protocols.

### Error Propagation and Handling

Errors compound across layers due to model non-linearities; regularization, adversarial training, and calibration can mitigate cascading failures.

### Performance Bottlenecks and Optimization

Memory and compute resource constraints, communication overhead, and inefficient training protocols are primary bottlenecks. Optimization involves mixed-precision, parallelism, and distributed training frameworks.

### Practical Designs/Techniques for Performance and Security

- Containerization, memory-efficient optimizers, adversarial training, cryptographic safeguards, and systematic monitoring.

### Means to Enhance Testability, Reviewability, Feedbackability

- Automated test generation, coverage analysis, explainable AI techniques, robust feedback loops, and iterative fine-tuning.

### Secure Upgrade, Evolution, and Development

- Tamper-resistant protocols, incremental model versioning, formal verification, and continuous red-teaming facilitate safe growth.

### Priorities, Use Cases, Pitfalls, and Best Practices

Priorities: Robustness, safety, efficiency, adaptability, and ethical alignment.
Pitfalls: Hallucinations, biases, security gaps, privacy leaks, overconfidence.
Best practices: Iterative evaluation, transparent documentation, continuous monitoring, Adherence to regulations, and inclusive stakeholder engagement.

### Law, Regulation, Principle Implementation (Comparative Analysis)

- Legislative frameworks ensure enforceability but may slow innovation and favor large entities.
- Industry self-regulation fosters agility but risks inconsistency and weak enforcement.

### Core Practice Tasks (Temporal/Significance-Driven)

1. Data acquisition and curation.
2. Infrastructure and resource allocation.
3. Model design, training, and fine-tuning.
4. Evaluation and safety alignment.
5. Deployment and monitoring.
6. Ongoing operation, governance, and iteration.

### Reasons for Adoption (Descending)

1. Superior performance and generalization.
2. Multimodal capability and efficiency.
3. Reduced annotation effort, scalability.
4. Market competitiveness and potential for innovation.

### Lifecycle Resource and Cost Estimation

- Greatest costs: AI hardware, expert staff, server infrastructure, energy, and ongoing operations.
- Cost distribution varies by phase, with development/training being most intensive.

### Organizational, Structural, Cultural, and System Adaptations

- Flexible, interdisciplinary teams; transparent, innovation-oriented culture; scalable architecture; balanced talent mix; workflow automation; modular business infrastructure; continuous ethical/process integration.

### Decision-Making Activities (Categorized)

- General: Day-to-day operations, data selection.
- Strategic: AI capability expansion, market analysis.
- Technical: Architecture choices, optimization, evaluation metrics.

### Causality, Interdependency, Cardinality, and Contradiction Notation

- Example: InputData -influences-> ModelPrediction.
- Modular structure <-> flexibility.
- Token -relates to-> Multiple outputs (1:M cardinality).
- Safety constraints <-conflicts with-> Model helpfulness.

### Sequential/Hierarchical Relationships

- Structured, iterative phases from data to deployment, with hierarchical task decomposition for fine-to-coarse decisions.

### Non-Trivial Problems and Research Frontiers

- Hallucination and reasoning failures, safety/alignment gaps, privacy vulnerabilities, resource bottlenecks, explainability deficits.
- Ongoing research: scalability, interpretability, robustness, fairness, multimodality, continuous learning, privacy, and sustainability.

### Within-Domain and Cross-Domain Innovation

- Advances in architectures, data integration, safety, multimodal learning, hybrid symbolic-neural systems, and eco-sustainable practices.

### Ultimate Form Prediction

- Generalized, multimodal, efficient, self-evolving, ethically aligned AI systems capable of cross-domain problem solving and continuous adaptation.

### Summary Table

| Aspect      | Description                                   |
|-------------|-----------------------------------------------|
| Purposes    | Generalization, generation, reasoning         |
| Characteristics | Scale, diversity, modularity, low interpretability |
| Use Cases   | NLP, vision, multi-modal, scientific domains  |
| Components  | Transformers, attention, layers, huge datasets|
| Evaluation  | Pre-training loss, task performance, robustness|
| Challenges  | Scale, biases, cost, alignment, security      |
| Market      | API access, subscriptions, enterprise sales   |

### Key Terminologies, Formulas, and Analogies

- **Large Language Model (LLM):** A neural network for language understanding and generation, typically Transformer-based.
- **Transformer:** Neural architecture utilizing self-attention for context modeling.
- **Prompt Engineering:** Crafting inputs for desired outputs.
- **Scaling Law:** Performance increases with model/data/compute growth.
- **Analogy:** Large AI models operate as vast, adaptive factories, taking in data, processing via SOPs (model layers/transformers), and yielding tailored products (text, images, insights).

---
This comprehensive, MECE-compliant report is designed to demonstrate a complete, structured, and critical understanding of large AI models for a job interview context.

Bibliography
01.AI Alex Young, Bei Chen, Chao Li, Chengen Huang, Ge Zhang, Guanwei Zhang, Heng Li, Jiangcheng Zhu, Jianqun Chen, Jing Chang, Kaidong Yu, Peng Liu, Qiang Liu, Shawn Yue, Senbin Yang, Shiming Yang, Tao Yu, Wen Xie, Wenhao Huang, … Zonghong Dai. (2024). Yi: Open Foundation Models by 01.AI. In ArXiv. https://arxiv.org/abs/2403.04652

A Aamodt & M Nygård. (1995). Different roles and mutual dependencies of data, information, and knowledge—An AI perspective on their integration. In Data & Knowledge Engineering. https://www.sciencedirect.com/science/article/pii/0169023X9500017M

A. Abuzaid & Majida Khalaf Khaleel Alsbou. (2024). AI and Entrepreneurship: Enablers, Obstacles, and Startups’ Role in Shaping the Future Economy. In 2024 International Conference on Knowledge Engineering and Communication Systems (ICKECS). https://ieeexplore.ieee.org/document/10616645/

A. Akkasi & Marie-Francine Moens. (2021). Causal relationship extraction from biomedical text using deep neural models: A comprehensive survey. In Journal of biomedical informatics. https://linkinghub.elsevier.com/retrieve/pii/S1532046421001490

A. Baruno, Meithiana Indrasari, & Agustiawan Djoko. (2025). Leveraging AI To Enhance Green Marketing Strategies. In Jurnal Ekonomi, Manajemen, Akuntansi dan Keuangan. https://www.semanticscholar.org/paper/fddd25294e843838a735092d5d08e1bdc3744ba3

A. Bengtson, Virpi Havila, & Susanne Åberg. (2001). Network Dependencies and Project Termination: Why some relationships survive the end of a project. https://www.semanticscholar.org/paper/d967a6ecddbb79247f34af54f3b503f331887ace

A Bewersdorff, K Seßler, A Baur, & E Kasneci. (2023). Assessing student errors in experimentation using artificial intelligence and large language models: A comparative study with human raters. https://www.sciencedirect.com/science/article/pii/S2666920X23000565

A Chou & LH Shu. (2015). Using analogies to explain versus inspire concepts. In AI EDAM. https://www.cambridge.org/core/journals/ai-edam/article/using-analogies-to-explain-versus-inspire-concepts/990EE1E833938CDDF852EC1D85E0CA48

A Faqihi & SJ Miah. (2023). Artificial intelligence-driven talent management system: Exploring the risks and options for constructing a theoretical foundation. In Journal of Risk and Financial Management. https://www.mdpi.com/1911-8074/16/1/31

A. Gholami, Z. Yao, Sehoon Kim, Coleman Hooper, Michael W. Mahoney, & Kurt Keutzer. (2024). AI and Memory Wall. In IEEE Micro. https://ieeexplore.ieee.org/document/10477550/

A. Joshi. (1997). Relationship between natural language processing and AI. In International Joint Conference on Artificial Intelligence. https://www.semanticscholar.org/paper/bf82e29f308ba7659d6621bf536760cb6d3e1477

A Kittur, L Yu, T Hope, J Chan, & H Lifshitz-Assaf. (2019). Scaling up analogical innovation with crowds and AI. https://www.pnas.org/doi/abs/10.1073/pnas.1807185116

A Korinek & J Vipra. (2025). Concentrating intelligence: scaling and market structure in artificial intelligence. In Economic Policy. https://academic.oup.com/economicpolicy/article-abstract/40/121/225/7905140

A Kyrychenko & Z Stezhko. (2024). The principle of contradiction in scientific and pedagogical research on AI (methodological aspect). http://fps-visnyk.lnu.lviv.ua/archive/53_2024/11.pdf

A Marrone. (2023). Optimizing Product Development and Innovation Processes with Artificial Intelligence. https://webthesis.biblio.polito.it/27710/

A Mastroianni. (2022). Design and AI revolution: the impact of large language models in the early stages of the design process. https://www.politesi.polimi.it/handle/10589/219075

A Paleyes, RG Urma, & ND Lawrence. (2022). Challenges in deploying machine learning: a survey of case studies. In ACM computing surveys. https://dl.acm.org/doi/abs/10.1145/3533378

A. Pfitzner & H. Lutz. (1993). The systems CuCl-MIICl2 (M = Mn, Cd) – crystal structures of Cu2MnCl4 and γ-CuCl. In Zeitschrift Fur Kristallographie. https://www.semanticscholar.org/paper/eb8dde89a387ca5a65a1458f57019d6bd56e94a7

A. Samareh & Mahshid Salemi Parizi. (2019). How Effectively Train Large-Scale Machine Learning Models? In Optimization in Large Scale Problems. https://link.springer.com/chapter/10.1007/978-3-030-28565-4_14

A Vassiliades, N Bassiliades, & T Patkos. (2021). Argumentation and explainable artificial intelligence: a survey. https://www.cambridge.org/core/journals/knowledge-engineering-review/article/argumentation-and-explainable-artificial-intelligence-a-survey/DC6841ED8C7A80DC9EFADF87E4558A1F

A. Veevers & K. A. Davies. (1985). Credibility as a Quantification of Software Reliability. In International Journal of Quality & Reliability Management. https://www.semanticscholar.org/paper/c2d2a62d5763dbeb58fe431bd094e94223c03be2

AA Rustamovich. (2024). COMPARATIVE LEGAL STUDY OF AI IMPLEMENTATION IN THE JUDICIAL SPHERE FOR A LONG-TERM PERIOD. In UAE–RUSSIA–INDIA. http://ran-nauka.ru/wp-content/uploads/2024/02/Practice-Oriented-Science-January-31-Part-1.pdf#page=39

Abi Aryan, Aakash Kumar Nain, Andrew McMahon, Lucas Augusto Meyer, & Harpreet Sahota. (2023). The Costly Dilemma: Generalization, Evaluation and Cost-Optimal Deployment of Large Language Models. In ArXiv. https://www.semanticscholar.org/paper/b946f3ee813aa671aff7db0a0c840049acb83662

Adam Dahlgren Lindstrom, Leila Methnani, Lea Krause, Petter Ericson, ’Inigo Mart’inez de Rituerto de Troya, Dimitri Coelho Mollo, & Roel Dobbe. (2024). AI Alignment through Reinforcement Learning from Human Feedback? Contradictions and Limitations. In ArXiv. https://arxiv.org/abs/2406.18346

Adhishree Kathikar, Aishwarya Nair, Ben Lazarine, Agrim Sachdeva, & Sagar Samtani. (2023). Assessing the Vulnerabilities of the Open-Source Artificial Intelligence (AI) Landscape: A Large-Scale Analysis of the Hugging Face Platform. In 2023 IEEE International Conference on Intelligence and Security Informatics (ISI). https://www.semanticscholar.org/paper/e9270f790459c84c3d16e2bb29bd1ab311ec5c78

Aditi Singh. (2023). A Survey of AI Text-to-Image and AI Text-to-Video Generators. In 2023 4th International Conference on Artificial Intelligence, Robotics and Control (AIRC). https://ieeexplore.ieee.org/document/10303174/

Agathe Balayn, Natasa Rikalo, Jie Yang, & A. Bozzon. (2023). Faulty or Ready? Handling Failures in Deep-Learning Computer Vision Models until Deployment: A Study of Practices, Challenges, and Needs. In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. https://dl.acm.org/doi/10.1145/3544548.3581555

Ahmed Menshawy, Zeeshan Nawaz, & Mahmoud Fahmy. (2024). Navigating Challenges and Technical Debt in Large Language Models Deployment. In Proceedings of the 4th Workshop on Machine Learning and Systems. https://www.semanticscholar.org/paper/a405b73b0e68ae5a94482a792f85240ebc532b29

Ailien Liu. (2024). AI techniques in board game: A survey. In Applied and Computational Engineering. https://www.semanticscholar.org/paper/5ea373999128a11dc80b6031c4e6dd4651a7f0e0

Aishan Liu, Xianglong Liu, Jun Guo, Jiakai Wang, Yuqing Ma, Zehao Zhao, Xing Gao, & Gang Xiao. (2021). A Comprehensive Evaluation Framework for Deep Model Robustness. In Pattern Recognit. https://linkinghub.elsevier.com/retrieve/pii/S0031320323000092

Ajay Bandi & Hemanth Kagitha. (n.d.). A Case Study on the Generative AI Project Life Cycle Using Large Language Models. In EPiC Series in Computing. https://www.semanticscholar.org/paper/66ddaeb00d068f4309954408a5ebd3ac4d85fe57

Akshat Dubey, Zewen Yang, & Georges Hattab. (2024). A nested model for AI design and validation. In iScience. https://linkinghub.elsevier.com/retrieve/pii/S2589004224018285

Akwi Helene Fomude, Chaoyu Yang, George Kofi Agordzo, Appiah Vincentia Serwah, & Linda Abangbila. (2023). AI Model to Improve HR Decision-Making with Machine Learning Predictions Algorithm. In 2023 25th International Conference on Advanced Communication Technology (ICACT). https://www.semanticscholar.org/paper/155400c35b04cc426eeada4c4293a8f3e3c19879

Alaa Fkirin, Ahmed Samy AbdElAziz Moursi, G. Attiya, Ayman El-Sayed, & M. Shouman. (2024). Hybrid two-level protection system for preserving pre-trained DNN models ownership. In Neural Comput. Appl. https://www.semanticscholar.org/paper/c73fa3ecc7d296671fc3d37f41f500b6ebd58c6b

Alberto García-Durán, Antoine Bordes, & Nicolas Usunier. (2014). Blending of Two and Three-way Interactions for Modeling Multi-relational Data. https://www.semanticscholar.org/paper/fd3521542acbd3d9d23dd5543e32ef9f70f0782d

Alejandro Duque, Abdullah Syed, Kastan Day, Matthew Berry, Daniel S. Katz, & Volodymyr V. Kindratenko. (2023). Leveraging Large Language Models to Build and Execute Computational Workflows. In ArXiv. https://www.semanticscholar.org/paper/48af8b4abe102a9efad47f93910d3b4bdddeb242

Alex Tamkin, Miles Brundage, Jack Clark, & Deep Ganguli. (2021). Understanding the Capabilities, Limitations, and Societal Impact of Large Language Models. In ArXiv. https://www.semanticscholar.org/paper/f577654d9dd29d88c6db9ee39a4fd831573b8770

AM Saghiri, SM Vahidipour, & MR Jabbarpour. (2022). A survey of artificial intelligence challenges: Analyzing the definitions, relationships, and evolutions. In Applied sciences. https://www.mdpi.com/2076-3417/12/8/4054

Amin Dada, Aokun Chen, C.A.I. Peng, Kaleb E. Smith, Ahmad Idrissi-Yaghir, Constantin Seibold, Jianning Li, Lars Heiliger, Xi Yang, Christoph M. Friedrich, Daniel Truhn, Jan Egger, Jiang Bian, J. Kleesiek, & Yonghui Wu. (2023). On the Impact of Cross-Domain Data on German Language Models. In ArXiv. https://www.semanticscholar.org/paper/b1ece182d4934dfc629ca409ef78e56c1762965c

Anand Tamboli. (2019). Evaluating Risks of the AI Solution. In Keeping Your AI Under Control. https://link.springer.com/chapter/10.1007/978-1-4842-5467-7_4

Angela Fan, Beliz Gokkaya, Mark Harman, Mitya Lyubarskiy, Shubho Sengupta, Shin Yoo, & Jie M. Zhang. (2023). Large Language Models for Software Engineering: Survey and Open Problems. In 2023 IEEE/ACM International Conference on Software Engineering: Future of Software Engineering (ICSE-FoSE). https://ieeexplore.ieee.org/document/10449667/

Aniya Aggarwal, Samiullah Shaikh, Sandeep Hans, Swastik Haldar, Rema Ananthanarayanan, & Diptikalyan Saha. (2021). Testing Framework for Black-box AI Models. In 2021 IEEE/ACM 43rd International Conference on Software Engineering: Companion Proceedings (ICSE-Companion). https://ieeexplore.ieee.org/document/9402329/

Ankit Gupta, Harsh Mehta, & Jonathan Berant. (2022). Simplifying and Understanding State Space Models with Diagonal Linear RNNs. In ArXiv. https://arxiv.org/abs/2212.00768

Ankur Padia, Francis Ferraro, & Tim Finin. (2024). Enhancing Knowledge Graph Consistency through Open Large Language Models: A Case Study. In AAAI Spring Symposia. https://www.semanticscholar.org/paper/df8d276e757db58a5f3aa461d84de0e1eda3f35d

Anthony Gatera. (2024). Role of Artificial Intelligence in Revenue Management and Pricing Strategies in Hotels. In Journal of Modern Hospitality. https://www.semanticscholar.org/paper/a6fe8495c32c8ab23839558ca59d40f43299aeed

Arno Candel, Jon McKinney, Philipp Singer, Pascal Pfeiffer, Maximilian Jeblick, Chun Ming Lee, & Marcos V. Conde. (2023). H2O Open Ecosystem for State-of-the-art Large Language Models. In ArXiv. https://arxiv.org/abs/2310.13012

Arshdeep Sekhon, Zhe Wang, & Yanjun Qi. (2021). Relate and Predict: Structure-Aware Prediction with Jointly Optimized Neural DAG. In ArXiv. https://www.semanticscholar.org/paper/c4ef69a3d6ac100db80ea3badc7f98d60b5de505

AU Patel, N Shaker, S Mohanty, S Sharma, & S Gangal. (2022). Cultivating clinical clarity through computer vision: a current perspective on whole slide imaging and artificial intelligence. In Diagnostics. https://www.mdpi.com/2075-4418/12/8/1778

Aysan Esmradi, Daniel Wankit Yip, & C. Chan. (2023). A Comprehensive Survey of Attack Techniques, Implementation, and Mitigation Strategies in Large Language Models. In International Conference on Ubiquitous Security. https://arxiv.org/abs/2312.10982

B Ahmad & JJ Nieto. (2009). Existence of Solutions for Nonlocal Boundary Value Problems of Higher‐Order Nonlinear Fractional Differential Equations. In Abstract and Applied Analysis. https://onlinelibrary.wiley.com/doi/abs/10.1155/2009/494720

B Chander, C John, & L Warrier. (2025). Toward trustworthy artificial intelligence (TAI) in the context of explainability and robustness. https://dl.acm.org/doi/abs/10.1145/3675392

B Coeuré. (2025). The competitive dynamics of generative artificial intelligence. In Journal of Antitrust Enforcement. https://academic.oup.com/antitrust/advance-article-abstract/doi/10.1093/jaenfo/jnaf002/7978249

B. Espinasse, S. Fournier, Adrian-Gabriel Chifu, Gaël Guibon, René Azcurra, & Valentin Macé. (2019). On the Use of Dependencies in Relation Classification of Text with Deep Learning. In Conference on Intelligent Text Processing and Computational Linguistics. https://www.semanticscholar.org/paper/ca42e680357de7b7e6cfa464bd2e012464609edd

B Jarinaa & M Manida. (2023). A Study on Pros and Cons of AI Technology Used Agri Farming in Tamil Nadu. https://www.researchgate.net/profile/Dr-Mmanida/publication/377729322_A_Study_on_Pros_and_Cons_of_AI_Technology_Used_Agri_Farming_in_Tamil_Nadu/links/65b4add079007454973bff21/A-Study-on-Pros-and-Cons-of-AI-Technology-Used-Agri-Farming-in-Tamil-Nadu.pdf

B Mittelstadt, C Russell, & S Wachter. (2019). Explaining explanations in AI. https://dl.acm.org/doi/abs/10.1145/3287560.3287574

B. Ulicny, C. Matheus, & M. Kokar. (2010). A Semantic Wiki Alerting Environment Incorporating Credibility and Reliability Evaluation. In Semantic Technologies for Intelligence, Defense, and Security. https://www.semanticscholar.org/paper/a112f227014d964bbe47761c25c12489d9458ccf

B. Wah & Guo-Jie Li. (1986). Survey on special purpose computer architectures for AI. In SIGART Newsl. https://dl.acm.org/doi/10.1145/15715.15718

B Zhang, T Liu, P Liang, & C Wang. (2023). Architecture decisions in AI-based systems development: an empirical study. https://ieeexplore.ieee.org/abstract/document/10123549/

Bart Verheij. (2009). The Toulmin Argument Model in Artificial Intelligence. In Argumentation in Artificial Intelligence. https://www.semanticscholar.org/paper/de2d71d24d77fd31c406b4113539411faa0c7627

Basile Lewandowski & Atli Kosson. (2023). Memory Efficient Mixed-Precision Optimizers. In ArXiv. https://arxiv.org/abs/2309.12381

Benji Peng, Ziqian Bi, Qian Niu, Ming Liu, Pohsun Feng, Tianyang Wang, Lawrence K.Q. Yan, Yizhu Wen, Yichao Zhang, & Caitlyn Heqi Yin. (2024). Jailbreaking and Mitigation of Vulnerabilities in Large Language Models. In ArXiv. https://arxiv.org/abs/2410.15236

BHA Khattak, I Shafi, AS Khan, & ES Flores. (2023). A systematic survey of AI models in financial market forecasting for profitability analysis. https://ieeexplore.ieee.org/abstract/document/10309124/

Bingbing Wen, Jihan Yao, Shangbin Feng, Chenjun Xu, Yulia Tsvetkov, Bill Howe, & Lucy Lu Wang. (2024). Know Your Limits: A Survey of Abstention in Large Language Models. https://www.semanticscholar.org/paper/314a471e8fa6788054e98aca1a74622f90fccbb9

Bingtao Han & ，刘涛 Liu. (n.d.). 大模型关键技术与应用 Key Technologies and Applications of Large Models. https://www.semanticscholar.org/paper/6b369fa145497b54da31682fbc45ac94399bb547

Bo Wang, Ke Dong, Nurul Akhira Binte Zakaria, Mohit Upadhyay, W. Wong, & L. Peh. (2022). Network-on-Chip-Centric Accelerator Architectures for Edge AI Computing. In 2022 19th International SoC Design Conference (ISOCC). https://ieeexplore.ieee.org/document/10031356/

Bor-Sung Liang. (2023). AI Computing in Large-Scale Era: Pre-trillion-scale Neural Network Models and Exa-scale Supercomputing. In 2023 International VLSI Symposium on Technology, Systems and Applications (VLSI-TSA/VLSI-DAT). https://www.semanticscholar.org/paper/5edced871273149766a517e1dbb0df6665528678

Boyuan Feng, Tianqi Tang, Yuke Wang, Zhaodong Chen, Zheng Wang, Shu Yang, Yuan Xie, & Yufei Ding. (2022). Faith: An Efficient Framework for Transformer Verification on GPUs. In ArXiv. https://arxiv.org/abs/2209.12708

Brendan Deakin. (2023). Best practices and important considerations for AI and digital transformation in an economic downturn. In Journal of Digital Banking. https://www.semanticscholar.org/paper/01b552e447d1f27c1a59776a594b0051b5188f6d

C. Boulton, L. Miniero, & Gary Munson. (2013). Media Resource Brokering. In RFC. https://www.semanticscholar.org/paper/a53f3521b589721b8bbf1565ebad699f3042ede1

C Boutilier, T Dean, & S Hanks. (1999). Decision-theoretic planning: Structural assumptions and computational leverage. In Journal of Artificial Intelligence Research. https://www.jair.org/index.php/jair/article/view/10237

C. Gallicchio, A. Micheli, & Antonio Sisbarra. (2020). Simplifying Deep Reservoir Architectures. In The European Symposium on Artificial Neural Networks. https://www.semanticscholar.org/paper/4c137e7e9f227d68f6ac879fb99465a095f0a0bf

C. Jennings, S. Cooley, & S. Nandakumar. (2017). Solution Architecture - Secure Firmware Upgrade (SecFU). https://www.semanticscholar.org/paper/bc56108b7ae1aa545241a651d7b5ead1fe0fac73

C Li. (2016). Cracking a hierarchical chaotic image encryption algorithm based on permutation. In Signal Processing. https://www.sciencedirect.com/science/article/pii/S0165168415002431

C. Martinie, Philippe A. Palanque, & M. Winckler. (2011). Structuring and Composition Mechanisms to Address Scalability Issues in Task Models. In IFIP TC13 International Conference on Human-Computer Interaction. https://www.semanticscholar.org/paper/92de8f23dc66bd3824d91d01f92cedb924d061fc

C. Tumma, Rahul Azmeera, Supraja Ayyamgari, & B. Thumma. (2025). Data Security and Privacy Protection in Artificial Intelligence Models: Challenges and Defense Mechanisms. In INTERANTIONAL JOURNAL OF SCIENTIFIC RESEARCH IN ENGINEERING AND MANAGEMENT. https://www.semanticscholar.org/paper/ecc7c62480bc3ee4cde06aa1263102855678f044

C Zhang, S He, J Qian, B Li, L Li, S Qin, & Y Kang. (2024). Large language model-brained gui agents: A survey. https://arxiv.org/abs/2411.18279

Cary R. Champlin. (1993). IRIDIUM satellite: A large system application of design for testability. In Proceedings of IEEE International Test Conference - (ITC). https://ieeexplore.ieee.org/document/470673/

Cathy Petrozzino & S. Shapiro. (2020). ACTIONABLE ETHICS FOR FAIRNESS IN AI. https://www.semanticscholar.org/paper/07ccfd095fd57d97290d4d78dd4359abb182a557

CC Jane, JS Lin, & J Yuan. (1993). Reliability evaluation of a limited-flow network in terms of minimal cutsets. In IEEE transactions on reliability. https://ieeexplore.ieee.org/abstract/document/257817/

Chen Ran. (2023). Exploring the Opportunities and Challenges of Developing Large AI Models and their Commercialization. In Advances in Engineering Technology Research. https://www.semanticscholar.org/paper/dea8ba68bca2a0a4418edbe5b627de2cab80593b

Chen Yang, Peng Liang, Liming Fu, & Zengyang Li. (2021). Self-Claimed Assumptions in Deep Learning Frameworks: An Exploratory Study. In Proceedings of the 25th International Conference on Evaluation and Assessment in Software Engineering. https://arxiv.org/abs/2104.14208

Christian A. Schiller. (2024). The Human Factor in Detecting Errors of Large Language Models: A Systematic Literature Review and Future Research Directions. In ArXiv. https://arxiv.org/abs/2403.09743

Christian Wagner & Ling Jiang. (2025). Death by AI: Will large language models diminish Wikipedia? In Journal of the Association for Information Science and Technology. https://www.semanticscholar.org/paper/adcb3aebae84401b8cb698e73832b3cd59b89707

Christina P. Walker, Danielle Schiff, & Kaylyn Jackson Schiff. (2024). Merging AI Incidents Research with Political Misinformation Research: Introducing the Political Deepfakes Incidents Database. In ArXiv. https://ojs.aaai.org/index.php/AAAI/article/view/30349

Chuang Li. (2008). An Analysis Model of Industrial International Competitiveness. In 2008 4th International Conference on Wireless Communications, Networking and Mobile Computing. https://ieeexplore.ieee.org/document/4680286/

Credibility in Information Retrieval. (2015). In Found. Trends Inf. Retr. https://www.semanticscholar.org/paper/f39c32723d4693278ffde32e1abc5f3f3370ea70

D Ali, MB Hayat, L Alagha, & OK Molatlhegi. (2018). An evaluation of machine learning and artificial intelligence models for predicting the flotation behavior of fine high-ash coal. In Advanced Powder Technology. https://www.sciencedirect.com/science/article/pii/S0921883118305922

D. Bobrow. (2005). AAAI: It’s Time for Large-Scale Systems. In AI Mag. https://www.semanticscholar.org/paper/55b069f1b6e87894e284c23bf83d0445d8a88f75

D. Engelmann, Juliana Damasio, Alison R. Panisson, V. Mascardi, & Rafael Heitor Bordini. (2022). Argumentation as a Method for Explainable AI : A Systematic Literature Review. In 2022 17th Iberian Conference on Information Systems and Technologies (CISTI). https://ieeexplore.ieee.org/document/9820411/

D Gentner & KD Forbus. (2011). Computational models of analogy. https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/wcs.105

D. Gupta, S. Kohail, & P. Bhattacharyya. (2018). Combining Graph-based Dependency Features with Convolutional Neural Network for Answer Triggering. In Conference on Intelligent Text Processing and Computational Linguistics. https://www.semanticscholar.org/paper/706600aa77ffb165097e4aeccb2b214dabdb8092

D Luitse & W Denkena. (2021). The great transformer: Examining the role of large language models in the political economy of AI. In Big Data & Society. https://journals.sagepub.com/doi/abs/10.1177/20539517211047734

D. Monroe. (2021). Trouble at the source. In Communications of the ACM. https://www.semanticscholar.org/paper/96709f0c0cd9a7e97dde6600da488670fc11a580

D. Narayanan, Mohammad Shoeybi, J. Casper, P. LeGresley, M. Patwary, V. Korthikanti, Dmitri Vainbrand, Prethvi Kashinkunti, Julie Bernauer, Bryan Catanzaro, Amar Phanishayee, Matei Zaharia, & Fiodar Kazhamiaka. (2021). Efficient Large-Scale Language Model Training on GPU Clusters. In ArXiv. https://www.semanticscholar.org/paper/77e73174e606c0820a52a940088832b32d9a033e

D. Partridge. (1992). The relationships of AI to software engineering. https://www.semanticscholar.org/paper/f7c56f7c66b015d478764a028d8fe62c4b4aa891

D Wu, M Chen, X Chen, & X Liu. (2024). Analyzing K-12 AI education: A large language model study of classroom instruction on learning theories, pedagogy, tools, and AI literacy. https://www.sciencedirect.com/science/article/pii/S2666920X24000985

D Zha, ZP Bhat, KH Lai, F Yang, & Z Jiang. (2025). Data-centric artificial intelligence: A survey. https://dl.acm.org/doi/abs/10.1145/3711118

Daechul Ahn, Yura Choi, Youngjae Yu, Dongyeop Kang, & Jonghyun Choi. (2024). Tuning Large Multimodal Models for Videos using Reinforcement Learning from AI Feedback. In Annual Meeting of the Association for Computational Linguistics. https://arxiv.org/abs/2402.03746

Darcy A. Davis, Ryan Lichtenwalter, & N. Chawla. (2012). Supervised methods for multi-relational link prediction. In Social Network Analysis and Mining. https://www.semanticscholar.org/paper/897611a1064d04d14fa78c3019ada488f0956c36

Daswin De Silva & D. Alahakoon. (2021). An artificial intelligence life cycle: From conception to production. In Patterns. https://linkinghub.elsevier.com/retrieve/pii/S2666389922000745

David Bamman, Kent K. Chang, Li Lucy, & Naitian Zhou. (2024). On Classification with Large Language Models in Cultural Analytics. In Workshop on Computational Humanities Research. https://arxiv.org/abs/2410.12029

Deep Ganguli, Danny Hernandez, Liane Lovitt, Nova Dassarma, T. Henighan, Andy Jones, Nicholas Joseph, John Kernion, Benjamin Mann, Amanda Askell, Yuntao Bai, Anna Chen, Tom Conerly, Dawn Drain, Nelson Elhage, S. E. Showk, Stanislav Fort, Zac Hatfield-Dodds, Scott Johnston, … Jack Clark. (2022). Predictability and Surprise in Large Generative Models. In Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency. https://www.semanticscholar.org/paper/a6f5b8f114b3eabbcd7f3f62091a481ca6f7f243

DH Liu. (2024). The Fundamental Theory of Artificial Intelligence—Logic Structure and Logic Engineering. In Intelligent Control and Automation. https://www.scirp.org/journal/paperinformation?paperid=131294

Dibyajyoti Chakraborty, Shivam Barwey, Hong Zhang, & R. Maulik. (2024). A note on the error analysis of data-driven closure models for large eddy simulations of turbulence. In ArXiv. https://arxiv.org/abs/2405.17612

Diego Marmsoler. (2018). On Syntactic and Semantic Dependencies in Service-Oriented Architectures. In 2018 International Symposium on Theoretical Aspects of Software Engineering (TASE). https://ieeexplore.ieee.org/document/8560743/

Divyanshu Kumar, Umang Jain, Sahil Agarwal, & P. Harshangi. (2024). Investigating Implicit Bias in Large Language Models: A Large-Scale Study of Over 50 LLMs. In ArXiv. https://arxiv.org/abs/2410.12864

Domenico Cotroneo, Roberta de Luca, & Pietro Liguori. (2024). DeVAIC: A Tool for Security Assessment of AI-generated Code. In Inf. Softw. Technol. https://www.semanticscholar.org/paper/a2d58458ac8956bb69ebb281b83b871cc48ee27b

Dong Xiaofei, Zhang Xueqiang, Zhang Dan, Cao Feng, & Bai Bingfeng. (2022). A Survey of Research Progress and Theory Foundation in Large Model. In 2022 IEEE 8th International Conference on Cloud Computing and Intelligent Systems (CCIS). https://www.semanticscholar.org/paper/272e77e2d4d69db2ef0160ef44f5e0abde03eaa6

Dr.V. Jalaja, Dr. Thejasvi Sheshadri, Dr.V.K. Arthi, Dr.S. Thilaga, Dr.J. Bamini, S. M. Basha, & M. Kethan. (2024). Maximizing Marketing Value: An Empirical Study on the Framework for Assessing AI and ML Integration in Marketing Management. In Indian Journal of Information Sources and Services. https://www.semanticscholar.org/paper/89bfa58bb067f90fbe421a81a384fe61c88ae56a

Dylan Manuel, Nafis Tanveer Islam, Joseph Khoury, Ana Nunez, Elias Bou-Harb, & Peyman Najafirad. (2024). Enhancing Reverse Engineering: Investigating and Benchmarking Large Language Models for Vulnerability Analysis in Decompiled Binaries. In ArXiv. https://www.semanticscholar.org/paper/aed79c89e00a275220fad36d68977a599e6dfed4

E. Mitchell, Charles Lin, Antoine Bosselut, Chelsea Finn, & Christopher D. Manning. (2021). Fast Model Editing at Scale. In ArXiv. https://www.semanticscholar.org/paper/9286ac6e9b1aacd7d93496eb4615ae7678876d2a

E Sezgin, J Sirrianni, & SL Linwood. (2022). Operationalizing and implementing pretrained, large artificial intelligence linguistic models in the US health care system: outlook of generative pretrained …. In JMIR medical informatics. https://medinform.jmir.org/2022/2/e32875

El-Mahdi El-Mhamdi, Sadegh Farhadkhani, R. Guerraoui, Nirupam Gupta, L. Hoang, Rafael Pinot, & John Stephan. (2022). On the Impossible Safety of Large AI Models. In ArXiv. https://arxiv.org/abs/2209.15259

Emet Bethany, Mazal Bethany, Juan Arturo Nolazco Flores, S. Jha, & Peyman Najafirad. (2024). Jailbreaking Large Language Models with Symbolic Mathematics. In ArXiv. https://arxiv.org/abs/2409.11445

Emily M. Bender, Timnit Gebru, Angelina McMillan-Major, & Shmargaret Shmitchell. (2021). On the Dangers of Stochastic Parrots: Can Language Models Be Too Big? 🦜. In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency. https://dl.acm.org/doi/10.1145/3442188.3445922

Emre Kıcıman. (2022). A Causal AI Suite for Decision-Making. https://www.semanticscholar.org/paper/af80cec0eaf3ed5f93eb3aa0d81965baec869f08

Erik Cambria, Lorenzo Malandri, Fabio Mercorio, Navid Nobani, & Andrea Seveso. (2024). XAI meets LLMs: A Survey of the Relation between Explainable AI and Large Language Models. In ArXiv. https://arxiv.org/abs/2407.15248

Erin Sanu, T. K. Amudaa, Prasiddha Bhat, Guduru Dinesh, Apoorva Uday Kumar Chate, & R. P. (2024). Limitations of Large Language Models. In 2024 8th International Conference on Computational System and Information Technology for Sustainable Solutions (CSITSS). https://ieeexplore.ieee.org/document/10817070/

F Danglade, JP Pernot, P Véron, & L Fine. (2017). A priori evaluation of simulation models preparation processes using artificial intelligence techniques. In Computers in Industry. https://www.sciencedirect.com/science/article/pii/S0166361516303311

F. H. Zunjani & Ana-Maria Olteţeanu. (2019). Cognitive AI Systems Contribute to Improving Creativity Modeling and Measuring Tools. In International Work-Conference on the Interplay Between Natural and Artificial Computation. https://www.semanticscholar.org/paper/74a23237fc76472a5a1dfbc0c9485bec77624ad7

F Jiang, C Pan, L Dong, K Wang, & M Debbah. (2025). A comprehensive survey of large ai models for future communications: Foundations, applications and challenges. https://arxiv.org/abs/2505.03556

F. Szabó & G. Juhász. (2014). Changes in the Macro-Environment of Hungarian Waste Management Sector. https://www.semanticscholar.org/paper/da3f381e79461a55692517535426d04d3db3a42b

Fabian Schmidt, Karin Hammerfald, Henrik Haaland Jahren, A. H. Payberah, & Vladimir Vlassov. (2024). Single-pass Hierarchical Text Classification with Large Language Models. In 2024 IEEE International Conference on Big Data (BigData). https://www.semanticscholar.org/paper/0be046fd33baa9e28aca699fa98deb5bdf4e9296

Farhana Ferdousi Liza. (2022). Challenges of Enforcing Regulations in Artificial Intelligence Act - Analyzing Quantity Requirement in Data and Data Governance. In IAIL@HHAI. https://www.semanticscholar.org/paper/608b9b7ab4e86df71cc8211bf862d3e085624469

Fatmanur BUDAK DURMUS. (2024). Swot Analysis of the Use of ChatGPT in Education. In Journal of Educational Studies and Multidisciplinary Approaches. https://www.semanticscholar.org/paper/cdae01358190c0d6ab9ab2cb97239eb3989fdaaf

Fengchun Qiao & Xi Peng. (2021). Uncertainty-guided Model Generalization to Unseen Domains. In 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). https://www.semanticscholar.org/paper/2c0ccf919d5347b87677e7a16a3ba5e555f51710

Feras A. Batarseh, Laura J. Freeman, & Chih-hao Huang. (2021). A survey on artificial intelligence assurance. In Journal of Big Data. https://www.semanticscholar.org/paper/c6e1a3505ff160e8cc747f02936b2f6861cba18e

Francesco Corea. (2018). AI Business Models. In Studies in Big Data. https://www.semanticscholar.org/paper/d9aadee80aa5f58857bb39ac8be933065c441603

Frank Weizhen Liu & Chenhui Hu. (2024). Exploring Vulnerabilities and Protections in Large Language Models: A Survey. In ArXiv. https://arxiv.org/abs/2406.00240

Frédéric C. G. Bogaerts, N. Ivaki, & José Manuel Cantera Fonseca. (2023). Using AI to Inject Vulnerabilities in Python Code. In 2023 53rd Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN-W). https://ieeexplore.ieee.org/document/10207078/

Frida Gjermeni & Fatmira Prodani. (2024). AI and Student Engagement: A Comparative Analysis. In Interdisciplinary Journal of Research and Development. https://www.semanticscholar.org/paper/8fa8ce2a22acb9b4d7cab4167a878cdb5bf05794

Fuka Matsuzaki & Haru-Tada Sato. (2024). Unmasking the Limits of Large Language Models: A Systematic Evaluation of Masked Text Processing Ability through MskQA and MskCal. In ArXiv. https://arxiv.org/abs/2411.05665

Fuxun Yu, Di Wang, Longfei Shangguan, Minjia Zhang, Xulong Tang, Chenchen Liu, & Xiang Chen. (2021). A Survey of Large-Scale Deep Learning Serving System Optimization: Challenges and Opportunities. In ArXiv. https://www.semanticscholar.org/paper/3eb5620dfe407c45789ae19f5ebe8b34abe331ee

G. Ghislat, Saiveth Hernández-Hernández, Chayanit Piwajanusorn, & Pedro J. Ballester. (2024). Data-centric challenges with the application and adoption of artificial intelligence for drug discovery. In Expert opinion on drug discovery. https://www.tandfonline.com/doi/full/10.1080/17460441.2024.2403639

G. Tarun, Saif O. Husain, Imad Al-Din Hussein Al-Saidi, S. Vats, Rabei Raad Ali, Ahmed Qusay Jawad, & Tareq Hafdhi Abdtawfeeq. (2024). Analysing Technical and Economic Dimensions using AI Techniques. In 2024 4th International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE). https://ieeexplore.ieee.org/document/10617367/

G. Varoquaux, A. Luccioni, & Meredith Whittaker. (2024). Hype, Sustainability, and the Price of the Bigger-is-Better Paradigm in AI. In ArXiv. https://arxiv.org/abs/2409.14160

Gaël Gendron, Bao Trung Nguyen, A. Peng, Michael Witbrock, & Gillian Dobbie. (2024). Can Large Language Models Learn Independent Causal Mechanisms? In Conference on Empirical Methods in Natural Language Processing. https://arxiv.org/abs/2402.02636

Gaurav Samdani, Kabita Paul, & Flavia Saldanha. (2022). Serverless architectures for agentic AI deployment. In World Journal of Advanced Engineering Technology and Sciences. https://www.semanticscholar.org/paper/3c129390bc1888ec3ce499734f1dd6933c7afc49

GC Tiao & WY Tan. (1965). Bayesian analysis of random-effect models in the analysis of variance. I. Posterior distribution of variance-components. In Biometrika. https://www.jstor.org/stable/2333810

Ge Wang, Helena S. Wisniewski, & Kenrick Mock. (2024). Revolutionizing Education with Large AI Models. In Technology &amp; Innovation. https://www.ingentaconnect.com/content/nai/ti/2024/00000023/00000001/art00004

GH Seo. (2025). Oracle of Delphi? Future Study Agenda and Knowledge Structure of Marketing Mix: A Hybrid Bibliometric Analysis Using ChatGPT. https://shudo-u.repo.nii.ac.jp/record/2000299/files/SG65201.pdf

GPT-3 AI language tool calls for cautious optimism. (2020). In Emerald Expert Briefings. https://www.semanticscholar.org/paper/afe7ced79c2f4017b86053322666cb56e1040774

Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, & Wojciech Zaremba. (2016). OpenAI Gym. In ArXiv. https://www.semanticscholar.org/paper/2b10281297ee001a9f3f4ea1aa9bea6b638c27df

Guangji Bai, Zheng Chai, Chen Ling, Shiyu Wang, Jiaying Lu, Nan Zhang, Tingwei Shi, Ziyang Yu, Mengdan Zhu, Yifei Zhang, Carl Yang, Yue Cheng, & Liang Zhao. (2024). Beyond Efficiency: A Systematic Survey of Resource-Efficient Large Language Models. In ArXiv. https://arxiv.org/abs/2401.00625

Guangji Shi, P. Aarabi, & Hui Jiang. (2007). Phase-Based Dual-Microphone Speech Enhancement Using A Prior Speech Model. In IEEE Transactions on Audio, Speech, and Language Processing. https://ieeexplore.ieee.org/document/4032794/

H Baniecki & P Biecek. (2024). Adversarial attacks and defenses in explainable artificial intelligence: A survey. In Information Fusion. https://www.sciencedirect.com/science/article/pii/S1566253524000812

H. Law & Sébastien A. Krier. (2023). Open-source provisions for large models in the AI Act. https://www.semanticscholar.org/paper/366dc4181cb7dc0e78b4cf7f3968818bc1a7da2d

H Naveed, AU Khan, S Qiu, M Saqib, & S Anwar. (2023). A comprehensive overview of large language models. https://dl.acm.org/doi/abs/10.1145/3744746

H Rahman, RS D’Cruze, MU Ahmed, & R Sohlberg. (2022). Artificial intelligence-based life cycle engineering in industrial production: a systematic literature review. https://ieeexplore.ieee.org/abstract/document/9991951/

H Surden. (2018). Artificial intelligence and law: An overview. In Ga. St. UL Rev. https://heinonline.org/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/gslr35&section=59

H Yukihiro. (n.d.). Information Phase Transition and AI Philosophy: Structural Responsibility and the Generative Dynamics of Intelligence and Meaning. https://philpapers.org/rec/YUKIPT

Han Yan-b. (2009). Water resources balance analysis of Ai river basin. https://www.semanticscholar.org/paper/75782ed8ff3cb31e9ddcf083afd052e449b38e37

Hangfeng He & Weijie J. Su. (2024). A Law of Next-Token Prediction in Large Language Models. In ArXiv. https://www.semanticscholar.org/paper/1c464e0cb0758a4206915332fd9e3cf35ee770d8

Harry Surden, Alec Radford, Jeff Wu, R. Child, D. Luan, Dario Amodei, I. Sutskever, Ouyang Long, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, … Mirjalili. (n.d.). CHATGPT, AI LARGE LANGUAGE MODELS, AND LAW. https://www.semanticscholar.org/paper/de0b3cd43f450ed34d6b08ac29a4314603410932

Heeyoung Kwon, Mahnaz Koupaee, Pratyush Singh, Gargi Sawhney, Anmol Shukla, Keerthi Kumar Kallur, Nathanael Chambers, & Niranjan Balasubramanian. (2020). Modeling Preconditions in Text with a Crowd-sourced Dataset. In ArXiv. https://www.semanticscholar.org/paper/39d3a491d833c7a9fdf9bf3b9be453053a2a7e5b

Henry Gasztowtt, Benjamin Smith, Vincent Zhu, Qinxun Bai, & Edwin Zhang. (2024). Large Legislative Models: Towards Efficient AI Policymaking in Economic Simulations. In ArXiv. https://arxiv.org/abs/2410.08345

HG Ma, XF Zhu, MS Ai, & JD Wang. (2007). Fault diagnosis for analog circuits based on chaotic signal excitation. In Journal of the franklin Institute. https://www.sciencedirect.com/science/article/pii/S0016003207000592

HH Elmousalami. (2020). Artificial intelligence and parametric construction cost estimate modeling: State-of-the-art review. https://ascelibrary.org/doi/abs/10.1061/(ASCE)CO.1943-7862.0001678

Himanshu Joshi & Volkan Ustun. (2024). Augmenting Cognitive Architectures with Large Language Models. In Proceedings of the AAAI Symposium Series. https://www.semanticscholar.org/paper/fc1f1e2b7841b3f657cd43b24aeeb7cd0e927f11

HM Heyn, E Knauss, & P Pelliccione. (2023). A compositional approach to creating architecture frameworks with an application to distributed AI systems. In Journal of Systems and Software. https://www.sciencedirect.com/science/article/pii/S0164121222002801

Hojiakbar Muminov. (2024). THE FUTURE OF AI IN DIGITAL MARKETING TRENDS AND PREDICTIONS FOR 2025. In International Journal of Artificial Intelligence for Digital Marketing. https://www.semanticscholar.org/paper/bd8f7d682fcc5ec56c1bd332a0a85c1eca4e3ac1

Hong N.Dao, ChuanYuan Wang, Aoshi Suzuki, Hitomi Sudo, Li Ye, & Debopriyo Roy. (2024). AI in Stock Market Forecasting: A Bibliometric Analysis. In SHS Web of Conferences. https://www.semanticscholar.org/paper/c3338d28bc66bf05bedb62f57c38b378d3039872

Hongguang Sun, Conglei Xu, Yudan Wu, Shuangdai Zou, & Fangxu Wan. (2020). L-CNN: An Improved Convolutional Neural Network to Capture Long-Distance Dependencies. In Recent Trends in Decision Science and Management. https://link.springer.com/chapter/10.1007/978-981-15-3588-8_14

Hongxia Zhang, Hua Zou, Fangchun Yang, & Rongheng Lin. (2012). From Requirements to Business Processes Development. In 2012 IEEE Ninth International Conference on Services Computing. https://ieeexplore.ieee.org/document/6274207/

Hongyin Zhu. (2024). Challenges and Responses in the Practice of Large Language Models. In ArXiv. https://arxiv.org/abs/2408.09416

Hongzhi Zhang, Guangluan Xu, Xiao Liang, Weili Zhang, Xian Sun, & Tinglei Huang. (2019). Multi-view multitask learning for knowledge base relation detection. In Knowl. Based Syst. https://www.semanticscholar.org/paper/18f273c722647363c5d170e57de8f0c12a92949b

Hussain Ahmad & Diksha Goel. (2025). The Future of AI: Exploring the Potential of Large Concept Models. In ArXiv. https://arxiv.org/abs/2501.05487

HY Lin. (2022). Large-scale artificial intelligence models. In Computer. https://scholar.archive.org/work/7ob6yidxxjcnrloxnjhxfprxqa/access/wayback/https://ieeexplore.ieee.org/ielx7/2/9771118/09771130.pdf?tp=&arnumber=9771130&isnumber=9771118&ref=

I. Craig. (1991). Formal specification of advanced AI architectures. In Ellis Horwood series in artificial intelligence. https://www.semanticscholar.org/paper/9b722cff861623195694d90b7d2d3b42158effb1

I. Drovtar, M. Landsberg, J. Kilter, & A. Rosin. (2012). Impacts of large scale wind integration on the baltic region’s thermal power plant economics and electricity market in 2025. In International Symposium on Power Electronics Power Electronics, Electrical Drives, Automation and Motion. https://www.semanticscholar.org/paper/2adc17b331b6dde699442a2c20b03e9b1b6dee0c

IR Panglipur & H Palayukan. (2024). Artificial Intelligence (AI) Modeling Technique to Improve Creative Thinking on Number Concepts for Early Childhood with Disabilities. https://mail.jurnaldidaktika.org/contents/article/view/422

Irene Solaiman, Miles Brundage, Jack Clark, Amanda Askell, Ariel Herbert-Voss, Jeff Wu, Alec Radford, & Jasmine Wang. (2019). Release Strategies and the Social Impacts of Language Models. In ArXiv. https://www.semanticscholar.org/paper/c7462e0ee928f095a7fc40b91f1e7557d283ae8e

Irma Ravkic, J. Ramon, & Jesse Davis. (2015). Learning relational dependency networks in hybrid domains. In Machine Learning. https://www.semanticscholar.org/paper/4803c4f013687249058bd4f2f863152882070e74

Iurii Perga. (2024). THE ROLE OF AI (LARGE LANGUAGE MODELS) IN MANAGERIAL DECISION-MAKING: BENEFITS AND CHALLENGES. In Наукові перспективи (Naukovì perspektivi). http://perspectives.pp.ua/index.php/np/article/view/15929

J. Baas, M. Dastani, & A. Feelders. (2021). Exploiting Transitivity for Entity Matching. In Extended Semantic Web Conference. https://www.semanticscholar.org/paper/6e626326c71a1cd7f9801f3aa9599b2f9d1ede52

J. Bézivin, S. Bouzitouna, Marcos Didonet Del Fabro, M. Gervais, F. Jouault, D. Kolovos, I. Kurtev, & R. Paige. (2006). A Canonical Scheme for Model Composition. In ECMDA-FA. https://www.semanticscholar.org/paper/bea4ba6ab20de9b8332eb87836d5f90dfe75017f

J Bi, Z Wang, H Yuan, X Shi, & Z Wang. (2025). Large AI Models and Their Applications: Classification, Limitations, and Potential Solutions. https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.3408

J. C. Xavier, Alberto Signoretti, A. Canuto, André M. C. Campos, L. Gonçalves, & S. Fialho. (2011). Introducing Affective Agents in Recommendation Systems Based on Relational Data Clustering. In International Conference on Database and Expert Systems Applications. https://www.semanticscholar.org/paper/4f56f438e62a97c719e8cbb95465bdb8bb6784bf

J Chen, Z Liu, X Huang, C Wu, Q Liu, G Jiang, & Y Pu. (2024). When large language models meet personalization: Perspectives of challenges and opportunities. In World Wide Web. https://link.springer.com/article/10.1007/s11280-024-01276-1

J. Gichoya, Kaesha Thomas, L. Celi, Nabile Safdar, I. Banerjee, John Banja, Laleh Seyyed-Kalantari, H. Trivedi, & Saptarshi Purkayastha. (2023). AI pitfalls and what not to do: mitigating bias in AI. In The British Journal of Radiology. https://academic.oup.com/bjr/article/doi/10.1259/bjr.20230023/7498925

J. Harolds. (2014). Tips for a Physician in Getting the Right Job, Part IX: Interview Questions for Any Physician Job Applicant. In Clinical Nuclear Medicine. https://www.semanticscholar.org/paper/68b0c5c1407199f31f166c919f824635ecb75af6

J. Jahic & Robin Roitsch. (2020). State of the Practice Survey: Predicting the Influence of AI Adoption on System Software Architecture in Traditional Embedded Systems. In ECSA Companion. https://link.springer.com/chapter/10.1007/978-3-030-59155-7_12

J. Jeon, Juhyeong Lee, Ricardo Vinuesa, & S. J. Kim. (2022). Residual-based physics-informed transfer learning: A hybrid method for accelerating long-term CFD simulations via deep learning. In International Journal of Heat and Mass Transfer. https://linkinghub.elsevier.com/retrieve/pii/S0017931023010451

J. L. Rodríguez Illera. (2024). AI in the discourse of the relationships between technology and education. In Digital Education Review. https://www.semanticscholar.org/paper/80d68c70d89c5e9dcff942761d9dfc3e248e7a9e

J Li & G Li. (2025). Triangular trade-off between robustness, accuracy, and fairness in deep neural networks: A survey. In ACM Computing Surveys. https://dl.acm.org/doi/abs/10.1145/3645088

J Pearl. (2002). Reasoning with cause and effect. In AI Magazine. https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/1612

J Ploennigs & M Berger. (2023). AI art in architecture. In AI in Civil Engineering. https://link.springer.com/article/10.1007/s43503-023-00018-y

J Renkhoff, K Feng, & M Meier-Doernberg. (2024). A survey on verification and validation, testing and evaluations of neurosymbolic artificial intelligence. https://ieeexplore.ieee.org/abstract/document/10385139/

J. V. Rijn. (2019). Self-aware AI Systems. https://www.semanticscholar.org/paper/f5a8091e58245b0713296f718b958129c939d79d

Jack David Carson. (2025). A Stochastic Dynamical Theory of LLM Self-Adversariality: Modeling Severity Drift as a Critical Process. In ArXiv. https://arxiv.org/abs/2501.16783

Jack Merullo, Carsten Eickhoff, & Ellie Pavlick. (2023). Language Models Implement Simple Word2Vec-style Vector Arithmetic. In North American Chapter of the Association for Computational Linguistics. https://arxiv.org/abs/2305.16130

Jad Kabbara & J. Cheung. (2022). Investigating the Performance of Transformer-Based NLI Models on Presuppositional Inferences. In International Conference on Computational Linguistics. https://www.semanticscholar.org/paper/90a35136bfdb158370cf5e7e6bc70fdb77fb5c8b

Jaffer Gardezi, L. Bertossi, & I. Kiringa. (2012). Matching dependencies: semantics and query answering. In Frontiers of Computer Science. https://www.semanticscholar.org/paper/1bce4b0f8f4c28ecc8f27fc69cf5cd26d04f64bf

Jayanti Prasad. (2023). Large Language Models: AI Foundations and Applications in Python. https://www.semanticscholar.org/paper/a024aba3a4c75a31cdc45e6312cc1156ddaf4e6a

Jaymari Chua, Yun Li, Shiyi Yang, Chen Wang, & Lina Yao. (2024). AI Safety in Generative AI Large Language Models: A Survey. In ArXiv. https://arxiv.org/abs/2407.18369

Jean Kaddour, J. Harris, Maximilian Mozes, Herbie Bradley, Roberta Raileanu, & R. McHardy. (2023). Challenges and Applications of Large Language Models. In ArXiv. https://arxiv.org/abs/2307.10169

Jeevan Sreerama & Gowrisankar Krishnamoorthy. (2022). Ethical Considerations in AI Addressing Bias and Fairness in Machine Learning Models. In Journal of Knowledge Learning and Science Technology ISSN: 2959-6386 (online). https://www.semanticscholar.org/paper/8a07c9348378c86e67e8ba804d8755a8b03f8c86

Jens Christian Bjerring, Jakob Mainz, & L. Munch. (2025). Deep learning models and the limits of explainable artificial intelligence. In Asian Journal of Philosophy. https://www.semanticscholar.org/paper/1cd675d7ca2dba9b41340cef4ac1eb0373e00a18

J’er’emy Scheurer, Jon Ander Campos, Jun Shern Chan, Angelica Chen, Kyunghyun Cho, & Ethan Perez. (2024). Learning from Natural Language Feedback. In Trans. Mach. Learn. Res. https://arxiv.org/abs/2204.14146

Jiahui Yu, Pengchong Jin, Hanxiao Liu, Gabriel Bender, Pieter-Jan Kindermans, Mingxing Tan, Thomas Huang, Xiaodan Song, & Quoc V. Le. (2020). BigNAS: Scaling Up Neural Architecture Search with Big Single-Stage Models. In European Conference on Computer Vision. https://www.semanticscholar.org/paper/a8c0ac6588012d91c81b83b6cbd16c40e2e5edd2

Jiajia Guo, Yiming Cui, Chao-Kai Wen, & Shi Jin. (2025). Prompt-Enabled Large AI Models for CSI Feedback. In ArXiv. https://www.semanticscholar.org/paper/b91dd02ff5df5ec639634f8ee67299364b704968

Jianing Qiu, Lin Li, Jiankai Sun, Jiachuan Peng, Peilun Shi, Rui Zhang, Yinzhao Dong, K. Lam, F. P. Lo, Bo Xiao, Wu Yuan, Dong Xu, & Benny P. L. Lo. (2023). Large AI Models in Health Informatics: Applications, Challenges, and the Future. In IEEE Journal of Biomedical and Health Informatics. https://ieeexplore.ieee.org/document/10261199/

Jiaqi Wang, Zihao Wu, Yiwei Li, Hanqi Jiang, Peng Shu, Enze Shi, Huawen Hu, Chong-Yi Ma, Yi-Hsueh Liu, Xuhui Wang, Yincheng Yao, Xuan Liu, Huaqin Zhao, Zheng Liu, Haixing Dai, Lin Zhao, Bao Ge, Xiang Li, Tianming Liu, & Shu Zhang. (2024). Large Language Models for Robotics: Opportunities, Challenges, and Perspectives. In ArXiv. https://www.semanticscholar.org/paper/8296eef3797afd1515021ff568a694412c38101b

Jiawei Li, Yizhe Yang, Yu Bai, Xiaofeng Zhou, Yinghao Li, Huashan Sun, Yuhang Liu, Xingpeng Si, Yuhao Ye, Yixiao Wu, Yiguan Lin, Bin Xu, Ren Bowen, Chong Feng, Yang Gao, & Heyan Huang. (2024). Fundamental Capabilities of Large Language Models and their Applications in Domain Scenarios: A Survey. In Annual Meeting of the Association for Computational Linguistics. https://aclanthology.org/2024.acl-long.599/

Jiaxi Wu, Xiaotong Lin, Zhiqiang Lin, & Yi Tang. (2018). A Security Concern About Deep Learning Models. In International Conference on Science of Cyber Security. https://link.springer.com/chapter/10.1007/978-3-030-03026-1_15

Jingze Lu, Kaijun Ren, Taikang Yuan, & Wuxin Wang. (2024). Phase-Space-Guided Deep Learning For Time Series Forecasting. In ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). https://ieeexplore.ieee.org/document/10446009/

Jinqi Lai, Wensheng Gan, Jiayang Wu, Zhenlian Qi, & Philip S. Yu. (2023). Large Language Models in Law: A Survey. In ArXiv. https://arxiv.org/abs/2312.03718

Jiumei Zhang, Weiqiang Li, & Siying Li. (2024). ChatGPT: Analyzing Intelligent Chatbots Based on Big Language Models. In Frontiers in Business, Economics and Management. https://www.semanticscholar.org/paper/c03c3193fa7b46e6b1da1c6680e5e5fbb488bc95

JL Espinoza, CL Dupont, & A O’Rourke. (2021). Predicting antimicrobial mechanism-of-action from transcriptomes: A generalizable explainable artificial intelligence approach. https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008857

JN Warfield. (1974). Developing interconnection matrices in structural modeling. https://ieeexplore.ieee.org/abstract/document/5408524/

John P. Lalor, Ahmed Abbasi, Kezia Oketch, Yi Yang, & Nicole Forsgren. (2024). Should Fairness be a Metric or a Model? A Model-based Framework for Assessing Bias in Machine Learning Pipelines. In ACM Transactions on Information Systems. https://www.semanticscholar.org/paper/f5dd2686dd44f35a77690de2fb5a5498a723e093

John Villasenor. (2023). How the White House’s AI Executive Order Could Increase U.S. Cyber Vulnerabilities. In International Journal of Innovative Research in Education, Technology and Social Strategies. https://www.semanticscholar.org/paper/60d3dd1e8c4817e9f97c97d954fc2cb950120b27

Jongseon Kim, Hyungjoon Kim, Hyungi Kim, Dongjun Lee, & Sungroh Yoon. (2024). A Comprehensive Survey of Time Series Forecasting: Architectural Diversity and Open Challenges. In ArXiv. https://arxiv.org/abs/2411.05793

Jörg Martin & C. Elster. (2021). Errors-in-Variables for deep learning: rethinking aleatoric uncertainty. In ArXiv. https://www.semanticscholar.org/paper/b7b1e8f7d3af09f37e8b55f1593d75ce0ca790bc

Joseph Paul Cohen, Tianshi Cao, J. Viviano, Chinwei Huang, M. Fralick, M. Ghassemi, M. Mamdani, R. Greiner, & Y. Bengio. (2021). Problems in the deployment of machine-learned models in health care. In CMAJ : Canadian Medical Association Journal. https://www.cmaj.ca/lookup/doi/10.1503/cmaj.202066

Joseph Sakau, Evander Kozlowski, Roderick Thistledown, & Basil Steinberger. (2025). Framework for Progressive Knowledge Fusion in Large Language Models Through Structured Conceptual Redundancy Analysis. In ArXiv. https://arxiv.org/abs/2501.13999

Joydeep Banerjee, Arun Das, & Arunabha Sen. (2017). A Survey of Interdependency Models for Critical Infrastructure Networks. In Examining Robustness and Vulnerability of Networked Systems. http://arxiv.org/abs/1702.05407

JP Müller. (1999). Architectures and applications of intelligent agents: A survey. In The Knowledge Engineering Review. https://www.cambridge.org/core/journals/knowledge-engineering-review/article/architectures-and-applications-of-intelligent-agents-a-survey/9524A9DA25640A4BD17C1E68F118C3E8

Juergen Schmidhuber. (2022). Annotated History of Modern AI and Deep Learning. In ArXiv. https://arxiv.org/abs/2212.11279

Jun Wan. (2025). Unifying Two Types of Scaling Laws from the Perspective of Conditional Kolmogorov Complexity. In ArXiv. https://www.semanticscholar.org/paper/3d87ddfa3cc94f007f66acd7363db0f9b618b820

Junfeng Jiao, Saleh Afroogh, Kevin Chen, David Atkinson, & Amit Dhurandhar. (2025). Generative AI and LLMs in Industry: A text-mining Analysis and Critical Evaluation of Guidelines and Policy Statements Across Fourteen Industrial Sectors. In ArXiv. https://www.semanticscholar.org/paper/ba6242ca66a83a1f232acbfb04d9fb222a60bf9f

Junhua Liu. (2024). A Survey of Financial AI: Architectures, Advances and Open Challenges. In ArXiv. https://arxiv.org/abs/2411.12747

Jun-Jie Zhang, Jiahao Song, Xiuwen Wang, Fu-Peng Li, Zehan Liu, Jian-Nan Chen, Haoning Dang, Shiyao Wang, Yiyan Zhang, Jianhui Xu, Chunxiang Shi, Fei Wang, Long-Gang Pang, Nan Cheng, Weiwei Zhang, Duo Zhang, & Deyu Meng. (2024). Is AI Robust Enough for Scientific Research? In ArXiv. https://arxiv.org/abs/2412.16234

K. Hammond & David B. Leake. (2023). Large Language Models Need Symbolic AI. In International Workshop on Neural-Symbolic Learning and Reasoning. https://www.semanticscholar.org/paper/0266171daa51dcc2c9b12b2c344a28aa8086ca36

K. Kenthapadi, M. Sameki, & Ankur Taly. (2024). Grounding and Evaluation for Large Language Models: Practical Challenges and Lessons Learned (Survey). In ArXiv. https://dl.acm.org/doi/10.1145/3637528.3671467

K Liu, S Liu, X Tan, W Li, L Wang, X Li, & X Xu. (2023). Deep learning system for distinguishing optic neuritis from non-arteritic anterior ischemic optic neuropathy at acute phase based on fundus photographs. https://www.frontiersin.org/articles/10.3389/fmed.2023.1188542/full

K Pauwels, M Tomasi, JD Alonso, & E Ros. (2011). A comparison of FPGA and GPU for real-time phase-based optical flow, stereo, and local image features. https://ieeexplore.ieee.org/abstract/document/5936059/

K. S. Shifrin. (1995). Simple relationships for the Ångström parameter of disperse systems. In Applied optics. https://www.semanticscholar.org/paper/3840a4604117431d85fe9fc2679c0424d17ad19c

K Thórisson & H Helgasson. (2012). Cognitive architectures and autonomy: A comparative review. In Journal of Artificial General Intelligence. https://sciendo.com/pdf/10.2478/v10229-011-0015-3

Kaarina Karppinen, M. Lindvall, & Lyly Yonkwa. (2008). Detecting Security Vulnerabilities with Software Architecture Analysis Tools. In 2008 IEEE International Conference on Software Testing Verification and Validation Workshop. https://www.semanticscholar.org/paper/a0f50d3ccda42e7343908c697be786f20d9640d5

Kaiqiang Wang, Li Song, Chutian Wang, Zhenbo Ren, Guangyuan Zhao, Jiazhen Dou, Jianglei Di, G. Barbastathis, Renjie Zhou, Jianlin Zhao, & E. Lam. (2023). On the use of deep learning for phase recovery. In Light, Science & Applications. https://www.nature.com/articles/s41377-023-01340-x

Kaiyuan Tian, Linbo Qiao, Baihui Liu, Gongqingjian Jiang, & Dongsheng Li. (2025). A Survey on Memory-Efficient Large-Scale Model Training in AI for Science. In ArXiv. https://arxiv.org/abs/2501.11847

Karen L. Myers & P. Berry. (1999). At the Boundary of Workflow and AI. https://www.semanticscholar.org/paper/7ce13222f63eb7b95324b5f46faa707913862957

Katherine Robbert, Christopher Penn, & John Wall. (2023). Use cases of large language models in marketing analytics. In Applied Marketing Analytics: The Peer-Reviewed Journal. https://hstalks.com/article/8196/use-cases-of-large-language-models-in-marketing-an/?business

Katikapalli Subramanyam Kalyan. (2023). A Survey of GPT-3 Family Large Language Models Including ChatGPT and GPT-4. In Nat. Lang. Process. J. https://arxiv.org/abs/2310.12321

Kazi Zakia Sultana, Zadia Codabux, & Byron J. Williams. (2020). Examining the Relationship of Code and Architectural Smells with Software Vulnerabilities. In 2020 27th Asia-Pacific Software Engineering Conference (APSEC). https://ieeexplore.ieee.org/document/9359268/

KF Hubert, KN Awa, & DL Zabelina. (2024). The current state of artificial intelligence generative language models is more creative than humans on divergent thinking tasks. In Scientific Reports. https://www.nature.com/articles/s41598-024-53303-w

Khalid Albulayhi, Predrag T. Tosic, & Frederick T. Sheldon. (2020). G-Model: A Novel Approach to Privacy-Preserving 1:M Microdata Publication. In 2020 7th IEEE International Conference on Cyber Security and Cloud Computing (CSCloud)/2020 6th IEEE International Conference on Edge Computing and Scalable Cloud (EdgeCom). https://www.semanticscholar.org/paper/bfc4266fd92631056e5daa40b3ec32d64b4e74a2

Khurram Yamin, Shantanu Gupta, Gaurav R. Ghosal, Zachary Chase Lipton, & Bryan Wilder. (2024). Failure Modes of LLMs for Causal Reasoning on Narratives. In ArXiv. https://arxiv.org/abs/2410.23884

Kiril Traykov. (2024). A Framework for Security Testing of Large Language Models. In 2024 IEEE 12th International Conference on Intelligent Systems (IS). https://ieeexplore.ieee.org/document/10705238/

Kranthi Godavarthi, Jayanna Hallur, & Sujan Das. (2024). Foundation Models for Big Data: Enabling AI-Powered Data Insights to Accelerate Business Outcomes and Achieve Sustainable Success. In 2024 IEEE International Conference on Big Data (BigData). https://ieeexplore.ieee.org/document/10825551/

KY Lee & N Ha. (2018). AI platform to accelerate API economy and ecosystem. https://ieeexplore.ieee.org/abstract/document/8343242/

L Boeschoten, EJ van Kesteren, & A Bagheri. (2020). Fair inference on error-prone outcomes. https://arxiv.org/abs/2003.07621

L. N. Harris. (1985). The use of models in reliability. In Quality and Reliability Engineering International. https://onlinelibrary.wiley.com/doi/10.1002/qre.4680010308

L Ranaldi & G Pucci. (2023). When large language models contradict humans? large language models’ sycophantic behaviour. In arXiv. https://arxiv.org/abs/2311.09410

Large language models: fast proliferation and budding international competition. (2023). In Strategic Comments. https://www.tandfonline.com/doi/full/10.1080/13567888.2023.2198430

Laura Ruis, Maximilian Mozes, Juhan Bae, S. Kamalakara, Dwarak Talupuru, Acyr F. Locatelli, Robert Kirk, Tim Rocktaschel, Edward Grefenstette, & Max Bartolo. (2024). Procedural Knowledge in Pretraining Drives Reasoning in Large Language Models. In ArXiv. https://www.semanticscholar.org/paper/75a1909815a8e4036a5fc212b545982506fc481e

Lei Cao, Minglu Li, & Jian Cao. (2005). An agent-based grid workflow management system using AI planning. In International Conference on Next Generation Web Services Practices (NWeSP’05). https://www.semanticscholar.org/paper/a5668479b66f73bb87ec85b5f31e79e47d49305a

Lei Liu. (2016). Hierarchical learning for large multi-class network classification. In 2016 23rd International Conference on Pattern Recognition (ICPR). https://ieeexplore.ieee.org/document/7899980/

Lei Wang & Taihui Zhu. (2018). The myth of China’s monetization. In Applied Economics Letters. https://www.tandfonline.com/doi/full/10.1080/13504851.2017.1366633

Leon Derczynski, Erick Galinkin, Jeffrey Martin, Subho Majumdar, & Nanna Inie. (2024). garak: A Framework for Security Probing Large Language Models. In ArXiv. https://arxiv.org/abs/2406.11036

Li Yi-guo. (2006). On Ai Siqi’s Philosophical Innovation. In Journal of Yunnan Normal University. https://www.semanticscholar.org/paper/bb0bf570bed3f0b5ad1d559c6a5b941f19f57952

Li-min Wen. (2012). The Credibility Estimation for the Collective Models. In Journal of Jiangxi Normal University. https://www.semanticscholar.org/paper/730d9dc30bedb3ba88657f1e9401f846c1c91ab3

Lin Li, Guikun Chen, Hanrong Shi, Jun Xiao, & Long Chen. (2024). A Survey on Multimodal Benchmarks: In the Era of Large AI Models. In ArXiv. https://arxiv.org/abs/2409.18142

Linge Guo. (2024). Unmasking the Shadows of AI: Investigating Deceptive Capabilities in Large Language Models. In ArXiv. https://arxiv.org/abs/2403.09676

Ling-ling Li, Fenfen Zhu, Chunwen Yang, & Zhi G. Li. (2011). Research on the Credibility of Fuzzy Reliability. In Applied Mechanics and Materials. https://www.scientific.net/AMM.48-49.984

Lingwei Chen & Yanfang Ye. (2017). SecMD: Make Machine Learning More Secure Against Adversarial Malware Attacks. In Australasian Conference on Artificial Intelligence. https://www.semanticscholar.org/paper/e01b73e9d301af798987cc9cd75b8a22b5852cf6

Lizhou Fan, Lingyao Li, Zihui Ma, Sanggyu Lee, Huizi Yu, & Libby Hemphill. (2023). A Bibliometric Review of Large Language Models Research from 2017 to 2023. In ACM Transactions on Intelligent Systems and Technology. https://www.semanticscholar.org/paper/07f07d4d59fdbc3596284f51057cb006779d42c1

LR Varshney, NS Keskar, & R Socher. (1909). Pretrained AI models: performativity, mobility, and change. In arXiv. https://arxiv.org/abs/1909.03290

Lucilla Gatt, I. A. Caggiano, Maria Cristina Gaeta, Livia Aulino, & Emiliano Troisi. (2023). The Possible Relationships Between Law and Ethics Applied to AI. In 2023 IEEE International Conference on Metrology for eXtended Reality, Artificial Intelligence and Neural Engineering (MetroXRAINE). https://www.semanticscholar.org/paper/6d5bb0d880d3d3b71512269637a9f9608b4650cb

Luiz C. Vieira, Morgan L. Handojo, & Claus O. Wilke. (2024). Scaling down for efficiency: Medium-sized protein language models perform well at transfer learning on realistic datasets. In bioRxiv. https://www.biorxiv.org/lookup/doi/10.1101/2024.11.22.624936

Luwei Sun, Dongrui Shen, & Han Feng. (2024). Theoretical Insights into CycleGAN: Analyzing Approximation and Estimation Errors in Unpaired Data Generation. In ArXiv. https://arxiv.org/abs/2407.11678

M. A. Pimentel, Cl’ement Christophe, Tathagata Raha, Prateek Munjal, P. K. Kanithi, & Shadab Khan. (2024). Beyond Metrics: A Critical Analysis of the Variability in Large Language Model Evaluation Frameworks. In ArXiv. https://arxiv.org/abs/2407.21072

M Abbasian, E Khatibi, I Azimi, & D Oniani. (2024). Foundation metrics for evaluating effectiveness of healthcare conversations powered by generative AI. https://www.nature.com/articles/s41746-024-01074-z

M. Bader & Christian Stummeyer. (2019). The Role of Innovation and IP in AI-Based Business Models. In Digital Entrepreneurship. https://www.semanticscholar.org/paper/cce314d8655b75516044b73b27cc4f9bbae6c5c9

M. Bagheri, T. Baum, A. Ebrahimi, & A. Abbasi. (2020). Talent Management in the Tourism and Hospitality Industry: Evidence from Iran. In Anatolia. https://www.tandfonline.com/doi/full/10.1080/13032917.2019.1708423

M BARBU & C CHIVU. (n.d.). A Review of Literature on Risk Identification in New Product Launches: Focusing on Market Needs and the Role of AI Utilization. https://www.recentonline.ro/2024/074/Barbu-R74.pdf

M Berti & MPE Cunha. (2023). Paradox, dialectics or trade‐offs? A double loop model of paradox. In Journal of Management Studies. https://onlinelibrary.wiley.com/doi/abs/10.1111/joms.12899

M Chui, J Manyika, M Miremadi, & N Henke. (2018). Notes from the AI frontier: Insights from hundreds of use cases. https://www.mckinsey.com/west-coast/~/media/McKinsey/Featured%20Insights/Artificial%20Intelligence/Notes%20from%20the%20AI%20frontier%20Applications%20and%20value%20of%20deep%20learning/Notes-from-the-AI-frontier-Insights-from-hundreds-of-use-cases-Discussion-paper.pdf

M. Danish. (2023). AI in Energy: Overcoming Unforeseen Obstacles. In AI. https://www.mdpi.com/2673-2688/4/2/22

M. Drozdz, D. Kourie, B. Watson, & A. Boake. (2006). Refactoring Tools and Complementary Techniques. In IEEE International Conference on Computer Systems and Applications, 2006. https://ieeexplore.ieee.org/document/1618429/

M Esposito, X Li, S Moreschini, & N Ahmad. (2025). Generative AI for Software Architecture. Applications, Trends, Challenges, and Future Directions. https://arxiv.org/abs/2503.13310

M. Mozina. (2018). Arguments in Interactive Machine Learning. In Informatica (Slovenia). https://www.semanticscholar.org/paper/0a32bc29c5bf07a41f7fb0e8e0c92896579f88a3

M. Oberhardt & E. Ruppin. (2013). Taming the complexity of large models. In EMBO reports. https://www.embopress.org/doi/10.1038/embor.2013.145

M. O’neill & M. Connor. (2023). Amplifying Limitations, Harms and Risks of Large Language Models. In ArXiv. https://arxiv.org/abs/2307.04821

M Ozkan-Okay, E Akin, Ö Aslan, & S Kosunalp. (2024). A comprehensive survey: Evaluating the efficiency of artificial intelligence and machine learning techniques on cyber security solutions. https://ieeexplore.ieee.org/abstract/document/10403908/

M. Puts, P. Daas, & Ton de Waal. (2015). Finding errors in Big Data. In Significance. https://rss.onlinelibrary.wiley.com/doi/10.1111/j.1740-9713.2015.00826.x

M. Zolghadri, C. Baron, & P. Girard. (2010). Modelling the mutual dependencies between product architectures and a network of partners. In International Journal of Product Development. https://www.semanticscholar.org/paper/fe0c0d8bb418dfd778640efb125c074299840635

Mahdi Hadj Ali, Yann Le Biannic, & Pierre-Henri Wuillemin. (2024). Reliable Estimation of Causal Effects Using Predictive Models. In Int. J. Artif. Intell. Tools. https://www.semanticscholar.org/paper/62589c2692274b15951bc216eb3cbe32437d5c73

Maheswara Reddy Basireddy. (2020). Leveraging Python AI for Robust Performance and Load Testing. In International Journal of Science and Research (IJSR). https://www.semanticscholar.org/paper/0f58053da01c672a4970ac1392e55acd04fce167

Mamadou H. Diallo, L. Naslavsky, T. Alspaugh, H. Ziv, & D. Richardson. (2008). Toward Architecture Evaluation through Ontology-Based Requirements-Level Scenarios. In Workshop on Algorithms and Data Structures. https://www.semanticscholar.org/paper/db2f3226b12b0c52d465ae774670b90dec2aa18b

Manikandan Natarajan. (2024). Product Lifecycle Management using AI. In International Journal For Multidisciplinary Research. https://www.ijfmr.com/research-paper.php?id=28137

Maohong Liao. (2024). Taking ChatGPT as an example to analyze the main technologies used in large language models. In Science and Technology of Engineering, Chemistry and Environmental Protection. https://www.semanticscholar.org/paper/df2311c0021d720e3ee8973a814c918e3f047136

Marcin Chrapek, Anjo Vahldiek-Oberwagner, Marcin Spoczynski, Scott Constable, Mona Vij, & Torsten Hoefler. (2024). Fortify Your Foundations: Practical Privacy and Security for Foundation Model Deployments In The Cloud. In ArXiv. https://arxiv.org/abs/2410.05930

Mar’ia Victoria Carro, Francisca Gauna Selasco, Denise Alejandra Mester, Margarita Gonzales, Mario A. Leiva, Maria Vanina Martinez, & Gerardo I. Simari. (2024). Do Large Language Models Show Biases in Causal Learning? In ArXiv. https://www.semanticscholar.org/paper/17bb17e343db012eb4de2e8b5304fefbce198762

Marianna Ciullo. (2024). Large Language Models: Ethics and Norms in the European Union. In 2024 IEEE International Conference on Metrology for eXtended Reality, Artificial Intelligence and Neural Engineering (MetroXRAINE). https://www.semanticscholar.org/paper/bf400cbbeb0c13f3d2c984a0e46a61efc1fa3da4

Marianna Nezhurina, Lucia Cipolina-Kun, Mehdi Cherti, & J. Jitsev. (2024). Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models. In ArXiv. https://www.semanticscholar.org/paper/32e086dd56041ddb63d9e9e210c29a7fdeabdb6d

Mario Fritz. (2024). Fundamental Risks in the Current Deployment of General-Purpose AI Models: What Have We (Not) Learnt From Cybersecurity? In ArXiv. https://arxiv.org/abs/2501.01435

Mark Haakman, Luís Cruz, Hennie Huijgens, & A. van Deursen. (2020). AI lifecycle models need to be revised. In Empirical Software Engineering. https://link.springer.com/article/10.1007/s10664-021-09993-1

Markus Anderljung, Joslyn Barnhart, Anton Korinek, Jade Leung, Cullen O’Keefe, Jess Whittlestone, S. Avin, Miles Brundage, Justin B. Bullock, D. Cass-Beggs, Ben Chang, Tantum Collins, Tim Fist, Gillian K. Hadfield, Alan Hayes, Lewis Ho, Sara Hooker, Eric Horvitz, Noam Kolt, … Kevin J. Wolf. (2023). Frontier AI Regulation: Managing Emerging Risks to Public Safety. In ArXiv. https://www.semanticscholar.org/paper/494b043fce4da2ecc7f87bc96f7c29a5278cca61

Matthew Arnold, Jeffrey Boston, Michael Desmond, E. Duesterwald, Benjamin Elder, Anupama Murthi, Jirí Navrátil, & Darrell Reimer. (2020). Towards Automating the AI Operations Lifecycle. In ArXiv. https://www.semanticscholar.org/paper/cbee77b20ced1bb96ee4877eb045aefa201bbdbc

Matthew Tassava, Cameron Kolodjski, Jordan Milbrath, Adorah Bishop, Nathan Flanders, Robbie Fetsch, Danielle Hanson, & Jeremy Straub. (2024). Development of an AI Anti-Bullying System Using Large Language Model Key Topic Detection. In ArXiv. https://arxiv.org/abs/2408.10417

Maximilian Kretzschmar, Maximilian Peter Dammann, Sebastian Schwoch, Elias Berger, Bernhard Saske, & Kristin Paetzold-Byhain. (2024). Key Concepts, Potentials and Obstacles for the Implementation of Large Language Models in Product Development. In Entwerfen Entwickeln Erleben 2024 : Menschen, Technik und Methoden in Produktentwicklung und Design. https://www.semanticscholar.org/paper/9769b3e5fb579a73d4d46efe2f19ed508e45185c

M.D. Takach & P. Lauritzen. (1995). Survey of magnetic core models. In Proceedings of 1995 IEEE Applied Power Electronics Conference and Exposition - APEC’95. https://ieeexplore.ieee.org/document/469077/

Md Tawfiqur Rahman. (2024). Harnessing AI for National Security: Bangladesh’s Technological Transformation. In International Journal of Scientific and Research Publications. https://www.semanticscholar.org/paper/d19a67dd93d6ef19c83d7efb4de90cd4efd3284c

Meirong Lin. (2024). Research on Development and Application of AI Agent for Travel Recommendation Driven by Large Language Model. In 2024 IEEE 2nd International Conference on Control, Electronics and Computer Technology (ICCECT). https://ieeexplore.ieee.org/document/10545805/

Meiziniu Li, Dongze Li, Jianmeng Liu, Jialun Cao, Yongqiang Tian, & S. Cheung. (2024). DLLens: Testing Deep Learning Libraries via LLM-aided Synthesis. In ArXiv. https://arxiv.org/abs/2406.07944

Melis Dokumacı. (2024). Legal Frameworks for AI Regulations. In Human Computer Interaction. https://www.semanticscholar.org/paper/09d9bae5bc69d20df47ad8a3fd1d54a4d7344787

Mengwei Xu, Dongqi Cai, Wangsong Yin, Shangguang Wang, Xin Jin, & Xuazhe Liu. (2024). Resource-efficient Algorithms and Systems of Foundation Models: A Survey. In ACM Comput. Surv. https://dl.acm.org/doi/10.1145/3706418

Mengwei Xu, Wangsong Yin, Dongqi Cai, Rongjie Yi, Daliang Xu, Qipeng Wang, Bingyang Wu, Yihao Zhao, Chen Yang, Shihe Wang, Qiyang Zhang, Zhenyan Lu, Li Zhang, Shangguang Wang, Yuanchun Li, Yunxin Liu, Xin Jin, & Xuanzhe Liu. (2024). A Survey of Resource-efficient LLM and Multimodal Foundation Models. In ArXiv. https://www.semanticscholar.org/paper/8ac21a1545a907fc64b54cde36bf41415608cd7d

Mesiono Mesiono, Nazli Fahada, I. Irwansyah, Diana Diana, & Andi Suhendra Siregar. (2024). SWOT Analysis of ChatGPT: Implications for Educational Practice and Research. In JMKSP (Jurnal Manajemen, Kepemimpinan, dan Supervisi Pendidikan). https://www.semanticscholar.org/paper/884947b274e13b7dc03fe59c68ff803042e69072

Michaela Regneri, Malte Hoffmann, Jurij Kost, N. Pietsch, Timothy Schulz, & Sabine Stamm. (2018). Analyzing Hypersensitive AI: Instability in Corporate-Scale Machine Learning. In ArXiv. https://www.semanticscholar.org/paper/d3462e9d394610fbe18c18b3916f1cdb0fa8e8fb

Mikhail Isaev, Nic McDonald, & R. Vuduc. (2023). Scaling Infrastructure to Support Multi-Trillion Parameter LLM Training. https://www.semanticscholar.org/paper/793f7284ccaa6c2cd530e6d405f5fa75bfd283e8

Minghao Shao, Abdul Basit, Ramesh Karri, & Muhammad Shafique. (2024). Survey of Different Large Language Model Architectures: Trends, Benchmarks, and Challenges. In IEEE Access. https://ieeexplore.ieee.org/document/10720163/

Minghong Zhou, Huaming Liao, & Feng Li. (2005). Schema Adaptation Under Multi-relation Dependencies. In International Conference on Grid and Cooperative Computing. https://www.semanticscholar.org/paper/129552319398be265e9bc8820117b47e7c9436e7

Miriam C. Buiten. (2024). Product liability for defective AI. In European Journal of Law and Economics. https://link.springer.com/article/10.1007/s10657-024-09794-z

Mitchell Goldburgh, Michael LaChance, Julia Komissarchik, Julia Patriarche, Joe Chapa, Oliver Chen, Priya Deshpande, Matthew Geeslin, Nina Kottler, Jennifer Sommer, Marcus Ayers, & Vedrana Vujic. (2024). 2023 Industry Perceptions Survey on AI Adoption and Return on Investment. In Journal of Imaging Informatics in Medicine. https://www.semanticscholar.org/paper/9a60569d74aa77ec3b26ab544bab5644da504e12

Mohamed Abdelaal. (2024). AI in Manufacturing: Market Analysis and Opportunities. In ArXiv. https://arxiv.org/abs/2407.05426

Mohamed Abdullahi Ali, Ng Keng Yap, A. Ghani, H. Zulzalil, N. Admodisastro, & Amin Arab Najafabadi. (2022). A Systematic Mapping of Quality Models for AI Systems, Software and Components. In Applied Sciences. https://www.mdpi.com/2076-3417/12/17/8700

Mohamed R. Shoaib, Heba M. Emara, & Jun Zhao. (2023). A Survey on the Applications of Frontier AI, Foundation Models, and Large Language Models to Intelligent Transportation Systems. In 2023 International Conference on Computer and Applications (ICCA). https://ieeexplore.ieee.org/document/10401518/

Moninder Singh, Gevorg Ghalachyan, Kush R. Varshney, & R. Bryant. (2021). An Empirical Study of Accuracy, Fairness, Explainability, Distributional Robustness, and Adversarial Robustness. In ArXiv. https://www.semanticscholar.org/paper/094b3b3a6d66d0c70c8d0e9539ae12f9a9590ff5

MU Hadi, R Qureshi, A Shah, M Irfan, & A Zafar. (2023). A survey on large language models: Applications, challenges, limitations, and practical usage. https://www.authorea.com/doi/full/10.36227/techrxiv.23589741.v3

Muhammad Usman Hadi, al tashi, Rizwan Qureshi, Abbas Shah, Muhammad Irfan, Anas Zafar, Muhammad Bilal Shaikh, Naveed Akhtar, Jia Wu, Seyedali Mirjalili, Qasem Al-Tashi, Amgad Muneer, M. Al-garadi, Gru Cnn, & T5 RoBERTa. (n.d.). Large Language Models: A Comprehensive Survey of its Applications, Challenges, Limitations, and Future Prospects. https://www.semanticscholar.org/paper/24de1048791bac4972ecc16d1c3c1de23691407d

Muhao Chen, Chaowei Xiao, Huan Sun, Lei Li, Leon Derczynski, A. Anandkumar, & Fei Wang. (2024). Combating Security and Privacy Issues in the Era of Large Language Models. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 5: Tutorial Abstracts). https://www.semanticscholar.org/paper/2563795cd4bdf1490c640b3885f6a68461213d3d

Mustafa Osman I. Elamin. (2024). AI Through the Ages: Unlocking Key Opportunities and Navigating Challenges in the History and Future of Artificial Intelligence. In International Journal of Religion. https://www.semanticscholar.org/paper/a5e6ea2f64a83a363d127aa1a28e6d7c0af87125

N Petit & J De Cooman. (2021). Models of Law and Regulation for AI. https://www.taylorfrancis.com/chapters/edit/10.4324/9780429198533-15/models-law-regulation-ai-nicolas-petit-jerome-de-cooman

N. Veselá, D. Hampel, Kateryna Yahelska, & V. Krasko. (2022). Preconditions for the formation of the investment policy of Ukraine as a key set of measures to ensure economic development. In Journal of Eastern European and Central Asian Research (JEECAR). https://www.semanticscholar.org/paper/8ae0fd5291a648bfac31bd015570c86c94f1437b

Nave Frost, Zachary Chase Lipton, Yishay Mansour, & Michal Moshkovitz. (2024). Partially Interpretable Models with Guarantees on Coverage and Accuracy. In International Conference on Algorithmic Learning Theory. https://www.semanticscholar.org/paper/1046864df6081b452841dc1bf0cd56b86fd8777f

Ned Cooper & Alex Zafiroglu. (2024). Constraining Participation: Affordances of Feedback Features in Interfaces to Large Language Models. In ArXiv. https://arxiv.org/abs/2408.15066

Neil Anderson, Aidan McGowan, Leo Galway, Philip Hanna, Matthew Collins, & David Cutting. (2023). Implementing Generative AI and Large Language Models in Education. In 2023 7th International Symposium on Innovative Approaches in Smart Technologies (ISAS). https://ieeexplore.ieee.org/document/10391517/

NevilleJennifer & JensenDavid. (2007). Relational Dependency Networks. In Journal of Machine Learning Research. https://www.semanticscholar.org/paper/561527a2647d74254dad48d9a78909fd80fe6732

Nguyen Quang Duc, Le Hai Son, Nguyen Duc Nhan, Nguyen Dich Nhat Minh, Le Thanh Huong, & D. V. Sang. (2024). Towards Comprehensive Vietnamese Retrieval-Augmented Generation and Large Language Models. In ArXiv. https://arxiv.org/abs/2403.01616

Nianqi Li, Siyu Yuan, Jiangjie Chen, Jiaqing Liang, Feng Wei, Zujie Liang, Deqing Yang, & Yanghua Xiao. (2024). Past Meets Present: Creating Historical Analogy with Large Language Models. In ArXiv. https://arxiv.org/abs/2409.14820

Nicola Fabiano. (2024). AI Act and Large Language Models (LLMs): When critical issues and privacy impact require human and ethical oversight. In ArXiv. https://arxiv.org/abs/2404.00600

Nima Shiri Harzevili, Jiho Shin, Junjie Wang, Song Wang, & Nachiappan Nagappan. (2023). Automatic Static Bug Detection for Machine Learning Libraries: Are We There Yet? In ArXiv. https://www.semanticscholar.org/paper/da3e48974d20056f42a72f3b5ce2999f9544b6a8

NN Kumar & P Sailaja. (2025). A Management Assessment on How Corporate Culture Affects Organizational Performance. https://www.taylorfrancis.com/chapters/edit/10.1201/9781003596721-84/management-assessment-corporate-culture-affects-organizational-performance-nukalapati-naresh-kumar-petikam-sailaja

Nova Spivack, Sam Douglas, Michelle Crames, & Tim Connors. (2024). Cognition is All You Need - The Next Layer of AI Above Large Language Models. In ArXiv. https://www.semanticscholar.org/paper/fa56be1738f4521d9b92c44c6dcfbedf5f6b95a3

NS Vasikarla, A Goel, ABM Alam, & M Nasir. (2025). An Interactive AI Solution for Market Research and Report Generation. https://link.springer.com/chapter/10.1007/978-3-031-82606-1_1

Nuthan Raj B M, Sandeep N, T. C. Bobby, & Ramaswamy Karthikeyan B. (2024). Development of AI Model for Robotic Vision Inspection of Sheet-Metal Components in Manufacturing. In INTERNATIONAL JOURNAL OF MULTIDISCIPLINARY RESEARCH AND ANALYSIS. https://www.semanticscholar.org/paper/6ba850928766aacd4f326b813d821fd73c0949a3

O. Zimmermann. (2015). Architectural Refactoring: A Task-Centric View on Software Evolution. In IEEE Software. https://ieeexplore.ieee.org/document/7057560/

Oscar J. Romero, John Zimmerman, Aaron Steinfeld, & A. Tomasic. (2023). Synergistic Integration of Large Language Models and Cognitive Architectures for Robust AI: An Exploratory Analysis. In ArXiv. https://arxiv.org/abs/2308.09830

Oyku Asikoglu & T. Simpson. (2010). A New Method for Evaluating Design Dependencies in Product Architectures. https://arc.aiaa.org/doi/10.2514/6.2012-5660

P. Chauhan, Swamini Chopra, & S. Thangaraju. (2019). Inter‐Dependency Relationships in High‐Entropy Alloys: Phase Stability Criteria. In Advanced Engineering Materials. https://onlinelibrary.wiley.com/doi/10.1002/adem.201900251

P Hofmann, J Jöhnk, D Protschky, & N Urbach. (2020). Developing Purposeful AI Use Cases-A Structured Method and Its Application in Project Management. https://www.fim-rc.de/Paperbibliothek/Veroeffentlicht/1025/wi-1025.pdf

P Kumar. (2024). Large language models (LLMs): survey, technical frameworks, and future challenges. In Artificial Intelligence Review. https://link.springer.com/article/10.1007/s10462-024-10888-y

P Kunama & S Leeratanavalee. (2022). All intra-regular and relationship between some regular submonoids of Relhyp ((m),(n)). In Int. J. Math. Comput. Sci. https://future-in-tech.net/17.1/R-KunamaLeeratanavalee.pdf

P Mehrotra, A Parab, & S Gulwani. (2024). Enhancing creativity in large language models through associative thinking strategies. In arXiv. https://arxiv.org/abs/2405.06715

P. Rosenbloom. (2010). An Architectural Approach to Statistical Relational AI. In StarAI@AAAI. https://www.semanticscholar.org/paper/f442eee9ff3f1a1fadfd15f63e7b5d929bf6ce1e

P. Strimling, Joel Krueger, & Simon Karlsson. (2024). GPT-4’s One-Dimensional Mapping of Morality: How the Accuracy of Country-Estimates Depends on Moral Domain. In ArXiv. https://arxiv.org/abs/2407.16886

P. Varbanov, Bohong Wang, Petro Kapustenko, P. Szármes, & Gábor Élő. (n.d.). Sustainability of Large AI Models: Balancing Environmental and Social Impact with Technology and Regulations. https://www.semanticscholar.org/paper/521c3c62b4a63144a8f64191b14d8b2a1b989cd8

P. Venkat Rangan & R. Ashany. (1988). The use of AI to secure communication in distributed systems for industrial applications. In Proceedings of the International Workshop on Artificial Intelligence for Industrial Applications. https://ieeexplore.ieee.org/document/13348/

Paolo Bacchiega, Davide Rusconi, Paolo Mereghetti, & F. Fontana. (2024). Refactoring of a Microservices Project Driven by Architectural Smell Detection. In 2024 IEEE 21st International Conference on Software Architecture Companion (ICSA-C). https://ieeexplore.ieee.org/document/10628266/

Paolo Faraboschi, Ellis Giles, Justin Hotard, Konstanty Owczarek, & Andrew Wheeler. (2024). Reducing the Barriers to Entry for Foundation Model Training. In ArXiv. https://arxiv.org/abs/2404.08811

Parsa Alian, Noor Nashid, M. Shahbandeh, Taha Shabani, & Ali Mesbah. (2024). Feature-Driven End-To-End Test Generation. https://www.semanticscholar.org/paper/c48614f334fbd7fc7e6dba0c49e53c2bdb1dd28b

Paulo Carreira, H. Galhardas, J. Pereira, & A. Wichert. (2007). On Handling One-to-Many Transformations in Relational Systems. In International Conference on Enterprise Information Systems. https://www.semanticscholar.org/paper/3cf98001e39ac8e0020de1b264b1876aeac75382

Pedro A. Ortega, M. Kunesch, Gr’egoire Del’etang, Tim Genewein, Jordi Grau-Moya, J. Veness, J. Buchli, Jonas Degrave, Bilal Piot, J. Pérolat, Tom Everitt, Corentin Tallec, Emilio Parisotto, Tom Erez, Yutian Chen, Scott E. Reed, Marcus Hutter, Nando de Freitas, & S. Legg. (2021). Shaking the foundations: delusions in sequence models for interaction and control. In ArXiv. https://www.semanticscholar.org/paper/bc031724d5323b294e22a895977928b79fbe8a29

Petter Törnberg. (2024). Best Practices for Text Annotation with Large Language Models. In ArXiv. https://www.semanticscholar.org/paper/b86363509341d205945e393941416978fff010fd

PH Padmanaban & YK Sharma. (2019). Implication of Artificial Intelligence in Software Development Life Cycle: A state of the art review. In 2019 IJRRA all rights reserved. https://www.researchgate.net/profile/Harish-Padmanaban-2/publication/377572222_Implication_of_Artificial_Intelligence_in_Software_Development_Life_Cycle_A_state_of_the_art_review/links/65ad54e5bf5b00662e333553/Implication-of-Artificial-Intelligence-in-Software-Development-Life-Cycle-A-state-of-the-art-review.pdf

Philip Resnik. (2024). Large Language Models are Biased Because They Are Large Language Models. In ArXiv. https://arxiv.org/abs/2406.13138

Pouya Pezeshkpour, Eser Kandogan, Nikita Bhutani, Sajjadur Rahman, Tom Mitchell, & Estevam R. Hruschka. (2024). Reasoning Capacity in Multi-Agent Systems: Limitations, Challenges and Human-Centered Solutions. In ArXiv. https://arxiv.org/abs/2402.01108

Prepare for truly useful large language models. (2023). In Nature Biomedical Engineering. https://www.semanticscholar.org/paper/01568d5b3777e0c123944b09095fa7ae5f791718

Puneet Mathur. (2018). Monetizing Finance Machine Learning. In Machine Learning Applications Using Python. https://www.semanticscholar.org/paper/a56c5969fe892da29f3f40a0e3a83c3724db6714

Q Zheng, J Wang, & Y Shen. (2024). Overview and Trend of Large-scale Model Deployment Mode. https://ieeexplore.ieee.org/abstract/document/10608242/

Qin Chen, Jinfeng Ge, Huaqing Xie, Xingcheng Xu, & Yanqing Yang. (2023). Large Language Models at Work in China’s Labor Market. In ArXiv. https://arxiv.org/abs/2308.08776

Qingbo Hao, Chundong Wang, Yingyuan Xiao, & Hao Lin. (2022). IMGC-GNN: A multi-granularity coupled graph neural network recommendation method based on implicit relationships. In Applied Intelligence (Dordrecht, Netherlands). https://www.semanticscholar.org/paper/1ec868f75c865147364ef0ac641482ea136696ec

R Chetty, JN Friedman, & JE Rockoff. (2014). Measuring the impacts of teachers I: Evaluating bias in teacher value-added estimates. In American economic review. https://www.aeaweb.org/articles?id=10.1257/aer.104.9.2593

R. Crundwell. (2005). Alternative Strategies for Large Scale Student Assessment in Canada: Is Value-Added Assessment One Possible Answer. In Canadian Journal of Educational Administration and Policy. https://www.semanticscholar.org/paper/195b0b1c98034877d5da66977f2cbf0766e5ba31

R. Demara & H. Kitano. (1992). Benchmarking performance of massively parallel AI architectures. In [Proceedings 1992] The Fourth Symposium on the Frontiers of Massively Parallel Computation. https://ieeexplore.ieee.org/document/234865/

R. E. Wendrich. (2020). CREATIVE THINKING: COMPUTATIONAL TOOLS IMBUED WITH AI. In Proceedings of the Design Society: DESIGN Conference. https://www.cambridge.org/core/journals/proceedings-of-the-design-society-design-conference/article/creative-thinking-computational-tools-imbued-with-ai/838A552D3662AD4926CF36B3A4E67CC9

R. Isaev & A. Podvesovskii. (2020). Verification of Cause-and-Effect Relationships in Cognitive Models Using Visualization Metaphors of Fuzzy Cognitive Maps. In Scientific Visualization. https://www.semanticscholar.org/paper/4d50e828cc8e29f5dabc829289210f7f9f207989

R Ishizaki & M Sugiyama. (2025). Ultimate intelligence and ethics. https://philpapers.org/rec/ISHUIA

R. Manning, R. Webb, F. G. Garcia Gunning, & M. Power. (2014). SOAs for Phase-Based Optical Signal Processing. In 2014 IEEE Photonics Society Summer Topical Meeting Series. https://ieeexplore.ieee.org/document/6903012

R Mostaghel, P Oghazi, & V Parida. (2022). Digitalization driven retail business model innovation: Evaluation of past and avenues for future research trends. https://www.sciencedirect.com/science/article/pii/S0148296322003095

R Mühlhoff & H Ruschemeier. (2024). Regulating AI with purpose limitation for models. In Journal of AI Law and Regulation. https://aire.lexxion.eu/data/article/19395/pdf/aire_2024_01-006.pdf

R. Peinl & Johannes Wirth. (2023). Evaluation of medium-large Language Models at zero-shot closed book generative question answering. In ArXiv. https://arxiv.org/abs/2305.11991

R. Steele, K. Min, & Amanda Lo. (2012). Personal health record architectures: Technology infrastructure implications and dependencies. In J. Assoc. Inf. Sci. Technol. https://onlinelibrary.wiley.com/doi/10.1002/asi.22635

R. Thomas McCoy, Shunyu Yao, Dan Friedman, Mathew D. Hardy, & Thomas L. Griffiths. (2024). Embers of autoregression show how large language models are shaped by the problem they are trained to solve. In Proceedings of the National Academy of Sciences of the United States of America. https://pnas.org/doi/10.1073/pnas.2322420121

R. Vasanth & Dinesh Jackson Samuel. (2020). Providing Data Security in Deep Learning by Using Genomic Procedure. https://www.semanticscholar.org/paper/e1193aac109c22a20f6d35e916ebe44d7d6f8262

Rachid Ejjami. (2024). Holistic AI-Enhanced Marketing Framework Theory: Bridging Human Creativity and AI for Ethical Marketing. In International Journal For Multidisciplinary Research. https://www.ijfmr.com/research-paper.php?id=28169

RC Basole & AI Accenture. (2021). Visualizing the Evolution of the AI Ecosystem. In HICSS. https://www.researchgate.net/profile/Rahul-Basole/publication/345119002_Visualizing_the_Evolution_of_the_AI_Ecosystem/links/5fd355e1a6fdccdcb8b830a4/Visualizing-the-Evolution-of-the-AI-Ecosystem.pdf

RE Gomory. (1965). On the relation between integer and noninteger solutions to linear programs. In Proceedings of the National Academy of Sciences. https://www.pnas.org/doi/abs/10.1073/pnas.53.2.260

Richard Shan. (2024). Language Artificial Intelligence at a Crossroads: Deciphering the Future of Small and Large Language Models. In Computer. https://www.semanticscholar.org/paper/b43e7d90706aa348896aefde2bc768120edb0128

Rida Hamid & S. Brohi. (2024). A Review of Large Language Models in Healthcare: Taxonomy, Threats, Vulnerabilities, and Framework. In Big Data and Cognitive Computing. https://www.mdpi.com/2504-2289/8/11/161

Rishub Tamirisa, Bhrugu Bharathi, Long Phan, Andy Zhou, Alice Gatti, Tarun Suresh, Maxwell Lin, Justin Wang, Rowan Wang, Ron Arel, Andy Zou, Dawn Song, Bo Li, Dan Hendrycks, & Mantas Mazeika. (2024). Tamper-Resistant Safeguards for Open-Weight LLMs. In ArXiv. https://arxiv.org/abs/2408.00761

Ritesh Singh, Swati Singh, & Amulya Singh. (2024). Landmark events, major trends, and the future of AI research: history, promise, hype. In 2024 2nd International Conference on Artificial Intelligence and Machine Learning Applications Theme: Healthcare and Internet of Things (AIMLA). https://ieeexplore.ieee.org/document/10531477/

RK Biswas, RA Banu, & MN Islam. (2003). … chemical properties of D2EHPA: Part 2. Distribution, dimerization and acid dissociation constants in n-hexane/1 M (Na+, H+) SO42− system, interfacial adsorption and …. In Hydrometallurgy. https://www.sciencedirect.com/science/article/pii/S0304386X02002128

Romain Cosentino & Sarath Shekkizhar. (2024). Reasoning in Large Language Models: A Geometric Perspective. In ArXiv. https://arxiv.org/abs/2407.02678

Rongcun Wang, Senlei Xu, Xingyu Ji, Yuan Tian, Lina Gong, & Ke Wang. (2024). An extensive study of the effects of different deep learning models on code vulnerability detection in Python code. In Automated Software Engineering. https://link.springer.com/article/10.1007/s10515-024-00413-4

Rongwu Xu, Zehan Qi, Zhijiang Guo, Cunxiang Wang, Hongru Wang, Yue Zhang, & Wei Xu. (2024). Knowledge Conflicts for LLMs: A Survey. In Conference on Empirical Methods in Natural Language Processing. https://www.semanticscholar.org/paper/ab8e6df5001dbb9b48445220099425aff536b3e8

Ru-Xi Ding, I. Palomares, Xueqing Wang, Guo-Rui Yang, Bingsheng Liu, Yucheng Dong, E. Herrera-Viedma, & F. Herrera. (2020). Large-Scale decision-making: Characterization, taxonomy, challenges and future directions from an Artificial Intelligence and applications perspective. In Inf. Fusion. https://www.semanticscholar.org/paper/a43ccf4935385066b041bb557e46ce1311f43e57

S AlZu’bi, A Mughaid, & F Quiam. (2024). Exploring the capabilities and limitations of chatgpt and alternative big language models. http://ojs.bonviewpress.com/index.php/AIA/article/view/820

S. Armstrong & Kaj Sotala. (2015). How We’re Predicting AI - or Failing to. https://link.springer.com/chapter/10.1007/978-3-319-09668-1_2

S Banerjee, G Surendra, & SK Nandy. (2008). On the effectiveness of phase based regression models to trade power and performance using dynamic processor adaptation. In Journal of Systems Architecture. https://www.sciencedirect.com/science/article/pii/S1383762108000301

S. D. Porcellinis, G. Oliva, S. Panzieri, & R. Setola. (2009). A Holistic-Reductionistic Approach for Modeling Interdependencies. In Critical Infrastructure Protection. https://link.springer.com/chapter/10.1007/978-3-642-04798-5_15

S. D’Elia. (2019). Trademark evaluation in the theory of intellectual property. https://www.semanticscholar.org/paper/78bcbeba91159aef7b01a75d1d349ca071915ad7

S Dilmaghani, MR Brust, & G Danoy. (2019). Privacy and security of big data in AI systems: A research and standards perspective. https://ieeexplore.ieee.org/abstract/document/9006283/

S. Ghoshal & Eleanor Westney. (1991). Organizing competitor analysis systems. In Southern Medical Journal. https://www.semanticscholar.org/paper/89615f39869fe677e99cce9dba20a5a9163383cf

S Kakutani. (1948). On equivalence of infinite product measures. In Annals of Mathematics. https://www.jstor.org/stable/1969123

S. Kanungo & Prof.Lavkesh patidar. (2019). A Survey on Solar Energy Prediction using AI based Techniques. https://www.semanticscholar.org/paper/e950cd2ef0f3a4c542a283258357b00765372054

S Kommrusch. (1912). Artificial intelligence techniques for security vulnerability prevention. In arXiv. https://arxiv.org/abs/1912.06796

S Konakanchi. (2025). Artificial Intelligence in Code Optimization and Refactoring. In Journal of Data and Digital Innovation (JDDI). http://datalensjourna.com/index.php/JDDI/article/view/5

S. Nakajima. (2019). Distortion and Faults in Machine Learning Software. In ArXiv. https://www.semanticscholar.org/paper/9ea68081aa5797b8db2ff19516b55b480e6c742d

S. Phadnis & Charles H. Fine. (2015). End-to-end Supply Chain Strategies. https://journals.aom.org/doi/10.5465/ambpp.2015.11422abstract

S Podduturi. (2025). AI-Driven Code Optimization: Leveraging ML to Refactor Legacy Codebases. In North American Journal of Engineering Research. http://najer.org/najer/article/view/115

S Shukla. (2024). The Role Of Gen AI In The Data Dependence Graph Generation. https://www.researchgate.net/profile/Shubham-Shukla-20/publication/389279668_THE_ROLE_OF_GEN_AI_IN_THE_DATA_DEPENDENCE_GRAPH_GENERATION/links/67bcfa7ff5cb8f70d5be9075/THE-ROLE-OF-GEN-AI-IN-THE-DATA-DEPENDENCE-GRAPH-GENERATION.pdf

S. Suthaharan. (2016). Deep Learning Models. https://www.semanticscholar.org/paper/3378016189704ea9fb17b401fb85d91164b2bb9a

S. Zouggar, M. Zolghadri, & P. Girard. (2009). Modelling product and partners network architectures to identify hidden dependencies. https://www.semanticscholar.org/paper/d35d904aab58cafcfd55a6035b95f15253ba2cee

SA Mess, AJ Mackey, & DE Yarowsky. (2025). Artificial Intelligence Scribe and Large Language Model Technology in Healthcare Documentation: Advantages, Limitations, and Recommendations. https://journals.lww.com/prsgo/fulltext/2025/01000/artificial_intelligence_scribe_and_large_language.31.aspx

Sabuj Laskar, Md. Hasanur Rahman, Bohan Zhang, & Guanpeng Li. (2022). Characterizing Deep Learning Neural Network Failures Between Algorithmic Inaccuracy and Transient Hardware Faults. In 2022 IEEE 27th Pacific Rim International Symposium on Dependable Computing (PRDC). https://ieeexplore.ieee.org/document/10027807/

Saleh Ashkboos, Iman Mirzadeh, Keivan Alizadeh-Vahid, M. Sekhavat, Moin Nabi, Mehrdad Farajtabar, & Fartash Faghri. (2024). Computational Bottlenecks of Training Small-scale Large Language Models. In ArXiv. https://arxiv.org/abs/2410.19456

Samir Mittal. (2017). Cognitive Computing Architectures for Machine (Deep) Learning at Scale. https://www.mdpi.com/2504-3900/1/3/186

Sandra Johnson & David Hyland-Wood. (2024). A Primer on Large Language Models and their Limitations. In ArXiv. https://arxiv.org/abs/2412.04503

Sangita Chakraborty, N. M. Jyothi, Sushil Lekhi, U. Dutta, Sachin Dasrath Mestry, & Ritesh Prasad. (2023). Multi Technology Ensembled Optimized Enterprise Architecture for Retail Industry. In 2023 International Conference on Computational Intelligence for Information, Security and Communication Applications (CIISCA). https://ieeexplore.ieee.org/document/10403585/

Satya R. Jaladi, Zhimin Chen, Narahari R. Malayanur, Raja M. Macherla, & Bing Li. (2022). End-To-End Training and Testing Gamification Framework to Learn Human Highway Driving. In 2022 IEEE 25th International Conference on Intelligent Transportation Systems (ITSC). https://ieeexplore.ieee.org/document/9922129/

Scott Krig. (2016). Feature Learning and Deep Learning Architecture Survey. https://www.semanticscholar.org/paper/d3ae09dac3d5ab3cf76e5d7ab6a46fbbae735dfa

Serdar Çakır. (2017). Phase-based techniques for image and video processing applications. https://www.semanticscholar.org/paper/be81d316a6a9d1a6c18456271ef9c3a3b8a961a2

Seth Poulsen, Sami Sarsa, J. Prather, Juho Leinonen, Brett A. Becker, Arto Hellas, Paul Denny, & Brent N. Reeves. (2024). Solving Proof Block Problems Using Large Language Models. In Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1. https://www.semanticscholar.org/paper/f1c42a9b6f759960dda0afb9ecd134da58b3ad96

Sha Yuan, Hanyu Zhao, Shuai Zhao, Jiahong Leng, Yangxiao Liang, Xiaozhi Wang, Jifan Yu, Xin Lv, Zhou Shao, Jiaao He, Yankai Lin, Xu Han, Zhenghao Liu, Ning Ding, Yongming Rao, Yizhao Gao, L. Zhang, Ming Ding, Cong Fang, … Jie Tang. (2022). A Roadmap for Big Model. In ArXiv. https://arxiv.org/abs/2203.14101

Shalom Lappin. (2023). Assessing the Strengths and Weaknesses of Large Language Models. In Journal of Logic, Language and Information. https://link.springer.com/article/10.1007/s10849-023-09409-x

Shani Goren, Ido Galil, & Ran El-Yaniv. (2024). Hierarchical Selective Classification. In ArXiv. https://arxiv.org/abs/2405.11533

Sheela Raju Kurupathi & W. Maass. (2020). Survey on Federated Learning Towards Privacy Preserving AI. In Computer Science & Information Technology (CS & IT). https://www.semanticscholar.org/paper/1a7fc8172b748c3777ecc5138d053e174692366d

Sherry Yang, Ofir Nachum, Yilun Du, Jason Wei, P. Abbeel, & D. Schuurmans. (2023). Foundation Models for Decision Making: Problems, Methods, and Opportunities. In ArXiv. https://www.semanticscholar.org/paper/2ebd5df74980a37370b0bcdf16deff958289c041

Shervin Minaee, Tomáš Mikolov, Narjes Nikzad, M. Chenaghlu, R. Socher, Xavier Amatriain, & Jianfeng Gao. (2024). Large Language Models: A Survey. In ArXiv. https://arxiv.org/abs/2402.06196

Shuo Wang, Hongsheng Hu, Jiamin Chang, Benjamin Zi Hao Zhao, Qi Alfred Chen, & Minhui Xue. (2024). DNN-GP: Diagnosing and Mitigating Model’s Faults Using Latent Concepts. In USENIX Security Symposium. https://www.semanticscholar.org/paper/305457b6d5465dbf477d09843c096b4fe6eb76ab

Silvia Terragni, Hoang Cuong, Joachim Daiber, Pallavi Gudipati, & Pablo N. Mendes. (2024). Evaluating Cost-Accuracy Trade-offs in Multimodal Search Relevance Judgements. In ArXiv. https://www.semanticscholar.org/paper/6da14989f523851f4480113f0f426f8267799602

Simon Thorne. (2024). Understanding and Evaluating Trust in Generative AI and Large Language Models for Spreadsheets. In ArXiv. https://arxiv.org/abs/2412.14062

SK Pattanayak. (2022). Generative AI for Market Analysis in Business Consulting: Revolutionizing Data Insights and Competitive Intelligence. https://www.researchgate.net/profile/Suprit-Kumar-Pattanayak/publication/385882153_Generative_AI_for_Market_Analysis_in_Business_Consulting_Revolutionizing_Data_Insights_and_Competitive_Intelligence/links/6738d6b169c07a411448f789/Generative-AI-for-Market-Analysis-in-Business-Consulting-Revolutionizing-Data-Insights-and-Competitive-Intelligence.pdf

Sonali Singh, Faranak Abri, & A. Namin. (2023). Exploiting Large Language Models (LLMs) through Deception Techniques and Persuasion Principles. In 2023 IEEE International Conference on Big Data (BigData). https://ieeexplore.ieee.org/document/10386814/

Sri Handila Mirwan, Puti Lenggo Ginny, Dirmansyah Darwin, Rahmat Ghazali, & M. N. J. Lenas. (2023). Using Artificial Intelligence (AI) in Developing Marketing Strategies. In International Journal of Applied Research and Sustainable Sciences. https://www.semanticscholar.org/paper/501dbf8de3e11c3569c8b1c3b23e242e3e548299

SS Joshi & P Tsiotras. (2023). Non-Trivial Query Sampling For Efficient Learning To Plan. In arXiv. https://arxiv.org/abs/2303.06737

Stéphane Bura. (2016). AI and the future of operating systems. In Inf. Serv. Use. https://www.semanticscholar.org/paper/f436eb0882f69e5c3454618fd65d9fbf1c4d44b2

Stephen Jose Hanson, Vivek Yadav, & C. Hanson. (2023). Dense Sample Deep Learning. In Neural Computation. https://arxiv.org/abs/2307.10991

Subharun Pal. (2023). The Future of Large Language Models: A Futuristic Dissection on AI and Human Interaction. https://www.semanticscholar.org/paper/47a5211f10c58c4187c95ce071418f0a0ef6d745

Sudipto Baral, Sajal Saha, & Anwar Haque. (2024). An Adaptive End-to-End IoT Security Framework Using Explainable AI and LLMs. In 2024 IEEE 10th World Forum on Internet of Things (WF-IoT). https://ieeexplore.ieee.org/document/10811456/

Sumanth Chennupati, S. Nooka, Shagan Sah, & R. Ptucha. (2020). Adaptive Hierarchical Decomposition of Large Deep Networks. In ArXiv. https://www.semanticscholar.org/paper/70d6b4777509ccd913a81de59eb45fc6cfeada6b

Sumit Pai, Sounak Lahiri, Ujjwal Kumar, K. Baksi, Elijah Soba, Michael Suesserman, Nirmala Pudota, Jon Foster, Edward Bowen, & Sanmitra Bhattacharya. (2023). Exploration of Open Large Language Models for eDiscovery. In Proceedings of the Natural Legal Language Processing Workshop 2023. https://aclanthology.org/2023.nllp-1.17/

Suncong Zheng, Jiaming Xu, P. Zhou, Hongyun Bao, Zhenyu Qi, & Bo Xu. (2016). A neural network framework for relation extraction: Learning entity semantic and relation pattern. In Knowl. Based Syst. https://linkinghub.elsevier.com/retrieve/pii/S0950705116303501

Swagata Ashwani, Kshiteesh Hegde, Nishith Reddy Mannuru, Mayank Jindal, Dushyant Singh Sengar, Krishna Chaitanya Rao Kathala, Dishant Banga, Vinija Jain, & Aman Chadha. (2024). Cause and Effect: Can Large Language Models Truly Understand Causality? In ArXiv. https://arxiv.org/abs/2402.18139

T. C. Silva & Liang Zhao. (2012). Preventing Error Propagation in Semi-supervised Learning. In International Symposium on Neural Networks. https://www.semanticscholar.org/paper/e36e8ae3eae84888516067f375ab823ad506ecb4

T. C. Silva & Liang Zhao. (2013). Detecting and Preventing Error Propagation via Competitive Learning. In Neural networks : the official journal of the International Neural Network Society. https://linkinghub.elsevier.com/retrieve/pii/S1877050912007351

T Grote. (2023). The allure of simplicity: On interpretable machine learning models in healthcare. In Philosophy of Medicine. https://philmed.pitt.edu/philmed/article/view/139

T Hagendorff & K Wezel. (2020). 15 challenges for AI: or what AI (currently) can’t do. In Ai & Society. https://link.springer.com/article/10.1007/s00146-019-00886-y

T. Holmes & Uwe Zdun. (2018). Refactoring Architecture Models for Compliance with Custom Requirements. In Proceedings of the 21th ACM/IEEE International Conference on Model Driven Engineering Languages and Systems. https://dl.acm.org/doi/10.1145/3239372.3239379

T. M. Valentini, T. Assis, D. Falcão, G. Taranto, A. D. Bomfim, F. R. M. Alves, & S. Gomes. (2016). Database adequacy for on-line dynamic security assessment tools. In 2016 IEEE Power and Energy Society General Meeting (PESGM). https://www.semanticscholar.org/paper/955dbb6fae08dca89334af1bfae6a5206fcf935a

T. Neller, John DeNero, D. Klein, Sven Koenig, W. Yeoh, Xiaoming Zheng, K. Daniel, A. Nash, Z. Dodds, G. Carenini, D. Poole, & Chris Brooks. (2010). Model AI Assignments. In EAAI. https://www.semanticscholar.org/paper/290d527fc00b2a7956231f5599f5b48e7710acea

T Raz, M Shalyt, E Leibtag, R Kalisch, & Y Hadad. (2025). From Euler to AI: Unifying Formulas for Mathematical Constants. https://arxiv.org/abs/2502.17533

T Zhang, M Xie, & M Horigome. (2006). Availability and reliability of k-out-of-(M+ N): G warm standby systems. In Reliability Engineering & System Safety. https://www.sciencedirect.com/science/article/pii/S0951832005000542

TA Kheya, MR Bouadjenek, & S Aryal. (2024). The pursuit of fairness in artificial intelligence models: A survey. In arXiv. https://arxiv.org/abs/2403.17333

Tao Li, Vivek Gupta, Maitrey Mehta, & Vivek Srikumar. (2019). A Logic-Driven Framework for Consistency of Neural Models. In ArXiv. https://www.semanticscholar.org/paper/ec9446482c8448911cbc7c98a676fcd156ab20af

Thomas Faseth, Michael Winkler, H. Arthaber, & G. Magerl. (2011). The influence of multipath propagation on phase-based narrowband positioning principles in UHF RFID. In 2011 IEEE-APS Topical Conference on Antennas and Propagation in Wireless Communications. https://ieeexplore.ieee.org/document/6046829/

Tianhao Shen, Renren Jin, Yufei Huang, Chuang Liu, Weilong Dong, Zishan Guo, Xinwei Wu, Yan Liu, & Deyi Xiong. (2023). Large Language Model Alignment: A Survey. In ArXiv. https://arxiv.org/abs/2309.15025

Tianyang Wang, Ziqian Bi, Yichao Zhang, Ming Liu, Weiche Hsieh, Pohsun Feng, Lawrence K.Q. Yan, Yizhu Wen, Benji Peng, Junyu Liu, Keyu Chen, Sen Zhang, Ming Li, Chuanqi Jiang, Xinyuan Song, Junjie Yang, Bowen Jing, Jintao Ren, Jun-Jie Song, … Qian Niu. (2024). Deep Learning Model Security: Threats and Defenses. In ArXiv. https://arxiv.org/abs/2412.08969

Timothy R. McIntosh, Teo Susnjak, Tong Liu, Paul Watters, & Malka N. Halgamuge. (2024). The Inadequacy of Reinforcement Learning From Human Feedback—Radicalizing Large Language Models via Semantic Vulnerabilities. In IEEE Transactions on Cognitive and Developmental Systems. https://www.semanticscholar.org/paper/76eb8409fccfe15a4d7ef8a8bb5ad0eddd097bd4

Ting Fang Tan, Kabilan Elangovan, J. Ong, Nigam Shah, J. Sung, T. Wong, Lan Xue, Nan Liu, Haibo Wang, C. Kuo, Simon Chesterman, Zee Kin Yeong, & Daniel Ting. (2024). A Proposed S.C.O.R.E. Evaluation Framework for Large Language Models : Safety, Consensus, Objectivity, Reproducibility and Explainability. In ArXiv. https://arxiv.org/abs/2407.07666

Tomohiko Takagi, T. Utsumi, & Z. Furukawa. (2013). Back-to-Back Testing Framework Using a Machine Learning Method. https://www.semanticscholar.org/paper/1110f0f158258e449dc1870418ee107fabbefd0c

Tosiron Adegbija & A. Gordon-Ross. (2014). Dynamic Phase-Based Optimization of Embedded Systems. In 2014 IEEE Computer Society Annual Symposium on VLSI. https://ieeexplore.ieee.org/document/6903366

Touseef Iqbal & Shaima Qureshi. (2020). The survey: Text generation models in deep learning. In Journal of King Saud University - Computer and Information Sciences. https://linkinghub.elsevier.com/retrieve/pii/S1319157820303360

Trewinshari, M. Ringel, BranhamStacy, S. LaseckiWalter, AzenkotShiri, BleuelNicole, JenkinsPhill, & P. BighamJeffrey. (2020). Workshop on AI fairness for people with disabilities. In ACM Sigaccess Accessibility and Computing. https://www.semanticscholar.org/paper/f977a50ffc82f00a6f999f92b5cccdf797194372

Tula Masterman, Sandi Besen, Mason Sawtell, & Alex Chao. (2024). The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey. In ArXiv. https://arxiv.org/abs/2404.11584

Upol Ehsan, Elizabeth A Watkins, Philipp Wintersberger, Carina Manger, Sunnie S. Y. Kim, N. V. Berkel, A. Riener, & Mark O. Riedl. (2024). Human-Centered Explainable AI (HCXAI): Reloading Explainability in the Era of Large Language Models (LLMs). In Extended Abstracts of the CHI Conference on Human Factors in Computing Systems. https://dl.acm.org/doi/10.1145/3613905.3636311

Urja Pawar, Christian Beder, Ruairi O’Reilly, & Donna O’Shea. (2024). On the Impact of Neighbourhood Sampling to Satisfy Sufficiency and Necessity Criteria in Explainable AI. In CLEaR. https://www.semanticscholar.org/paper/602fbe5d96ad0234a8c9ca1c2adee6c1a51bd283

V Gadepally, J Goodwin, J Kepner, & A Reuther. (2019). Ai enabling technologies: A survey. https://arxiv.org/abs/1905.03592

V Kharchenko, H Fesenko, & O Illiashenko. (2022). Quality models for artificial intelligence systems: characteristic-based approach, development and application. In Sensors. https://www.mdpi.com/1424-8220/22/13/4865

V KOLLURI. (2014). VULNERABILITIES: EXPLORING RISKS IN AI MODELS AND ALGORITHMS. https://www.researchgate.net/profile/Venkateswaranaidu-Kolluri/publication/380729855_AN_IN-DEPTH_EXPLORATION_OF_UNVEILING_VULNERABILITIES_EXPLORING_RISKS_IN_AI_MODELS_AND_ALGORITHMS/links/664c0b3022a7f16b4f3e6c8c/AN-IN-DEPTH-EXPLORATION-OF-UNVEILING-VULNERABILITIES-EXPLORING-RISKS-IN-AI-MODELS-AND-ALGORITHMS.pdf

V. Liagkou, Evangelia Filiopoulou, George Fragiadakis, Mara Nikolaidou, & C. Michalakelis. (2024). The cost perspective of adopting Large Language Model-as-a-Service. In 2024 IEEE International Conference on Joint Cloud Computing (JCC). https://ieeexplore.ieee.org/document/10685415/

Vaikunth Thukral, Lawrence Latvala, Mark Swenson, & Jeff Horn. (2023). Customer journey optimisation using large language models: Best practices and pitfalls in generative AI. In Applied Marketing Analytics: The Peer-Reviewed Journal. https://www.semanticscholar.org/paper/3001b24de70cec1090cfea4eee99b01ff05a9bd9

Valerie G. Eslick. (2012). Book Review: Interdependency and Care over the Lifecourse (Relationships and Resources). In Sociological Research Online. https://www.semanticscholar.org/paper/d6ef72c3bebc3f3a4f88d17665b031797a1696b4

Veronica Kecki & Alan Said. (2024). Understanding Fairness in Recommender Systems: A Healthcare Perspective. In ACM Conference on Recommender Systems. https://www.semanticscholar.org/paper/48331aa835e8526d2435a04ee55017e03fd11b14

Vibha Gaur & Anuja Soni. (2012). A Novel Approach to Explore Inter Agent Dependencies from User Requirements. In Procedia Technology. https://linkinghub.elsevier.com/retrieve/pii/S2212017312000941

Vincenzo Laveglia & E. Trentin. (2018). A Refinement Algorithm for Deep Learning via Error-Driven Propagation of Target Outputs. In IAPR International Workshop on Artificial Neural Networks in Pattern Recognition. https://www.semanticscholar.org/paper/05d7124ab5374cb26d52dd7bbab84bc8ddc9e5cb

Vladislavs Minkevics & Jānis Kampars. (2020). Methods, Models and Techniques to Improve Information System’s Security in Large Organizations. In International Conference on Enterprise Information Systems. https://www.semanticscholar.org/paper/26bf03cb532b3e20f247886aa635724eafe70f90

W Brewer, A Gainaru, F Suter, & F Wang. (2024). AI-coupled HPC workflow applications, middleware and performance. https://arxiv.org/abs/2406.14315

W. F. Samayoa, M. Crespo, A. Cicuttin, & Sergio Carrato. (2023). A Survey on FPGA-Based Heterogeneous Clusters Architectures. In IEEE Access. https://ieeexplore.ieee.org/document/10158531/

W Uzair & S Naz. (2023). Six-Tier Architecture for AI-Generated Software Development: A Large Language Models Approach. https://www.researchsquare.com/article/rs-3086026/latest

W Zhang. (2023). Large Decision Models. In IJCAI. https://www.ijcai.org/proceedings/2023/0808.pdf

W. Ziarko & Ning Shan. (1995). Discovering attribute relationships, dependencies and rules by using rough sets. In Proceedings of the Twenty-Eighth Annual Hawaii International Conference on System Sciences. https://ieeexplore.ieee.org/document/375608/

Waddah Saeed & C. Omlin. (2021). Explainable AI (XAI): A Systematic Meta-Survey of Current Challenges and Future Opportunities. In ArXiv. https://linkinghub.elsevier.com/retrieve/pii/S0950705123000230

Wang Na-n. (2015). CREDIBILITY MODELS UNDER THE ENTROPY LOSS FUNCTION. In Journal of Mathematics. https://www.semanticscholar.org/paper/4b7fce4760ad6c96b625fe5e5b82b3ad5ab0b773

Wang Wei-ping. (2006). Cause-and-Effect Relationships Tracing in Analysis of Large-scale Campaign Simulation. In Computer Simulation. https://www.semanticscholar.org/paper/6d75f2a8e45af0b68ddeadd06483d342a7c07dca

Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Z. Chen, Jinhao Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, … Ji-rong Wen. (2023). A Survey of Large Language Models. In ArXiv. https://arxiv.org/abs/2303.18223

Wei Jie-yun. (2012). Teaching Reform on Food Standards and Regulations. In Journal of Anhui Agricultural Sciences. https://www.semanticscholar.org/paper/62c004f7822b847a521ed077f6ef9c793a3ab21a

Wei Liu, R. Tan, G. Cao, Fei Yu, & Hui Li. (2019). Creative design through knowledge clustering and case-based reasoning. In Engineering with Computers. https://www.semanticscholar.org/paper/88aba4c0264a5a6a2e8d4d6886684459a1d0d3bc

Wei Zhou, Xiaogang Zhu, Qing-Long Han, Lin Li, Xiao Chen, Sheng Wen, & Yang Xiang. (2025). The Security of Using Large Language Models: A Survey with Emphasis on ChatGPT. In IEEE/CAA Journal of Automatica Sinica. https://ieeexplore.ieee.org/document/10751746/

Wenbin Zhang. (2024). AI fairness in practice: Paradigm, challenges, and prospects. In AI Mag. https://www.semanticscholar.org/paper/84cf8f970538861e1efbe3e17cb54e427c186c27

Wenbo Zhang, Aditya Majumdar, & Amulya Yadav. (2024). CHAI for LLMs: Improving Code-Mixed Translation in Large Language Models through Reinforcement Learning with AI Feedback. In ArXiv. https://www.semanticscholar.org/paper/06c1ec31219d68f0ffca74f6ee4c22acd6664a5b

X Li, S Zhou, Y Zhao, & B Yang. (2023). Marine and land economy–energy–environment systems forecasting by novel structural-adaptive fractional time-delay nonlinear systematic grey model. https://www.sciencedirect.com/science/article/pii/S0952197623009612

X Liu, J Zhao, W Chen, M Tan, & Y Su. (2024). BET: Explaining Deep Reinforcement Learning through The Error-Prone Decisions. In arXiv. https://arxiv.org/abs/2401.07263

X Tu, Z He, Y Huang, ZH Zhang, M Yang, & J Zhao. (2024). An overview of large AI models and their applications. In Visual Intelligence. https://link.springer.com/article/10.1007/s44267-024-00065-8

Xi Wang, Hongliang Dai, Shen Gao, & Piji Li. (2024). Characteristic AI Agents via Large Language Models. In International Conference on Language Resources and Evaluation. https://arxiv.org/abs/2403.12368

Xianbin Li, Xiaoyan Song, & R. Gray. (2004). Comparison of the missing-indicator method and conditional logistic regression in 1:m matched case-control studies with missing exposure values. In American journal of epidemiology. https://www.semanticscholar.org/paper/06d290f5aeba47aab6007eee10719f104191ef8d

Xiao Li Li, Jinhong You, & Yong Zhou. (2011). Statistical inference for varying-coefficient models with error-prone covariates. In Journal of Statistical Computation and Simulation. https://www.semanticscholar.org/paper/4593799335c59714db703916869f5e9874a40866

Xiao-Bo Deng, Chuan-Qi Zhu, Guang-Hua Zhang, & Dong-Bin Liu. (2024). Application and Development of AI Intelligent Hospital Guidance System Based on Multimodal Large Language Model (MLLM). In Journal of Intelligent Computing and Mathematics. https://www.semanticscholar.org/paper/f967becc9e978252ae53c3533fdfebc80cb8ff4e

Xingyu Xie, Kuang-Yu Ding, Shuicheng Yan, Kim-Chuan Toh, & Tianwen Wei. (2024). Optimization Hyper-parameter Laws for Large Language Models. In ArXiv. https://www.semanticscholar.org/paper/dbdda156a9de5d8ba73a12d9b50c6eed097da055

Xinyi Xu, Zhaoxuan Wu, Rui Qiao, Arun Verma, Yao Shu, Jingtan Wang, Xinyuan Niu, Zhenfeng He, Jiangwei Chen, Zijian Zhou, Gregory Kang Ruey Lau, Hieu Dao, Lucas Agussurja, Rachael Hwee Ling Sim, Xiaoqiang Lin, Wenyang Hu, Zhongxiang Dai, Pang Wei Koh, & B. Low. (2024). Data-Centric AI in the Age of Large Language Models. In ArXiv. https://arxiv.org/abs/2406.14473

Xuan Huang, Linyi Huang, Guowei Tong, Xundao Zhou, & Jianheng Luo. (2024). Security Challenges and Reflections on Large Models. In Frontiers in Computing and Intelligent Systems. https://drpress.org/ojs/index.php/fcis/article/view/25094

Xudong Shen, Hannah Brown, Jiashu Tao, Martin Strobel, Yao Tong, Akshay Narayan, Harold Soh, & F. Doshi-Velez. (2024). Directions of Technical Innovation for Regulatable AI Systems. In Commun. ACM. https://www.semanticscholar.org/paper/31e69bedd35219487c0aa721bdcd68d6abbc9b85

Y Bengio. (2009). Learning deep architectures for AI. In Foundations and trends® in Machine Learning. https://www.nowpublishers.com/article/Details/MAL-006

Y Chang, X Wang, J Wang, Y Wu, & L Yang. (2024). A survey on evaluation of large language models. https://dl.acm.org/doi/abs/10.1145/3641289

Y Liang, C Wu, T Song, W Wu, Y Xia, & Y Liu. (2024). Taskmatrix. ai: Completing tasks by connecting foundation models with millions of apis. https://spj.science.org/doi/full/10.34133/icomputing.0063

Y Lu. (2019). Artificial intelligence: a survey on evolution, models, applications and future trends. In Journal of Management Analytics. https://www.tandfonline.com/doi/abs/10.1080/23270012.2019.1570365

Y Lu, J Tong, J Chubak, T Lumley, & RA Hubbard. (2024). Leveraging error-prone algorithm-derived phenotypes: Enhancing association studies for risk factors in EHR data. https://www.sciencedirect.com/science/article/pii/S1532046424001084

Y Shen, K Song, X Tan, D Li, & W Lu. (2023). Hugginggpt: Solving ai tasks with chatgpt and its friends in hugging face. https://proceedings.neurips.cc/paper_files/paper/2023/hash/77c33e6a367922d003ff102ffb92b658-Abstract-Conference.html

Y Wang, Q Wang, S Shi, X He, & Z Tang. (2020). Benchmarking the performance and energy efficiency of AI accelerators for AI training. https://ieeexplore.ieee.org/abstract/document/9139681/

Y Yang, H Akbarzadeh Khorshidi, & U Aickelin. (2022). Limitations. https://link.springer.com/chapter/10.1007/978-981-19-1223-8_9

Yair Lakretz, Dieuwke Hupkes, A. Vergallito, M. Marelli, Marco Baroni, & S. Dehaene. (2020). Mechanisms for handling nested dependencies in neural-network language models and humans. In Cognition. https://linkinghub.elsevier.com/retrieve/pii/S0010027721001189

Yanfeng Shu, Ji Zhang, Guangyan Huang, Chi-Hung Chi, & Jing He. (2023). Entity alignment via graph neural networks: a component-level study. In World Wide Web (WWW). https://www.semanticscholar.org/paper/86b2cc2f2f724689e7d3729c14e11ea90288337f

Yang Dong-sheng. (2006). The gracefulness of the graph ω_(m_1,m_2,…,m_n). In jOURNAL OF southwest University for Nationalities. https://www.semanticscholar.org/paper/d3a5b8924d81dd4db529d479c21c1c3bfbd874a4

Yangming Li, Zhaozhi Qian, & M. Schaar. (2023). Do Diffusion Models Suffer Error Propagation? Theoretical Analysis and Consistency Regularization. In ArXiv. https://arxiv.org/abs/2308.05021

Yannic Schröder, Dennis Reimers, & L. Wolf. (2017). A test environment for phase-based ranging and localization. In 2017 14th Workshop on Positioning, Navigation and Communications (WPNC). https://ieeexplore.ieee.org/document/8250078/

Yanyu Chen & Ganhong Huang. (2024). GUIDE: A Global Unified Inference Engine for Deploying Large Language Models in Heterogeneous Environments. In ArXiv. https://arxiv.org/abs/2412.04788

Yedi Zhang, Yufan Cai, Xinyue Zuo, Xiaokun Luan, Kailong Wang, Zhe Hou, Yifan Zhang, Zhiyuan Wei, Meng Sun, Jun Sun, Jing Sun, & Jin Song Dong. (2024). The Fusion of Large Language Models and Formal Methods for Trustworthy AI Agents: A Roadmap. In ArXiv. https://arxiv.org/abs/2412.06512

Yiannis Charalambous, Edoardo Manino, & Lucas C. Cordeiro. (2024). Automated Repair of AI Code with Large Language Models and Formal Verification. In ArXiv. https://arxiv.org/abs/2405.08848

Yide Song. (2020). The Relationship between AI and Human in the Future. In International STEAM Communications. https://www.semanticscholar.org/paper/ce413fd2452e3a562770bcd02392c2fa4c96f7b8

Yihao Dong & Xiaolong Xu. (2023). Weighted-Dependency with Attention-Based Graph Convolutional Network for Relation Extraction. In Neural Processing Letters. https://www.semanticscholar.org/paper/7fe47325ecac982cc49079a4a70cf5679b86a01f

Yijia Zhang, Hongfei Lin, Zhihao Yang, Jian Wang, Yuanyuan Sun, Bo Xu, & Zhehuan Zhao. (2019). Neural network-based approaches for biomedical relation classification: A review. In Journal of biomedical informatics. https://linkinghub.elsevier.com/retrieve/pii/S1532046419302138

Yinheng Li, Shaofei Wang, Han Ding, & Hang Chen. (2023). Large Language Models in Finance: A Survey. In Proceedings of the Fourth ACM International Conference on AI in Finance. https://dl.acm.org/doi/10.1145/3604237.3626869

YM AlSerkal, NM Ibrahim, & AS Alsereidi. (2025). Real-Time Analytics and AI for Managing No-Show Appointments in Primary Health Care in the United Arab Emirates: Before-and-After Study. https://formative.jmir.org/2025/1/e64936

Yong Wang, Zepeng Shen, Ke Hu, Junqi Yang, & Changlin Li. (2025). AI End-to-End Autonomous Driving. In World Journal of Innovation and Modern Technology. https://www.semanticscholar.org/paper/ae0fd9f71ce10226b92ad355b1761db56ca3e54a

Yuan Ming. (2002). The Theories of the Basketball Quick Attack Tactics. https://www.semanticscholar.org/paper/95b963f8c563c8003e3c4b46f53cbe0cd35391f6

Yue Zhang, Wangdong Qi, & Su Zhang. (2014). The Unambiguous Distance in a Phase-based Ranging System with Hopping Frequencies. In ArXiv. https://www.semanticscholar.org/paper/ee65275f45572e937651cb71900f8285967f238c

Yuebing Liang, Guan Huang, & Zhan Zhao. (2021). Joint Demand Prediction for Multimodal Systems: A Multi-task Multi-relational Spatiotemporal Graph Neural Network Approach. In ArXiv. https://www.semanticscholar.org/paper/afd0b2804010eea7616272a4acc3035daf1a2be5

Yunhong He, Jianling Qiu, Wei Zhang, & Zhe Yuan. (2024). Fortifying Ethical Boundaries in AI: Advanced Strategies for Enhancing Security in Large Language Models. In ArXiv. https://arxiv.org/abs/2402.01725

Yusuf Usman, P. Gyawali, Sohan Gyawali, & Robin Chataut. (2024). The Dark Side of AI: Large Language Models as Tools for Cyber Attacks on Vehicle Systems. In 2024 IEEE 15th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON). https://ieeexplore.ieee.org/document/10754676/

Z Li, S Xu, K Mei, W Hua, B Rama, & O Raheja. (2024). Autoflow: Automated workflow generation for large language model agents. https://arxiv.org/abs/2407.12821

Z Shao, R Zhao, S Yuan, M Ding, & Y Wang. (2022). Tracing the evolution of AI in the past decade and forecasting the emerging trends. https://www.sciencedirect.com/science/article/pii/S0957417422013732

Z. Stephenson, J. Mcdermid, & Jason Choy. (2006). Using Simulation to Validate Style-Specific Architectural Refactoring Patterns. In 2006 30th Annual IEEE/NASA Software Engineering Workshop. https://ieeexplore.ieee.org/document/4090253/

Zeyuan Allen-Zhu & Yuanzhi Li. (2023). Physics of Language Models: Part 3.2, Knowledge Manipulation. In ArXiv. https://www.semanticscholar.org/paper/47daf5f81470564f94adcac672405c2cd39dd186

Zhang Guo-cha. (2015). Talent Cultivation Model Reform in Cultural Industry Management. In Journal of Beijing Institute of Education. https://www.semanticscholar.org/paper/f896e1818f8bd5c0b4a2be18e038fbc1e0daf1d0

Zhanhao Liu & Huailin Zhao. (2024). Exploration of the application of AI large models in the field of autonomous driving. In 2024 9th International Conference on Intelligent Informatics and Biomedical Sciences (ICIIBMS). https://ieeexplore.ieee.org/document/10792841/

Zhaohui Yang, Wei Xu, Le Liang, Yuan-zhang Cui, Zhijin Qin, & Mérouane Debbah. (2024). On Privacy, Security, and Trustworthiness in Distributed Wireless Large AI Models (WLAM). In ArXiv. https://arxiv.org/abs/2412.02538

Zhe Yang, Yichang Zhang, Tianyu Liu, Jian Yang, Junyang Lin, Chang Zhou, & Zhifang Sui. (2024). Can Large Language Models Always Solve Easy Problems if They Can Solve Harder Ones? In Conference on Empirical Methods in Natural Language Processing. https://www.semanticscholar.org/paper/af40586366f32af5f912bfb7fc43d56a34bb1f0b

Zhenmei Shi, Junyi Wei, Zhuoyan Xu, & Yingyu Liang. (2024). Why Larger Language Models Do In-context Learning Differently? In ArXiv. https://www.semanticscholar.org/paper/ec6023c6af6087ae9ed76efff448e0f9dc0254cc

Zheyuan Liu, Guangyao Dou, Zhaoxuan Tan, Yijun Tian, & Meng Jiang. (2024). Machine Unlearning in Generative AI: A Survey. In ArXiv. https://arxiv.org/abs/2407.20516

Zhicheng Yan, Hao Zhang, Robinson Piramuthu, Vignesh Jagadeesh, D. DeCoste, Wei Di, & Yizhou Yu. (2014). HD-CNN: Hierarchical Deep Convolutional Neural Networks for Large Scale Visual Recognition. In 2015 IEEE International Conference on Computer Vision (ICCV). https://www.semanticscholar.org/paper/ccd8a298081f9813592e42ea2d84ea798ef0dbbb

Zhou Yang, Jieke Shi, & David Lo. (2024). Ecosystem of Large Language Models for Code. In ArXiv. https://arxiv.org/abs/2405.16746

Zhouquan Lu. (2024). Large Language Models: Development in Model Scale and Challenges. In Applied and Computational Engineering. https://www.semanticscholar.org/paper/83873e5ebf7c289c9812f4a37025dcd6dd9de2b2

Zhuoyan Li & Ming Yin. (2024). Utilizing Human Behavior Modeling to Manipulate Explanations in AI-Assisted Decision Making: The Good, the Bad, and the Scary. In ArXiv. https://www.semanticscholar.org/paper/30d5c465b37b9e9a92f71430d83e3b4817b99472

Zhuoyan Xu, Zhenmei Shi, & Yingyu Liang. (2024). Do Large Language Models Have Compositional Ability? An Investigation into Limitations and Scalability. In ArXiv. https://arxiv.org/abs/2407.15720

Zihao Liu. (2024). Analyze and Evaluate the Method Used as Well as the Fallout of OpenAI’s Board of Directors Decision to Remove Sam Altman as CEO of the Company. In Highlights in Business, Economics and Management. https://drpress.org/ojs/index.php/HBEM/article/view/19785

Zihong He, Weizhe Lin, Hao Zheng, Fan Zhang, Matt Jones, Laurence Aitchison, Xuhai Xu, Miao Liu, P. O. Kristensson, & Junxiao Shen. (2024). Human-inspired Perspectives: A Survey on AI Long-term Memory. In ArXiv. https://arxiv.org/abs/2411.00489

Zishan Guo, Renren Jin, Chuang Liu, Yufei Huang, Dan Shi, Supryadi, Linhao Yu, Yan Liu, Jiaxuan Li, Bojian Xiong, & Deyi Xiong. (2023). Evaluating Large Language Models: A Comprehensive Survey. In ArXiv. https://arxiv.org/abs/2310.19736

Ziyang Li, Saikat Dutta, & Mayur Naik. (2024). LLM-Assisted Static Analysis for Detecting Security Vulnerabilities. In ArXiv. https://www.semanticscholar.org/paper/1ddcd76d2e4c40bbc7aa8e8f1fc77d5ecf11bcb2

Zvi Kam, Lorenzo Peracchio, & Giovanna Nicora. (2025). End-User Confidence in Artificial Intelligence-Based Predictions Applied to Biomedical Data. In International journal of neural systems. https://www.worldscientific.com/doi/10.1142/S0129065725500170

К.В. Барышков. (2024). Интеграция искусственного интеллекта в стратегии маркетинга. In Цифровая экономика. https://www.semanticscholar.org/paper/5e03c41d0ba77eddf3e927cbbbb8f7c491efa6fd

Р. Н. Квєтний, І. В. Богач, & Р. В. Слободян. (n.d.). IMPROVING TASKS DISTRIBUTION USING AI. https://www.semanticscholar.org/paper/dae4e3f7fa52d41c69430e6727f0d3e00a513565

周伟忠. (2016). n∑i=n0 ai /1〈C（C为常数）的数列不等式的证明方法比较. https://www.semanticscholar.org/paper/e51b604f6a946c118f5a15c74f84d02cec21f387

李想姣 & 刘珩. (2012). 基于SWOT分析的行业型高校人文社会科学研究战略思考——以中国地质大学（武汉）为例. https://www.semanticscholar.org/paper/3960d2d9c25bc543dd68c5469ea8438ba244ad9b

永波 常. (2024). Industrial Application Ecology Driven by Large Models: Connotation, Evolution and Challenges. In Sustainable   Development. https://www.hanspub.org/journal/doi.aspx?DOI=10.12677/sd.2024.143081



Generated by Liner
https://getliner.com/search/s/5926611/t/85906513