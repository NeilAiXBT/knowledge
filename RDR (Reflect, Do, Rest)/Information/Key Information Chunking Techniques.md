'Key Information Chunking Techniques..' For example, building relationships. compressing, wrapping, mounting, ect.   Requirements: 1. Ensure compliance with MECE. 2. Classify/categorize logically and appropriately if necessary. 3. Explain with analogy and examples. 4. Use numbered lists for clear explanations when possible. 5. Describe core elements, components, factors and aspects. 6. List core evaluation dimensions and corresponding evaluations if applicable. 7. Describe their concepts, definitions, functions, and characteristics. 8. Clarify their purposes and assumptions (Value, Descriptive, Prescriptive, Worldview, Cause-and-Effect). 9. Describe relevant markets, ecosystems, regulations, and economic models, and explain the corresponding strategies used to generate revenue. 10. Describe their work mechanism concisely first and then explain how they work with phase-based workflows throughout the entire lifecycle. 11. Clarify their preconditions, inputs, outputs, immediate outcomes, value-added outcomes, long-term impacts, and potential implications (including the influences of emotion, public opinion, and public responses). 12. Clarify their underlying laws, axioms, theories, and patterns. 13. Describe the design philosophy and architectural features. 14. Provide ideas, techniques, and means of architectural refactoring. 15. Clarify relevant frameworks, models, and principles. 16. Clarify their origins, evolutions, and trends. 17. List key historical events, security incidents, core factual statements, raw data points, and summarized statistical insights. 18. Clarify techniques, methods, approaches, protocols, and algorithms.  19. Describe contradictions and trade-offs. 20. Identify and list all major competitors (including the one being searched at present) with concise descriptions within the target market or industry segment. 21. Conduct a comprehensive competitor analysis to evaluate each competitor’s (including the one being searched at present) operational strategies, product offerings, market position, and performance metrics. 22. Perform a SWOT analysis for each competitor (including the one being searched at present), categorizing findings into strengths, weaknesses, opportunities, and threats. 23. Clarify principles, rules, constrains, limitations, vulnerabilities, challenges, obstacles, and risks. 24. Describe potential security vulnerabilities, troubleshooting methods, attack tactics, prevention methods and emergency measures. 25. Describe potential performance bottlenecks, troubleshooting methods and optimization measures. 26. Explain priorities, use cases, potential pitfalls, error-prone points, and best practices (dos and don'ts). 27. Clarify cause-and-effect relationships, using symbols like '<-verb(s)-', '-verb(s)->', and '<-verb(s)->'. 28. Clarify interdependency relationships, using symbols like '<-verb(s)-', '-verb(s)->', and '<-verb(s)->'. 29. Clarify cardinality-based relationships (1:1, 1:M, M:N). 30. Clarify contradictory relationships, using symbols like '<-verb(s)-', '-verb(s)->', and '<-verb(s)->'. 31. Clarify important sequential/temporal relationships. 32. Clarify hierarchical (classification) relationship; 33. Describe the existing non-trivial problems and potential approaches to address them. 34. Introduce the relevant research topics of significant value that remain to be overcome. 35. Introduce the possible directions and approaches of within-domain and cross-domain innovation. 36. Predict the ultimate form of the related development. 37. Make a summary table at the end with purposes, characteristics, use cases, ect. for clarity. 38. Append the terminologies, formulas, and analogies at the end with concise descriptions for each item.

Mon Jun 16 2025

### Overview of Key Information Chunking Techniques and MECE-Based Classification

Information chunking refers to the process of organizing data, knowledge, or content into manageable, meaningful units ("chunks") to optimize memory, processing, storage, analysis, and communication((38)). This concept fundamentally improves efficiency and performance in both human cognition and technological systems((4)). To ensure a comprehensive and mutually exclusive, collectively exhaustive (MECE) classification, information chunking techniques can be divided into three primary, non-overlapping categories:

1. **Cognitive/Conceptual Chunking** – Building Relationships  
2. **Data Chunking** – Compressing, Wrapping, Mounting, etc.  
3. **Linguistic/Statistical Chunking** – Syntactic and Semantic Segmentation

Each category is subdivided and explained below for clarity, with analogies, examples, and analytical depth.


---

### 1. Cognitive/Conceptual Chunking (Building Relationships)
#### 1.1 Concept, Definition, Functions, and Characteristics
Cognitive chunking is a technique grounded in cognitive psychology where information is grouped into meaningful units based on semantic, conceptual, or functional relationships((4)). The function is to reduce cognitive load and enhance working memory, making complex information easier to process, learn, and recall((19)).

**Example/Analogy:**  
Imagine memorizing a phone number—it's easier to remember "555-123-4567" as three groups ("chunks") of digits than as a string of ten discrete numbers((17)). Similarly, learning medical anatomy is facilitated by chunking organs into physiological systems((20)).

#### 1.2 Core Elements, Components, and Aspects
- **Grouping Principle:** Formed by semantic or conceptual similarity (e.g., list of fruits or social relationship networks)((38)).  
- **Chunk Size:** Typically limited by human memory constraints (the “magic number 7±2” or 4 in working memory studies).  
- **Associativity:** Chunks are internally cohesive but distinct from other chunks((4)).

#### 1.3 Purposes and Assumptions
- **Value:** Improved memory retention and comprehension((4)).
- **Descriptive:** Human brains intrinsically form chunks to organize information efficiently.
- **Prescriptive:** Instructional strategies can incorporate chunking to optimize learning.
- **Worldview:** Knowledge is best assimilated and recalled when organized into meaningful relational structures((4)).
- **Cause-and-Effect:** Chunking <-reduces- cognitive load, which -increases-> recall and learning performance((19)).

#### 1.4 Evaluation Dimensions and Criteria
- Recall accuracy (pre/post chunking)
- Comprehension tests
- Subjective measures of cognitive load((263)).

#### 1.5 Market, Ecosystem, Economic Model, and Revenue Strategies
Prominent in education, training, and communication design (e.g., e-learning products, memory training apps).
- **Revenue Model:** Licensing curricula, training programs, certifications, adaptive edtech subscriptions((34)).
- **Ecosystem:** EdTech companies, corporate training providers, blended learning platforms((32)).

#### 1.6 Mechanism and Lifecycle Workflow
**Concise Mechanism:** Content is grouped logically before being taught, enabling better comprehension and recall.
**Lifecycle Workflow:**
1. **Preconditions/Input:** Complex, ungrouped information((20)).
2. **Chunking Phase:** Grouping information by similarity, function, or relevance.
3. **Cognitive Integration:** Internalization and memory encoding as "chunks."
4. **Recall/Output:** Efficient storage and retrieval due to chunk structure.
5. **Feedback/Adjustment:** Learner self-assessment and instructor feedback to refine chunking strategy((4)).

#### 1.7 Core Outcomes and Implications
- **Immediate Outcome:** Enhanced short-term learning((34)).
- **Value-Added Outcome:** Accelerated mastery and concept transfer.
- **Long-Term Impact:** Higher expertise—seen in “chunk-based” memory of chess masters((36)).
- **Implications:** Positive engagement; chunking is often viewed favorably in public opinion for its learning benefits.

#### 1.8 Underlying Laws, Theories, Patterns
- Limited working memory capacity((4)).
- Hierarchical schema theory in cognitive science((321)).
- Patterns: Chunks are formed recursively and hierarchically.

#### 1.9 Design Philosophy and Architecture
Design focuses on hierarchies and modularity, matching cognitive capacity, using semantic clusters or graphical organizers in instructional materials((41)).

#### 1.10 Refactoring and Frameworks
- **Refactoring:** Reorganize instructional units into increasingly granular or abstracted chunks for better alignment with learning goals((83)).
- **Frameworks:** Cognitive Load Theory, Schema Theory, and dual-coding models((4)).

#### 1.11 Origins, Evolution, and Trends
- **Origins:** Miller’s 1956 research on memory capacity((38)).
- **Evolution:** Integration into schema learning, neuroscience, and adaptive EdTech.
- **Trends:** Personalized, real-time chunk adaptation using AI((96)).
  
#### 1.12 Key Historical Events and Factual Insights
- Miller introduced the "chunks" concept; later refined to about four items for working memory.
  
#### 1.13 Techniques, Methods, Protocols, Algorithms
- Semantic grouping, visual organizers, mind maps, spaced repetition, and memory palaces((34)).

#### 1.14 Contradictions and Trade-Offs
- Too large chunks <-overwhelm- working memory, while too small chunks <-fail- to improve recall efficiency((263)).
  
#### 1.15 Competitors, Positioning, SWOT
- EdTech companies focused on memory and learning optimization are primary competitors.
- **Strengths:** Fundamental process; high demand.
- **Weaknesses:** Efficacy depends on learner background.
- **Opportunities:** Integration with AI and brain-computer interfaces.
- **Threats:** Changing learning styles and digital distractions.

#### 1.16 Challenges, Vulnerabilities, Security
- **Limitation:** Individual chunking capacity varies, which challenges standardization across learners.
- **Vulnerabilities:** Not applicable.

#### 1.17 Performance Bottlenecks and Optimization
- Performance drops if chunking does not align with learner's prior knowledge; optimization through continuous feedback and adaptive presentation((34)).

#### 1.18 Priorities, Use Cases, Best Practices
- Priority to group information by natural associations((20));
- Use in school curricula, onboarding, and complex training scenarios.
- **Best Practice:** Use meaningful, not arbitrary, groupings.

#### 1.19 Sequential/Temporal, Hierarchical, and Cardinality Relationships
- Chunks are formed and recalled sequentially in learning.
- Hierarchy: Nested/recursive structures (chunks within chunks).
- Cardinality: 1:M (one chunk—many items within).

#### 1.20 Non-Trivial Problems and Innovation Directions
- **Problems:** Over-chunking or under-chunking.
- **Within-domain Innovation:** Real-time chunk adaptation.
- **Cross-domain:** Integrate neuro-adaptive chunking into intelligent tutoring systems((163)).
- **Ultimate Development:** Integration with real-time neurofeedback and AI for fully adaptive cognitive chunking.

---

### 2. Data Chunking (Compressing, Wrapping, Mounting, etc.)
#### 2.1 Concept, Definition, Functions, and Characteristics
Data chunking divides digital data streams into 'chunks' for deduplication, compression, efficient storage, and transmission((9)). Unlike cognitive chunking, it is algorithmic and often used in IT infrastructure, backup, and cloud environments((76)).

**Analogy/Example:**  
Consider backing up a hard drive: rather than saving every file in entirety, only unique chunks are stored and repeated chunks are referenced, minimizing storage((164)). This is akin to dividing a long rope into standard sections for easier handling.

#### 2.2 Core Elements, Components, and Aspects
- **Fixed-Size Chunking (FSC):** Data is split into equal-sized blocks; simple but less efficient.
- **Content-Defined Chunking (CDC):** Chunks are delineated based on data content using rolling hashes (e.g., Rabin fingerprint)((164)).
- **Advanced Algorithms:** Two Threshold Two Divisor (TTTD), Asymmetric Extremum (AE), Dynamic Prime Chunking (DPC), Frequency-Based Chunking (FBC)((259)).

#### 2.3 Purposes and Assumptions
- **Value:** Maximize storage efficiency, reduce bandwidth((174)).
- **Descriptive:** Redundant data occurs frequently; chunking can capture and eliminate these patterns.
- **Prescriptive:** Storage systems should use content-defined chunking for optimal deduplication.
- **Worldview:** Digital information is naturally segmented and can be modularly stored.
- **Cause-and-Effect:** More effective chunking -reduces-> storage costs and network bandwidth demand((94)).

#### 2.4 Evaluation Dimensions and Criteria
- **Deduplication Ratio:** Proportion of eliminated redundant data((94)).
- **Throughput:** Data chunking/processing speed.
- **Chunk Size Variance:** Variation in chunk length affects efficiency((411)).
- **Security:** Resistance to parameter extraction and attacks((30)).

#### 2.5 Market/Ecosystem, Economical Model, Revenue
- **Market:** Cloud storage, enterprise backup, big data analytics.
- **Revenue:** Subscription pricing by storage used, performance tiers, value-added deduplication/compression features((76)).
- **Ecosystem:** Providers (e.g. Tarsnap, Borg, Restic), open-source deduplication frameworks((111)).

#### 2.6 Work Mechanism and Workflow (Phase-based)
**Concise Mechanism:**  
The chunking algorithm reads a data stream and uses chunking rules (e.g. hashes, byte patterns) to determine chunk boundaries, then processes, deduplicates or transmits those chunks.

**Workflow:**
1. **Precondition/Input:** Raw data stream((174)).
2. **Chunking:** Divided into chunks via FSC or CDC.
3. **Hashing/Fingerprinting:** Compute unique identifiers for each chunk.
4. **Processing:** Identify duplicates; eliminate redundant storage or transmission.
5. **Output/Immediate Outcome:** Efficient chunks stored or sent.
6. **Value-Added Outcomes:** Storage savings and faster transfers.
7. **Long-Term:** Cost reduction, backend simplification, and higher system scalability.

#### 2.7 Laws, Theories, and Patterns
- Information theory (redundancy elimination).
- Hash function properties (collision resistance).
- Statistical distribution of chunk sizes in CDC.

#### 2.8 Design Philosophy & Architecture
- Employ modular architecture with pluggable chunking modules, indexing, and deduplication((164)).

#### 2.9 Refactoring and Frameworks
- Parallelize chunking for high throughput (Multi-Threaded/Frequency-Based Chunking)((356)).
- Extend or refine rolling hash algorithms; hybrid statistical and content-defined techniques.

#### 2.10 Origins, Evolutions, and Trends
- **Origins:** Emergence in backup and storage optimization fields.
- **Trends:** Increasing shift to CDC, multi-threading, hardware-accelerated chunking, adaptive chunking for cloud-scale data.

#### 2.11 Key Historical Events, Insights, and Security Incidents
- Development of Rabin fingerprint and open attacks on their parameterization leading to security improvements((111)).
- Performance benchmarking frameworks (DedupBench) highlight best chunking solutions for given workloads((76)).

#### 2.12 Techniques/Methods/Algorithms
- Fixed-Size, Content-Defined, Rabin Fingerprinting, Buzhash, AE, DPC, FBC, rolling hash, parallel chunking, hybrid methods((259)).

#### 2.13 Contradictions/Trade-Offs
- Chunk size: Large chunks increase throughput but can miss deduplication; small chunks save space but slow processing.
- Aggressively optimizing deduplication ratio can degrade throughput((94)).

#### 2.14 Competitors and SWOT Analysis
Major players include Tarsnap (secure, deduplicating storage), Borg (efficient, open-source backup), Restic (fast, secure, flexible backups), emerging algorithms like FastCDC and DPC((111)).
- **Strengths:** Effective storage cost reduction; high industry adoption.
- **Weaknesses:** High computational resource needs; security risks.
- **Opportunities:** Growth in cloud and big data.
- **Threats:** Emerging quantum-resistant and AI-driven deduplication.

#### 2.15 Challenges, Security, and Performance Bottlenecks
- **Vulnerabilities:** Parameter-extraction and known-plaintext attacks((30)).
- **Performance Bottlenecks:** Rolling hash computations, especially in large-scale datasets.
- **Optimizations:** Multi-threading, skipping non-minimum chunk cut-points, algorithmic refinements, low-entropy block detection((355)).

#### 2.16 Priorities, Use Cases, Best Practices
- Priority: Minimize storage and bandwidth by intelligent chunking.
- Use in cloud backup, distributed file systems, edge computing.
- **Best Practice:** Tune chunking algorithms to workload; encrypt chunks before deduplication; monitor chunk size distribution for optimal performance.

#### 2.17 Sequential/Temporal, Hierarchical, Cardinality Relationships
- **Temporal:** Data streams are chronologically chunked as input arrives.
- **Hierarchy:** Chunks mapped to larger data structures (files, storage pools).
- **Cardinality:** Chunks:DataBlocks is M:N, as redundant chunks serve multiple data assets((111)).

#### 2.18 Problems, Innovation, and Future Directions
- **Problems:** Handling encrypted or compressed streams, attacks exploiting chunking properties.
- **Within-domain:** Adaptive, hybrid chunkers; security-targeted solutions.
- **Cross-domain:** Integrating AI for real-time chunk boundary optimization.
- **Ultimate Form:** AI-driven, adaptive chunking, robust to attacks, optimized for granular deduplication.

---

### 3. Linguistic/Statistical Chunking (Syntactic/Semantic Segmentation)
#### 3.1 Concept, Definition, Functions, and Characteristics
This technique segments text into syntactically or semantically coherent chunks, such as noun or verb phrases, using statistical or machine learning models((44)). Enables better parsing, entity extraction, and downstream NLP tasks.

**Analogy/Example:**  
Like dividing a sentence into logical phrases: “The quick brown fox// jumps over// the lazy dog”((99)).

#### 3.2 Core Elements and Aspects
- **Tagging Schemes:** Inside-Outside-Beginning (IOB), Start/End((54)).
- **ML Models:** Conditional Random Fields, Support Vector Machines, Memory-Based Learning((325)).
- **Contextual Features:** POS tags, morphological patterns, proximity features.

#### 3.3 Purposes and Assumptions
- **Value:** Streamlines syntactic and semantic understanding((324)).
- **Descriptive:** Text inherently contains chunkable structure.
- **Prescriptive:** Automated systems can be trained to recognize these efficiently.
- **Worldview:** Language is a structured, rule-governed system((14)).
- **Cause-and-Effect:** Enhanced chunking -improves-> parsing and entity recognition.

#### 3.4 Evaluation Dimensions and Criteria
- **Precision/Recall/F-measure:** Evaluated against tagged corpora((325)).
- **Portability:** How well chunking models adapt across domains((98)).

#### 3.5 Market and Economic Models
- **Market:** NLP APIs, translation systems, digital assistants.
- **Revenue:** Licensing APIs, custom models, consulting services for language tech((186)).
- **Ecosystem:** NLP research, open-source toolkits, enterprise solutions.

#### 3.6 Mechanism and Phase-Based Workflow
1. **Input:** Raw text((44)).
2. **POS/Morphological Tagging:** Pre-processing((46)).
3. **Chunking:** Assignment of chunk tags or boundaries((325)).
4. **Type Classification:** E.g., NP, VP labels((338)).
5. **Output:** Annotated text segments.
6. **Downstream Use:** Parsing, entity extraction, semantic analysis.

#### 3.7 Laws, Patterns, Design Philosophy
- **Patterned after syntax theory and distributional hypotheses**.
- Designs focus on modular, layered pipelines that process text hierarchically((99)).

#### 3.8 Refactoring and Frameworks
- **Refactoring:** Decouple noun, verb, and other phrase chunkers for post-hoc combination((333)).
- **Frameworks:** CoNLL-2000 shared task architecture, XML-driven processing pipelines.

#### 3.9 Origins, Evolution, and Trends
- **Origins:** Emerged in linguistics, computational linguistics, and parsing research((326)).
- **Trends:** Integration with deep learning architectures, unsupervised and few-shot chunking((182)).
  
#### 3.10 Security, Performance, Contradictions, and Trade-Offs
- **Challenges:** Data sparsity, annotation errors, ambiguity((350)).
- **Trade-Offs:** Rule-based chunkers (portable, flexible) vs ML chunkers (higher accuracy but data-dependent)((98)).

#### 3.11 Competitors and SWOT
- Providers of NLP platforms, including open-source toolkits (e.g., SpaCy, NLTK) and commercial APIs.
- **Strengths:** Critical for many NLP tasks.
- **Weaknesses:** Domain adaptation is non-trivial.
- **Opportunities:** Expanding AI/NLP applications and languages.
- **Threats:** Large unsupervised models.

#### 3.12 Problems and Innovation
- **Problem:** Cross-lingual and domain adaptation remains challenging((167)).
- **Within-domain Innovation:** Unsup./semi-sup. learning for chunking.
- **Ultimate Form:** Context-aware, dynamically adapting neural chunkers embedded in foundational language models((182)).

---

### Summary Table: Purposes, Characteristics, and Use Cases

| Technique Type         | Purpose                                | Key Characteristics             | Use Cases                | Analogy           | Major Markets          |
|-----------------------|----------------------------------------|------------------------------|--------------------------|--------------------|-----------------------|
| Cognitive Chunking    | Optimize memory & learning             | Semantic grouping, hierarchy  | Education, training, UX  | Phone number memory| Edtech, HR training   |
| Data Chunking         | Storage/processing efficiency           | Algorithmic, scalable, hash-based | Cloud storage, backup   | Dividing a rope    | IT, cloud, data analytics|
| Linguistic Chunking   | Syntactic/semantic segmentation         | ML/statistical, rule-based    | NLP, translation, parsing| Breaking sentences | NLP platforms, AI APIs |

---

### Terminologies, Formulas, and Analogies

**Chunk:** A logical, meaningful grouping or unit in any system (like a “folder” for related files).  
**Rolling Hash:** A hashing function that slides over input to find data-dependent chunk boundaries (“scanner on a moving belt”)((164)).  
**Content-Defined Chunking (CDC):** Algorithm that decides where to cut data based on content, not size((174)).  
**IOB Tagging:** Labeling words as Inside, Outside, or Beginning parts of syntactic chunks (“labeling each word’s position in a phrase”).  
**Deduplication Ratio:** Storage space saved due to chunking and eliminating duplicates.  
**Magic Number 7±2:** Cognitive science proposition regarding memory capacity; refined to about 4 chunks in some studies.  
**F-Score (F1):** 
\\[
F_1 = 2 \times \frac{Precision \times Recall}{Precision+Recall}
\\]
A key metric for chunking accuracy in linguistic/statistical approaches.

**Analogy – Cognitive:** Grouping digits in a phone number.  
**Analogy – Data:** Dividing a book into chapters.  
**Analogy – Linguistic:** Breaking a sentence into logical phrases.

---

This MECE-structured, multi-dimensional analysis ensures a comprehensive, non-overlapping understanding of key information chunking techniques, their mechanisms, principles, and markets—clarified with examples, analogies, and actionable frameworks suitable for both scientific and business applications.

Bibliography
A Guida, F Gobet, H Tardieu, & S Nicolas. (2012). How chunks, long-term working memory and templates offer a cognitive explanation for neuroimaging data on expertise acquisition: a two-stage framework. In Brain and cognition. https://www.sciencedirect.com/science/article/pii/S0278262612000176

A. Hammi, Abdelhak Belhi, Houssem Gasmi, & Abdelaziz Bouras. (2022). Blockchain-Based Lifecycle Approach towards a Secure Building Information Modelling (BIM) Workflow. In 2022 2nd International Conference on Computers and Automation (CompAuto). https://ieeexplore.ieee.org/document/10027096/

A Isenko, R Mayer, J Jedele, & HA Jacobsen. (2022). Where is my training bottleneck? hidden trade-offs in deep learning preprocessing pipelines. https://dl.acm.org/doi/abs/10.1145/3514221.3517848

A Kathpalia & N Nagaraj. (1910). Measuring causality: The science of cause and effect. In arXiv. https://arxiv.org/abs/1910.08750

A Klippel, H Tappe, & C Habel. (2003). Pictorial representations of routes: Chunking route segments during comprehension. https://link.springer.com/chapter/10.1007/3-540-45004-1_2

A Lotem & JY Halpern. (2025). Evolution of diverse (and advanced) cognitive abilities through adaptive fine-tuning of learning and chunking mechanisms. In arXiv. https://arxiv.org/abs/2501.11201

A Srinivasan. (2023). Improving Selection of Analogical Inspirations with Chunking and Recombination. https://search.proquest.com/openview/5c1d854b35961b28251685dd7095fcba/1?pq-origsite=gscholar&cbl=18750&diss=y

A Venish & K Siva Sankar. (2016). Study of chunking algorithm in data deduplication. https://link.springer.com/chapter/10.1007/978-81-322-2674-1_2

AL Gilchrist. (2015). How should we measure chunks? A continuing issue in chunking research and a way forward. In Frontiers in psychology. https://www.frontiersin.org/articles/10.3389/fpsyg.2015.01456/full

Alan Liu, Abdelrahman Baba, Sreeharsha Udayashankar, & S. Al-Kiswany. (2023). DedupBench: A Benchmarking Tool for Data Chunking Techniques. In 2023 IEEE Canadian Conference on Electrical and Computer Engineering (CCECE). https://www.semanticscholar.org/paper/30076dadba4376d1a06642343a1c241a68d2bb6a

Andrii Barna & R. Kaminsky. (2022). ANALYSIS OF THE EFFICIENCY OF DATA CHUNKING METHODS FOR DATA DEDUBLICATION SYSTEMS. In Herald of Khmelnytskyi National University. Technical sciences. https://www.semanticscholar.org/paper/4d820cc232852438cabc7457339ff097e98a5e79

Anup Anand Deshmukh, Qianqiu Zhang, Ming Li, Jimmy J. Lin, & Lili Mou. (2021). Unsupervised Chunking as Syntactic Structure Induction with a Knowledge-Transfer Approach. In Conference on Empirical Methods in Natural Language Processing. https://www.semanticscholar.org/paper/60af7ea858c52df04bdb5d8c874c0549a83e1105

B. Chapuis, B. Garbinato, & Periklis Andritsos. (2016). Throughput: A Key Performance Measure of Content-Defined Chunking Algorithms. In 2016 IEEE 36th International Conference on Distributed Computing Systems Workshops (ICDCSW). https://ieeexplore.ieee.org/document/7756201/

B Sarma & AK Barman. (2015). A Comprehensive Survey of Noun Phrase Chunking in Natural Languages. https://www.academia.edu/download/111205707/a-comprehensive-survey-of-noun-phrase-chunking-in-natural-languages-IJERTV4IS040854.pdf

Boris Alexeev, Colin Percival, & Yan X Zhang. (2025). Chunking Attacks on File Backup Services using Content-Defined Chunking. https://www.semanticscholar.org/paper/9c0c9e721f7242926127660b425f252a7c0ab164

Bowen Qin, Binyuan Hui, Lihan Wang, Min Yang, Jinyang Li, Binhua Li, Ruiying Geng, Rongyu Cao, Jian Sun, Luo Si, Fei Huang, & Yongbin Li. (2022). A Survey on Text-to-SQL Parsing: Concepts, Methods, and Future Directions. In ArXiv. https://arxiv.org/abs/2208.13629

C Lilienthal. (2009). Architectural complexity of large-scale software systems. https://ieeexplore.ieee.org/abstract/document/4812735/

C. Mahlow & M. Piotrowski. (2010). Noun Phrase Chunking and Categorization for Authoring Aids. In Conference on Natural Language Processing. https://www.semanticscholar.org/paper/99bb13508a528acd2402c7476a4fbef8bcb3b2e0

C Sankar & M VasanthaNila. (2025). Mnemonics, Chunking, and Mind Mapping in Enhancing the Perceived Memory of Nursing Students. https://journals.lww.com/ijnp/fulltext/2025/04000/mnemonics,_chunking,_and_mind_mapping_in_enhancing.14.aspx?context=latestarticles

Chen Yi. (2006). On Chunking Approach in ELT. In Journal of Fujian Medical University. https://www.semanticscholar.org/paper/df1054ead8c48499275b4a9f79c7d81fee9c9ec1

Chetan Arora, M. Sabetzadeh, L. Briand, Frank Zimmer, & Raul Gnaga. (2013). Automatic Checking of Conformance to Requirement Boilerplates via Text Chunking: An Industrial Case Study. In 2013 ACM / IEEE International Symposium on Empirical Software Engineering and Measurement. https://ieeexplore.ieee.org/document/6681336/

Claire Grover & R. Tobin. (2006). Rule-Based Chunking and Reusability. In International Conference on Language Resources and Evaluation. https://www.semanticscholar.org/paper/941516fefc1319864060dee2cff7f243985073f2

D Feng. (2022). Chunking algorithms. https://link.springer.com/chapter/10.1007/978-981-19-0112-6_3

D Ganesh. (2024). Super-Fast and Secure Deduplication System based on Fixed Window Fixed Byte Chunking and Semantic Weight Poisson Process Filter in Cloud Storage. In Frontiers in Health Informatics. https://search.ebscohost.com/login.aspx?direct=true&profile=ehost&scope=site&authtype=crawler&jrnl=26767104&AN=184638285&h=38PD%2BKlnRMh7g3MlDz1VXEbKU6UJRUg7PHBvXnl7cHfrrpiCj9KpxdgQktvlVKZAFiqNRLjitVCnEHNqnGMv5g%3D%3D&crl=c

D Su. (2017). Semantics and chunking in written and conversational discourses: A corpus study of two near-synonymous words in Mandarin. In Chinese Language and Discourse. https://www.jbe-platform.com/content/journals/10.1075/cld.8.1.03su

D. Viji & Dr.S. Revathy. (2021). Comparative Analysis for Content Defined Chunking Algorithms in Data Deduplication. In Webology. https://www.semanticscholar.org/paper/be47b61e1b71f1e72591f4889670fc6fc1c3a270

D Zou. (2017). Vocabulary acquisition through cloze exercises, sentence-writing and composition-writing: Extending the evaluation component of the involvement load hypothesis. In Language Teaching Research. https://journals.sagepub.com/doi/abs/10.1177/1362168816652418

DE West. (2022). Linguistic and visuospatial chunking as quantitative constraints on propositional logic. In Handbook of cognitive mathematics. https://link.springer.com/content/pdf/10.1007/978-3-031-03945-4_44.pdf

E. Drábek & Qiang Zhou. (2001). Experiments in learning models for functional chunking of Chinese text. In 2001 IEEE International Conference on Systems, Man and Cybernetics. e-Systems and e-Man for Cybernetics in Cyberspace (Cat.No.01CH37236). https://ieeexplore.ieee.org/document/973023/

E Kruus, C Ungureanu, & C Dubnicki. (2010). Bimodal content defined chunking for backup streams. In Fast. https://www.usenix.org/legacy/event/fast10/tech/full_papers/kruus.pdf

E. Tjong Kim Sang. (2000). Text Chunking by System Combination. In CoNLL/LLL. https://dl.acm.org/citation.cfm?doid=1117601.1117638

EG Akyürek, N Kappelmann, & M Volkert. (2017). What you see is what you remember: Visual chunking by temporal integration enhances working memory. https://direct.mit.edu/jocn/article-abstract/29/12/2025/28728

EL Martínez-Huamán, CQ Añazco, & SC Quispe. (2023). Teaching with chunking in synchronous classes: The influence on university students’ intrinsic motivation. http://www.ijlter.net/index.php/ijlter/article/view/1534

ES Btoush & MM Hammad. (2015). Generating ER diagrams from requirement specifications based on natural language processing. https://www.researchgate.net/profile/Eman-Btoush/publication/275952818_Generating_ER_Diagrams_from_Requirement_Specifications_Based_On_Natural_Language_Processing/links/554a878e0cf21ed21358e791/Generating-ER-Diagrams-from-Requirement-Specifications-Based-On-Natural-Language-Processing.pdf

F. Bouchacourt, Stefano Palminteri, E. Koechlin, & S. Ostojic. (2019). Temporal chunking as a mechanism for unsupervised learning of task-sets. In eLife. https://www.biorxiv.org/lookup/doi/10.1101/713156

F Dalpiaz & M Parente. (2019). RE-SWOT: from user feedback to requirements via competitor analysis. https://link.springer.com/chapter/10.1007/978-3-030-15538-4_4

F Gobet. (2005). Chunking models of expertise: Implications for education. In Applied Cognitive Psychology. https://onlinelibrary.wiley.com/doi/abs/10.1002/acp.1110

F. Gobet & K. Ericsson. (2005). Chunking models of expertise: Implications for education. Commentary. In Applied Cognitive Psychology. https://www.semanticscholar.org/paper/e28713cd47097b5e24b8b6dd8ceb22583b3bc5e3

F Gobet & PCR Lane. (2012). Chunking mechanisms and learning. In Encyclopedia of the sciences of learning. https://link.springer.com/rwe/10.1007/978-1-4419-1428-6_1731

F Gobet, PCR Lane, S Croker, & PCH Cheng. (2001). Chunking mechanisms in human learning. https://www.cell.com/ajhg/abstract/S1364-6613(00)01662-4

G. Keinan, N. Friedland, & L. Arad. (1991). Chunking and integration: effects of stress on the structuring of information. In Cognition & Emotion. https://www.tandfonline.com/doi/abs/10.1080/02699939108411030

GD Bodie & WG Powers. (2006). Chunking, priming and active learning: Toward an innovative and blended approach to teaching communication-related skills. https://www.tandfonline.com/doi/abs/10.1080/10494820600800182

Gerrit Muller. (2013). From Legacy to State-of-the-art; Architectural Refactoring. https://www.semanticscholar.org/paper/31e3e7af466c0fd17435bb16c171ded88d691070

Guanglu Sun, C. Huang, Xiaolong Wang, & Zhi-ming Xu. (2006). Chinese Chunking Based on Maximum Entropy Markov Models. In Int. J. Comput. Linguistics Chin. Lang. Process. https://www.semanticscholar.org/paper/889db78a0e07a9add5870de7fbf09e078f84f0b1

Guoqi Li, Lei Deng, Dong Wang, Wen Wang, Fei Zeng, Ziyang Zhang, Huanglong Li, Sen Song, Pei Jing, & Luping Shi. (2016). Hierarchical Chunking of Sequential Memory on Neuromorphic Architecture with Reduced Synaptic Plasticity. In Frontiers in Computational Neuroscience. https://www.frontiersin.org/articles/10.3389/fncom.2016.00136/full

H. Aamer, B. Bogaerts, D. Surinx, E. Ternovska, & Jan Van den Bussche. (2020). Inputs, Outputs, and Composition in the Logic of Information Flows. In ACM Transactions on Computational Logic. https://dl.acm.org/doi/10.1145/3604553

H Lee, K Choi, D Yoo, Y Suh, & S Lee. (2018). Recommending valuable ideas in an open innovation community: a text mining approach to information overload problem. https://www.emerald.com/insight/content/doi/10.1108/imds-02-2017-0044/full/html

H Shahriar & M Zulkernine. (2012). Mitigating program security vulnerabilities: Approaches and challenges. In ACM Computing Surveys (CSUR). https://dl.acm.org/doi/abs/10.1145/2187671.2187673

H Sharma. (2021). Survey of Research on Chunking Techniques. In Semanticscholar. org. https://www.academia.edu/download/46950325/1471.pdf

I Karunarathna, S Dius, R Ranwala, & S Bandara. (n.d.). Bridging and Chunking: Tools for Robust. https://www.researchgate.net/profile/Band-Rathnayak/publication/387057092_Bridging_and_Chunking_Tools_for_Robust_Memory_in_Medical_Learning/links/675dbffbda24c8537c71552c/Bridging-and-Chunking-Tools-for-Robust-Memory-in-Medical-Learning.pdf

J. Canós, C. Penadés, & J. A. Carsí. (1999). Process to Workflow Process : the Workflow Lifecycle. https://www.semanticscholar.org/paper/193e6d7cf20d93774bde9b1508eeaf97f47bc535

J Dey, N Soures, M Gonzales, I Lerner, & C Kanan. (2025). Temporal Chunking Enhances Recognition of Implicit Sequential Patterns. https://arxiv.org/abs/2506.00588

J Fonollosa, E Neftci, & M Rabinovich. (2015). Learning of chunking sequences in cognition and behavior. In PLoS computational biology. https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004592

J. Gutjahr & Andreas Loew. (2002). Scalability and Performance: JDBC Best Practices and Pitfalls. https://www.semanticscholar.org/paper/08ddaac2d0fe104499e6ca9c014cddbaaef24f81

J Ralyté, MA Jeusfeld, P Backlund, & H Kühn. (2008). A knowledge-based approach to manage information systems interoperability. In Information systems. https://www.sciencedirect.com/science/article/pii/S0306437908000112

J Rodriguez, O Sanan, & G Vizarreta-Luna. (2025). Text Chunking for Document Classification for Urban System Management using Large Language Models. https://arxiv.org/abs/2504.00274

J Sadek & F Meziane. (2016). Extracting arabic causal relations using linguistic patterns. https://dl.acm.org/doi/abs/10.1145/2800786

J Visumathi, PJ Jayarin, & PS Rose. (2016). Chunking and Storing of Sensitive Data in Public Cloud for Hospital Management. https://www.indianjournals.com/ijor.aspx?target=ijor:ajrssh&volume=6&issue=8&article=005

J Zhao, Z Ji, P Qi, S Niu, B Tang, & F Xiong. (2024). Meta-Chunking: Learning Efficient Text Segmentation via Logical Perception. https://arxiv.org/abs/2410.12788

JE Laird, PS Rosenbloom, & A Newell. (1986). Chunking in Soar: The anatomy of a general learning mechanism. In Machine learning. https://link.springer.com/article/10.1007/bf00116249

JF da Costa Júnior & JFD de Rezende. (2018). The impact of big data on SMEs strategic management: A study on a small British enterprise specialized in business intelligence. https://www.academia.edu/download/65973505/8774.pdf

Jiahui Geng, Zongxiong Chen, Yuandou Wang, Herbert Woisetschlaeger, Sonja Schimmler, Ruben Mayer, Zhiming Zhao, & Chunming Rong. (2023). A Survey on Dataset Distillation: Approaches, Applications and Future Directions. In International Joint Conference on Artificial Intelligence. https://www.semanticscholar.org/paper/1a3efe3595ca2f31da443e57d1b2dba585dba6b8

Jie Zheng. (2014). Enhance Data DeDuplication Performance With Multi-Thread Chunking Algorithm. https://www.semanticscholar.org/paper/f0e27bc0488e792af12e53f8edb9ccafbf0109a5

Joseph W. Caddell. (2017). Historical case studies in intelligence education: best practices, avoidable pitfalls. In Intelligence & National Security. https://www.semanticscholar.org/paper/5c5a2c42db6773478b0d647cd2ed2713e4467191

K Greer. (2005). New ideas for brain modelling 6. In arXiv. https://arxiv.org/abs/2005.05137

Katharina Eggensperger, M. Lindauer, & F. Hutter. (2017). Pitfalls and Best Practices in Algorithm Configuration. In J. Artif. Intell. Res. https://jair.org/index.php/jair/article/view/11420

KT Truong, SP Merz, M Scarlata, & F Günther. (2025). Breaking and fixing content-defined chunking. https://eprint.iacr.org/2025/558

L Qiu & W Wang. (2011). The effects of message order and information chunking on eWOM persuasion. https://aisel.aisnet.org/pacis2011/151/

LA Ramshaw & MP Marcus. (1999). Text chunking using transformation-based learning. https://link.springer.com/content/pdf/10.1007/978-94-017-2390-9_10?pdf=chapter%20toc

León Welicki, Javier Piqueres Juan, F. Martin, & V. Hernandez. (2009). Employee Life-Cycle Process Management Improvement with Web-Enabled Workflow Systems. https://www.semanticscholar.org/paper/5698c0651c3730cb6ec02966b698ab3c6e2574a9

Liu Yu-hua. (2010). Data Chunking Algorithm Based on Byte-fingerprint Extremum Characteristics. In Computer Engineering. https://www.semanticscholar.org/paper/92ea16d7adc97342c1f616b9fc2c1002c7c5db4f

Łukasz Kurant. (2023). Mechanism for Detecting Cause-and-Effect Relationships in Court Judgments. In 2023 18th Conference on Computer Science and Intelligence Systems (FedCSIS). https://annals-csis.org/Volume_35/drp/4827.html

M Akbar, I Ahmad, M Mirza, M Ali, & P Barmavatu. (2024). Enhanced authentication for de-duplication of big data on cloud storage system using machine learning approach. In Cluster Computing. https://link.springer.com/article/10.1007/s10586-023-04171-y

M Dozza, J Bärgman, & JD Lee. (2013). Chunking: A procedure to improve naturalistic data analysis. In Accident Analysis & Prevention. https://www.sciencedirect.com/science/article/pii/S0001457512001091

M. Galster, Laurens Lapre, & P. Avgeriou. (2014). SOA in Variability-Intensive Environments: Pitfalls and Best Practices. In IEEE Software. https://ieeexplore.ieee.org/document/6420845/

M Gregoriadis, L Balduf, & B Scheuermann. (2024). A Thorough Investigation of Content-Defined Chunking Algorithms for Data Deduplication. https://arxiv.org/abs/2409.06066

M Munyofu, WJ Swain, BD Ausman, & H Lin. (2007). The effect of different chunking strategies in complementing animated instruction. https://www.tandfonline.com/doi/abs/10.1080/17439880701690109

M Omar & SL Syed Abdullah. (2013). Agile practices: A cognitive learning perspective. https://core.ac.uk/download/pdf/42979359.pdf

Manabu Sassano & T. Utsuro. (2000). Named Entity Chunking Techniques in Supervised Learning for Japanese Named Entity Recognition. In International Conference on Computational Linguistics. https://www.semanticscholar.org/paper/ae0519743fe1d80cd2bb4de931980adb6cce216a

Manogar Ellappan & S. Abirami. (2021). Dynamic Prime Chunking Algorithm for Data Deduplication in Cloud Storage. In KSII Trans. Internet Inf. Syst. https://www.semanticscholar.org/paper/372badab2cc21fbc9a728f4d6e5048dfdc3fae1d

Marko Junkkari & A. Sirkka. (2014). Data-Centric Workflow Approach to Lifecycle Data Management. In International Conference on Data Technologies and Applications. https://www.scitepress.org/Link.aspx?doi=10.5220/0005001001160124

Máté Pataki. (2003). Plagiarism Detection and Document Chunking Methods. In The Web Conference. https://www.semanticscholar.org/paper/04ea6ff284a094301225949c3e97b24d3c2777d4

Me Me Khaing & N. Jeyanthi. (2022). DaDe: A Study of Chunking Algorithm and Hashing Function in Block Level Chunk based Data Deduplication. In 2022 IEEE 3rd Global Conference for Advancement in Technology (GCAT). https://ieeexplore.ieee.org/document/9972150/

MG Beruvides, P Pazos, & JL Hanson. (2004). The Chunking of Course Material Delivery and Evaluation: A Case for Information Processing Management and Evaluation. In 2004 GSW. https://peer.asee.org/40030.pdf

MH Christiansen & N Chater. (2016). The now-or-never bottleneck: A fundamental constraint on language. In Behavioral and brain sciences. https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/nowornever-bottleneck-a-fundamental-constraint-on-language/938D54E80A2A90A1C5990F4915B5E8D8

MI Rabinovich, P Varona, & I Tristan. (2014). Chunking dynamics: heteroclinics in mind. https://www.frontiersin.org/articles/10.3389/fncom.2014.00022/full

MJP Wolf. (2016). The Importance of Overflow and Chunking in World-Building and the Experiencing of Imaginary Worlds. In Revisiting Imaginary Worlds. https://www.taylorfrancis.com/chapters/edit/10.4324/9781315673363-28/importance-overflow-chunking-world-building-experiencing-imaginary-worlds-mark-wolf

MR Nassar, JC Helmers, & MJ Frank. (2018). Chunking as a rational strategy for lossy data compression in visual working memory. In Psychological review. https://psycnet.apa.org/record/2018-30695-002

Mu’men Al Jarah, Sreeharsha Udayashankar, Abdelrahman Baba, & S. Al-Kiswany. (2024). The Impact of Low-Entropy on Chunking Techniques for Data Deduplication. In 2024 IEEE 17th International Conference on Cloud Computing (CLOUD). https://ieeexplore.ieee.org/document/10643911/

Niu Shu-jie. (2005). The Chunking Theory in Human Learning. In Journal of Chongqing University. https://www.semanticscholar.org/paper/357fd72f1decc4097484a0067c61ed2c32030bca

Norma Che Lah, R. M. Saat, & Ruhaya Hassan. (2014). Cognitive strategy in learning chemistry: how chunking and learning get together. In Malaysian Online Journal of Educational Sciences. https://www.semanticscholar.org/paper/0f3386fe7fc5707c3b9b99666c76124d2090ea78

O. Lappi. (2022). Egocentric Chunking in the Predictive Brain: A Cognitive Basis of Expert Performance in High-Speed Sports. In Frontiers in Human Neuroscience. https://www.frontiersin.org/articles/10.3389/fnhum.2022.822887/full

P. Minishapriya & S. Maheswari. (2018). Performance Analysis of Cloud Storage Using Chunking Algorithm. In 2018 Fourth International Conference on Advances in Electrical, Electronics, Information, Communication and Bio-Informatics (AEEICB). https://ieeexplore.ieee.org/document/8480952/

P Ramkumar, DE Acuna, M Berniker, & ST Grafton. (2016). Chunking as the result of an efficiency computation trade-off. https://www.nature.com/articles/ncomms12176

P Suppawittaya & P Yasri. (2021). The comparison of chunking methods to enhance the cognitive capacity of short-term memory to retain textual information among high school students. https://jurnal-fkip.ut.ac.id/index.php/ijrse/article/view/502

P. Suppawittaya & Pratchayapong Yasri. (2021). THE EFFECTIVENESS OF CHUNKING METHODS FOR ENHANCING SHORT-TERM MEMORY OF TEXTUAL INFORMATION. https://www.semanticscholar.org/paper/eea171aca8ce3329733692a2f9197a466b3818cd

Pinar Alper. (2014). Re-thinking Workflow Provenance against Data-Oriented Investigation Lifecycle. https://www.semanticscholar.org/paper/b532c700bbc0697a8967c807aa349221c346c8f3

Pooja Singh & Roshni Parihar. (2018). Systematic Survey on issues and challenges on cloud storage. In Journal of emerging technologies and innovative research. https://www.semanticscholar.org/paper/3c95322745349d55bbcaaf874678594792629428

PS Rosenbloom & A Newell. (1982). Learning by chunking: A production-system model of practice. https://kilthub.cmu.edu/ndownloader/files/12097361

R. Iyer. (2006). Security vulnerabilities: from measurements to design. In ACM Asia Conference on Computer and Communications Security. https://dl.acm.org/doi/10.1145/1128817.1128823

R. Saranya, S. Vidhya, M. Muthumari, & B. Sangeerthana. (2019). Data Deduplication in Cloud by Chunking. https://www.semanticscholar.org/paper/3db98c6610bbba17c17c9a7e3b2ddab9d30c52ab

R Tourani, S Misra, & T Mick. (2017). Security, privacy, and access control in information-centric networking: A survey. https://ieeexplore.ieee.org/abstract/document/8027034/

Richa Arora & Vetrithangam D. (2024). Enhancing Cloud Data Deduplication with Dynamic Chunking and Public Blockchain. In Journal of Machine and Computing. https://www.semanticscholar.org/paper/824784fe4ebd30f89dc04aba2137f9cf67046dea

RNS Widodo, H Lim, & M Atiquzzaman. (2017). A new content-defined chunking algorithm for data deduplication in cloud storage. https://www.sciencedirect.com/science/article/pii/S0167739X16305829

S Aryal, T Do, B Heyojoo, & S Chataut. (2024). Leveraging multi-AI agents for cross-domain knowledge discovery. https://arxiv.org/abs/2404.08511

S Chen, J Xu, Z Kalbarczyk, & K Iyer. (2006). Security vulnerabilities: From analysis to detection and masking techniques. In Proceedings of the IEEE. https://ieeexplore.ieee.org/abstract/document/1580509/

S Federici, S Montemagni, & V Pirrelli. (1998). Chunking Italian: Linguistic and Task-oriented Evaluation. https://www.academia.edu/download/70977032/Chunking_Italian_Linguistic_and_Task-ori20211002-31980-8cgvmu.pdf

S. Ruba & A. Kalpana. (2018). Survey on Content based Chunking in Data Deduplication on Cloud Storage Environment. In Data mining and knowledge engineering. https://www.semanticscholar.org/paper/99e39a2b59a1d5475967a553b18732694fd4ff72

S Sirniawan, Y Hala, & AB Jamaluddin. (2025). The application of chunking technique combined with writing is thinking to improve the communication skills. In Jurnal Mangifera Edu. https://jurnal.biounwir.ac.id/article/view/213

Safa Ali, Abdo Hussein, R. Badlishah, N. Yaakob, Fathey Mohammed, & Abdul Ghani Khan. (2024). Content-Defined Chunking Algorithms in Data Deduplication: Performance, Trade-Offs and Future-Oriented Techniques. In Journal of Advanced Research in Applied Sciences and Engineering Technology. https://www.semanticscholar.org/paper/ff4473fd426ec32e4bd0f4333a02d2fe7c3c53ef

SB Fountain, JL Sharp, & CC Jackman. (2022). Chunking. https://link.springer.com/content/pdf/10.1007/978-3-319-55065-7_1582.pdf

SBNP Kumari, A Ravi, & SSS Shony. (2025). A secure cloud based data chunking and file encryption system. https://pubs.aip.org/aip/acp/article-abstract/3258/1/020017/3345253

Sébastien Jean & Andrew Drozdov. (2016). Tagging and Chunking with Subword 2 Word models. https://www.semanticscholar.org/paper/87b860da2501169aafafdfa0cac18e6779a198c1

Seng-Beng Ho & Fiona Liausvia. (2013). Incremental Rule Chunking for Problem Solving. In 2013 BRICS Congress on Computational Intelligence and 11th Brazilian Congress on Computational Intelligence. https://ieeexplore.ieee.org/document/6855870/

Seong-Bae Park & Byoung-Tak Zhang. (2003). Text Chunking by Combining Hand-Crafted Rules and Memory-Based Learning. In Annual Meeting of the Association for Computational Linguistics. https://www.semanticscholar.org/paper/3430d81b966bad129026c31d1dba4069c89628a5

Sharma, Mishra, S. Hershey, Yavuz Akbulut, Ramesh C Sharma, Sanjaya Mishra, & Indira. (2007). CASES ON GLOBAL E-LEARNING PRACTICES : Successes and Pitfalls. https://www.semanticscholar.org/paper/5b400ebdb1433de0e6f0e64c2a333bebbea2f430

ST Ngandoh, R Riandi, & A Rahmat. (2025). Chunking Techniques to Enhance Learning Outcomes in the Human Body System. https://journal.ia-education.com/index.php/ijorer/article/view/754

T Dasgupta, R Saha, & L Dey. (2018). Automatic extraction of causal relations from text using linguistically informed deep neural networks. https://aclanthology.org/W18-5035/

T Hope, J Chan, A Kittur, & D Shahaf. (2017). Accelerating innovation through analogy mining. https://dl.acm.org/doi/abs/10.1145/3097983.3098038

T Trese & S Tilley. (2007). Documenting software systems with views V: towards visual documentation of design patterns as an aid to program understanding. https://dl.acm.org/doi/abs/10.1145/1297144.1297167

T Zhang, F Damerau, & D Johnson. (2002). Text chunking based on a generalization of winnow. In Journal of Machine Learning Research. http://www.jmlr.org/papers/v2/zhang02c.html

Takeshi Ito, H. Matsubara, & R. Grimbergen. (2001). The Use of Memory and Causal Chunking in the Game of Shogi. https://www.semanticscholar.org/paper/b5cc763a38e79b57eafbe87f85427f35e61d1023

Takeya Kota & Lepage Yves. (2011). Evaluation of Analogy-based Translation of Chunks obtained by Marker-based Chunking. https://www.semanticscholar.org/paper/759e5fb2a919898a1fb6391b22624e6cd2799988

TL Lee & A Storkey. (2023). Chunking: Continual Learning is not just about Distribution Shift. In arXiv. https://arxiv.org/abs/2310.02206

U Schneider. (2014). Frequency, chunks and hesitations: A usage-based analysis of chunking in English. https://d-nb.info/112264678X/34

V. Afraimovich, T. Young, & M. Rabinovich. (2014). Hierarchical Heteroclinics in Dynamical Model of Cognitive Processes: Chunking. In Int. J. Bifurc. Chaos. https://www.worldscientific.com/doi/abs/10.1142/S0218127414501326

V. Surovtsev. (2024). Skepticism, Straight Solution and Linguistic Frameworks. In Epistemology &amp; Philosophy of Science. https://www.semanticscholar.org/paper/a939d351cd68ef02d7af53997240b52303febdb6

Verónica Mendoza Fernández. (2020). TOWARDS THE AUTOMATISATION OF A FOREIGN LANGUAGE: SENSORIMOTOR DRILLING, THE STRUCTURATION OF LINGUISTIC INPUT ON THE BASIS OF PROCESSING DEMANDS AND SENSORY CHUNKING. https://www.semanticscholar.org/paper/68b46aaeb0861b605310beb1f17ca8c681343dfd

W. Orvis & A. Lehn. (1995). Data Security Vulnerabilities of Facsimile Machines and Digital Copiers. https://www.semanticscholar.org/paper/0a30e9df02486fe0c887c3c9368e5b7e7b6be7ba

W Xia, X Zou, H Jiang, Y Zhou, & C Liu. (2020). The design of fast content-defined chunking for data deduplication based storage systems. https://ieeexplore.ieee.org/abstract/document/9055082/

W Zhang, J Zhang, S Yu, & M Duan. (2024). A Cross-Silo Vulnerability Federated Learning Approach Based on Content Chunking. https://ieeexplore.ieee.org/abstract/document/10794678/

Wen Xia, Yukun Zhou, Hong Jiang, D. Feng, Yu Hua, Yuchong Hu, Qing Liu, & Yucheng Zhang. (2016). FastCDC: a Fast and Efficient Content-Defined Chunking Approach for Data Deduplication. In USENIX Annual Technical Conference. https://www.semanticscholar.org/paper/64b5ce9ff6c7f5396cd1ec6bba8a9f5f27bc8dba

X Lu. (2023). Chunking Grammar Learning: The Study of Formulaic Expressions in Chinese as a Second Language. https://search.proquest.com/openview/04168f57dc6532149ad052047e0dc8d5/1?pq-origsite=gscholar&cbl=18750&diss=y

Xiaolu Zhang, Wuqiang Shen, Zheheng Liang, Lei Cui, & Yechao Wang. (2024). Research and Application of Automated Testing Technology for Data Security Vulnerabilities. In 2024 4th International Conference on Mobile Networks and Wireless Communications (ICMNWC). https://www.semanticscholar.org/paper/2a79fc39df0df0d8496501f24ccbab66fac7f868

Y. Won, Kyeongyeol Lim, & Jaehong Min. (2015). MUCH: Multithreaded Content-Based File Chunking. In IEEE Transactions on Computers. https://ieeexplore.ieee.org/document/6815680/

Y. Zhang, Wen Wang, Ting Yin, & Jiang Yuan. (2013). A Novel Frequency Based Chunking for Data Deduplication. In Applied Mechanics and Materials. https://www.scientific.net/AMM.278-280.2048

Yilin Jiang. (2023). The Competitiveness of Shake Shack in Chengdu under SWOT Analysis. In Advances in Economics, Management and Political Sciences. https://www.semanticscholar.org/paper/16c0cf32ec058b3cc9c4a019c8d8b28114a99ef3

Yuqi Zhang & Qiang Zhou. (2002). Chinese Base-Phrases Chunking. In SIGHAN@COLING. https://dl.acm.org/citation.cfm?doid=1118824.1118842

Z Wu, AA Deshmukh, Y Wu, J Lin, & L Mou. (2025). The Emergence of Chunking Structures with Hierarchical RNN. In Computational Linguistics. https://direct.mit.edu/coli/article/doi/10.1162/coli_a_00545/125288

Zamfir Cristina-Mihaela. (2010). Applications of the Chunking Technique in Business Communication. In Ovidius University Annals: Economic Sciences Series. https://www.semanticscholar.org/paper/f3712620d6faeef7dcb54c93f20d81a4028ac3db

Zi Hui, Gencheng Wang, & Yuzhen Chen. (2023). Double embedding reversible information hiding based on chunking. In International Conference on Computer Graphics, Image and Virtualization. https://www.spiedigitallibrary.org/conference-proceedings-of-spie/12934/3007994/Double-embedding-reversible-information-hiding-based-on-chunking/10.1117/12.3007994.full

Zijun Wu, Anup Anand Deshmukh, Yongkang Wu, Jimmy Lin, & Lili Mou. (2024). The Emergence of Chunking Structures with Hierarchical HRNN. In Computational Linguistics. https://direct.mit.edu/coli/article/doi/10.1162/coli_a_00545/125288/The-Emergence-of-Chunking-Structures-with



Generated by Liner
https://getliner.com/search/s/5926611/t/85662430